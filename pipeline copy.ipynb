{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overview\n",
    "- pipeline that finds the best suggestion, prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random, sys, copy, os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Ensure deterministic algorithms\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/filtered_model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"start_time\"] = df[\"start_time\"].astype('datetime64[ns]')\n",
    "df = df.sort_values(by=[\"patient_id\", \"start_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a row of sessions, take domain_ids and domain_scores, which are in string format separated by \",\", and replace with a list of the values\n",
    "def process_row(row):\n",
    "    values_a = [int(x.strip()) for x in str(row['domain_ids']).split(',')]\n",
    "    values_b = [float(x.strip()) for x in str(row['domain_scores']).split(',')]\n",
    "    return values_a, values_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in a dataframe of a patient's session, extract information useful for training\n",
    "def create_training_data(data: pd.DataFrame):\n",
    "    # Initialize variables\n",
    "    session_row = [] # contents of a row (patient id, encoding, cur score, prev score, repeat)\n",
    "    overall = [] # aggregate of everything (n sessions x 44)\n",
    "\n",
    "    cur_score = np.zeros((14)) # score for each session\n",
    "    cur_score.fill(np.nan)\n",
    "    prev_score = None\n",
    "\n",
    "    # seen = {} # dictionary for seen\n",
    "    patient_id = data[\"patient_id\"].iloc[0] # save patient_id\n",
    "\n",
    "    # Sort data by session start time\n",
    "    data = data.sort_values(by=[\"start_time\"])\n",
    "\n",
    "    # Process each row\n",
    "    for idx, row in data.iterrows():\n",
    "        domains, domain_scores = process_row(row)  # returns a list of domains : int and of domain_scores : float\n",
    "        domain = np.random.choice(14, 1)[0] # choose a random domain instead\n",
    "\n",
    "        # Track repeat status and update scores\n",
    "        if prev_score is None:\n",
    "            repeat = False\n",
    "        else:\n",
    "            # find if domain already has a score\n",
    "            next_domain_score = prev_score[domain]\n",
    "            if np.isnan(next_domain_score): repeat = False\n",
    "            else: repeat = True\n",
    "        # repeat = False\n",
    "\n",
    "        # for j, domain in enumerate(domains):\n",
    "        # if domain not in seen:\n",
    "        #     seen[domain] = True\n",
    "        # else:\n",
    "        #     repeat = True\n",
    "        \n",
    "        for j, domain in enumerate(domains):\n",
    "            cur_score[domain - 1] = domain_scores[j] # update score in the loop\n",
    "\n",
    "        # Encode domains for this session\n",
    "        domain_encoding = np.zeros(14)\n",
    "        domain_encoding[domain - 1] = 1\n",
    "        \n",
    "        \n",
    "\n",
    "        # if the session does not contain the target domain or is the first (no prev score), continue in the loop without doing anything, do this before appending\n",
    "        if prev_score is None:\n",
    "            session_row = []\n",
    "            prev_score = cur_score.copy()\n",
    "            continue\n",
    "        # assert np.sum(domain_encoding) != 1, \"continue not working\"\n",
    "\n",
    "        # append everything in the row list\n",
    "        session_row.append(patient_id)\n",
    "        session_row.extend(domain_encoding.copy().tolist()) #encoding\n",
    "        session_row.extend(prev_score.copy().tolist()) # score\n",
    "        session_row.extend(cur_score.copy().tolist())# target\n",
    "        session_row.append(repeat)\n",
    "        session_row.append(row[\"start_time\"].timestamp())\n",
    "        assert len(session_row) == 45, \"session row length incorrect\"\n",
    "\n",
    "        # append row to overall, reset\n",
    "        overall.append(session_row)\n",
    "        session_row = []\n",
    "        prev_score = cur_score.copy()\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    if overall:\n",
    "        overall = np.array(overall)\n",
    "        assert len(overall.shape) == 2, \"dimensions of overall wrong\"\n",
    "    else:\n",
    "        # Handle case where scores is empty\n",
    "        return pd.DataFrame(columns=[\"patient_id\"] + [\"domain %d encoding\" % i for i in range(1, 15)] +\n",
    "                                   [\"domain %d score\" % i for i in range(1, 15)] +\n",
    "                                   [\"domain %d target\" % i for i in range(1, 15)] +\n",
    "                                   [\"repeat\"] +\n",
    "                                   [\"start_time\"])\n",
    "    \n",
    "        # Create column names\n",
    "    column_names = (\n",
    "        [\"patient_id\"]\n",
    "        + [f\"domain {i} encoding\" for i in range(1, 15)]\n",
    "        + [f\"domain {i} score\" for i in range(1, 15)]\n",
    "        + [f\"domain {i} target\" for i in range(1, 15)]\n",
    "        + [\"repeat\"]\n",
    "        + [\"start_time\"]\n",
    "    )\n",
    "\n",
    "    # Create dataframe\n",
    "    scores_df = pd.DataFrame(overall, columns=column_names)\n",
    "    scores_df.reset_index(drop=True, inplace=True)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here [0.429   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "   nan   nan]\n",
      "nan\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatient_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_training_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ct/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[1;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1829\u001b[0m         ):\n\u001b[1;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1836\u001b[0m             )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ct/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ct/lib/python3.9/site-packages/pandas/core/groupby/ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[34], line 30\u001b[0m, in \u001b[0;36mcreate_training_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     28\u001b[0m     next_domain_score \u001b[38;5;241m=\u001b[39m prev_score[domain]\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(next_domain_score)\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnext_domain_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m(): repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# repeat = False\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# for j, domain in enumerate(domains):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#     repeat = True\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'isna'"
     ]
    }
   ],
   "source": [
    "data = df.groupby(\"patient_id\")[df.columns].apply(create_training_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = [\"domain %d score\" %i for i in range(1, 15)]\n",
    "encoding_columns = [\"domain %d encoding\" %i for i in range(1, 15)]\n",
    "target_columns = [\"domain %d target\" %i for i in range(1, 15)]\n",
    "repeat_columns = [\"repeat\"]\n",
    "time_columns = [\"start_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows based on number of missing values (denoted by nans) the session has\n",
    "def filter_n_missing(df, n_missing):\n",
    "    # only use the score columns when counting 0s\n",
    "    scores = df[score_columns]\n",
    "    # Count number of nans in each row\n",
    "    missing_count = scores.isna().sum(axis=1)\n",
    "    \n",
    "    # Filter rows with n_zeros number of zeros\n",
    "    filtered_rows = df[missing_count == n_missing]\n",
    "    return filtered_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "n_samples = 100000\n",
    "\n",
    "## one sample for train, only to see if it learns that one example\n",
    "train_data = train_data[:n_samples].copy()\n",
    "test_data = test_data[:n_samples].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing indicator when given the score data\n",
    "def create_missing_indicator(data):\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    (l, w) = data.shape\n",
    "    temp = np.zeros((l, w*2))\n",
    "    for i in range(l):\n",
    "        for d in range(w):\n",
    "            p = data[i, d]\n",
    "            # update output array\n",
    "            # if p == 0:\n",
    "            if np.isnan(p):\n",
    "                missing_ind = np.random.choice(2, 1)[0]\n",
    "                temp[i, d*2] = missing_ind\n",
    "                temp[i, d*2+1] = missing_ind\n",
    "            else:\n",
    "                temp[i, d*2] = p # score\n",
    "                temp[i, d*2+1] = 1-p # 1-score\n",
    "    assert not np.isnan(temp).any(), \"nans exists!!!\"\n",
    "    return copy.deepcopy(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a processed dataframe, return data and target numpy arrays\n",
    "def create_model_data(data : pd.DataFrame):\n",
    "    target = data[target_columns].copy().to_numpy() * data[encoding_columns].copy().to_numpy()\n",
    "    data_scores = create_missing_indicator(data[score_columns].copy().to_numpy())\n",
    "    return data_scores, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input : 14 domain encodings + 14 domains (28 total features with missing indicator)\n",
    "## output: 28 score (prediction for the scores after next domain)\n",
    "## copied from next_step.py, which was used to train the model\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        n_domains = 14\n",
    "        \n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_domains * 3, 100),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(100, n_domains)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# used for batch training\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index, :], self.target[index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = NN()\n",
    "model = torch.load(\"output/experiment4/model.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add encoding to scores and return a tensor that can be put directly into the model\n",
    "def add_encoding(scores : np.ndarray, encoding : np.ndarray):\n",
    "    return torch.from_numpy(np.hstack((encoding, scores))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return predictions, loss, and mae\n",
    "def predict(model, x, y):\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(x)\n",
    "        loss = loss_function(predictions, y.reshape(predictions.shape))    \n",
    "        return predictions.clone().numpy(), loss.clone().item(), torch.mean(torch.abs(predictions - y.reshape(predictions.shape))).clone().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average improvement plots and store, d_type= Ground Truth or Prediction, mode=train or test, cur_score=whatever we need, data=test or train data\n",
    "def plot_average_improvements(mode, cur_score, encoding, prev_score):\n",
    "    # Step 1: Compute differences\n",
    "    differences = cur_score - prev_score\n",
    "    # Step 2: Mask the differences using the encoding array\n",
    "    masked_differences = np.where(encoding == 1, differences, 0)  # Retain differences only where encoding is 1\n",
    "    # Step 3: Compute the column-wise sum and count\n",
    "    column_sums = np.sum(masked_differences, axis=0)  # Sum of differences for each column\n",
    "    column_counts = np.sum(encoding, axis=0)          # Number of 1s in each column\n",
    "    # Step 4: Filter out columns with no encoding == 1\n",
    "    valid_columns = column_counts > 0  # Boolean mask for valid columns\n",
    "    filtered_sums = column_sums[valid_columns]\n",
    "    filtered_counts = column_counts[valid_columns]\n",
    "    # Step 5: Compute the column-wise averages for valid columns\n",
    "    filtered_averages = filtered_sums / filtered_counts\n",
    "    filtered_column_indices = np.where(valid_columns)[0]\n",
    "    # Plot the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Create the figure and axes\n",
    "    bars = ax.bar(range(len(filtered_averages)), filtered_averages, tick_label=[f\"{i+1}\" for i in filtered_column_indices])\n",
    "    # Add values to the bars\n",
    "    ax.bar_label(bars, fmt='%.4f', label_type='edge')\n",
    "    # Set the y-axis range\n",
    "    ax.set_ylim(-0.1, 0.5)\n",
    "    # Add labels and title\n",
    "    title_s = \"%s Data Domain Improvement Averages\" % (mode)\n",
    "    plt.xlabel(\"Domains\", fontsize=12)\n",
    "    plt.ylabel(\"Average Difference\", fontsize=12)\n",
    "    plt.title(title_s, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_avg_improvement(cur_score, prev_score, encoding):\n",
    "    cur_score = np.nan_to_num(cur_score, nan=0)\n",
    "    prev_score = np.nan_to_num(prev_score, nan=0)\n",
    "    if np.sum(encoding) == 0:\n",
    "        total_improvement = 0\n",
    "        print(\"no sessions\")\n",
    "    else:\n",
    "        total = np.sum(encoding)\n",
    "        total_improvement = np.sum(encoding * cur_score - encoding * prev_score) / total\n",
    "    return total_improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assignment(data):\n",
    "    # sort by timestamp\n",
    "    data = data.sort_values(by=\"start_time\")\n",
    "    # assign repeat values\n",
    "    seen = dict() # Track repeat status and update scores\n",
    "    repeat_lst = []\n",
    "    for idx, row in data.iterrows():\n",
    "            domain = row[encoding_columns].idxmax()\n",
    "            if domain not in seen:\n",
    "                seen[domain] = 1\n",
    "                repeat_lst.append(0)\n",
    "            else:\n",
    "                repeat_lst.append(1)\n",
    "    data.drop(repeat_columns[0], axis=1, inplace=True)\n",
    "    data[repeat_columns[0]] = repeat_lst    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_data_repeat = test_data[test_data.repeat == 1].copy()\n",
    "ground_truth_test_data_nonrepeat = test_data[test_data.repeat == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_data_n_zeros_repeat = dict() ## a dictionary that stores the data on the key of the number of missing domains\n",
    "for n in range(14):\n",
    "    tmp = filter_n_missing(ground_truth_test_data_repeat, n_missing=n)\n",
    "    ground_truth_test_data_n_zeros_repeat[n] = tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_data_n_zeros_nonrepeat = dict() ## a dictionary that stores the data on the key of the number of missing domains\n",
    "for n in range(14):\n",
    "    tmp = filter_n_missing(ground_truth_test_data_nonrepeat, n_missing=n)\n",
    "    ground_truth_test_data_n_zeros_nonrepeat[n] = tmp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_prediction_dict_repeat = dict() # dictionary that stores the prediction list\n",
    "ground_truth_avg_improvement_lst_repeat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through number of domains\n",
    "for n in range(14):\n",
    "    tmp = ground_truth_test_data_n_zeros_repeat[n] # set tmp to the data used for this iteration\n",
    "    x_tmp, y_tmp = create_model_data(tmp) # create scores with missing indicators and target\n",
    "\n",
    "    encoding = tmp[encoding_columns].copy().to_numpy() # encoding\n",
    "    tmp_single = add_encoding(x_tmp, encoding) # add encoding on x_tmp\n",
    "    prediction, loss, mae = predict(model, tmp_single, torch.from_numpy(y_tmp).float())\n",
    "    \n",
    "    ground_truth_prediction_dict_repeat[n] = prediction\n",
    "    ground_truth_avg_improvement_lst_repeat.append(overall_avg_improvement(prediction, ground_truth_test_data_n_zeros_repeat[n][score_columns].to_numpy(), encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,15), ground_truth_avg_improvement_lst_repeat[::-1])\n",
    "plt.xlabel(\"number of known domains\")\n",
    "plt.ylabel(\"average best improvement in score\")\n",
    "plt.title(\"average best improvement for random repeats\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_prediction_dict_nonrepeat = dict() # dictionary that stores the prediction list\n",
    "ground_truth_avg_improvement_lst_nonrepeat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through number of domains\n",
    "for n in range(14):\n",
    "    tmp = ground_truth_test_data_n_zeros_nonrepeat[n] # set tmp to the data used for this iteration\n",
    "    x_tmp, y_tmp = create_model_data(tmp) # create scores with missing indicators and target\n",
    "\n",
    "    encoding = tmp[encoding_columns].copy().to_numpy() # encoding\n",
    "    tmp_single = add_encoding(x_tmp, encoding) # add encoding on x_tmp\n",
    "    prediction, loss, mae = predict(model, tmp_single, torch.from_numpy(y_tmp).float())\n",
    "    \n",
    "    ground_truth_prediction_dict_nonrepeat[n] = prediction\n",
    "    ground_truth_avg_improvement_lst_nonrepeat.append(overall_avg_improvement(prediction, ground_truth_test_data_n_zeros_nonrepeat[n][score_columns].to_numpy(), encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,15), ground_truth_avg_improvement_lst_nonrepeat[::-1])\n",
    "plt.xlabel(\"number of known domains\")\n",
    "plt.ylabel(\"average best improvement in score\")\n",
    "plt.title(\"average best improvement for random nonrepeats\")\n",
    "plt.show()\n",
    "## TODO: double check that this matches the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(14):\n",
    "    tmp = filter_n_missing(test_data, n_missing=n)\n",
    "    print(\"# of missing = %d, # of sessions = %d\" % (n, tmp.shape[0]))\n",
    "    print(np.isnan(tmp[score_columns]).sum(axis=1).sum() == n * tmp.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
