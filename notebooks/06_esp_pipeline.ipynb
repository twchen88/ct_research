{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3e6f8d",
   "metadata": {},
   "source": [
    "# Project: Time series predictor with zero prescriptor ESP project\n",
    "Description: Similar setup to Covid NPI project  \n",
    "12/18/25: switch to package preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5114f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List, Dict, Any, Optional, Tuple, Sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcea5bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/964505/CT/ct_research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory so we can load data correctly (all functions at this point are not put into modules yet)\n",
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e0949",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05aec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== CONFIG =====================\n",
    "CONFIG = {\n",
    "    \"time\": {\n",
    "        \"granularity\": \"week\",\n",
    "        \"week_freq\": \"W-MON\",\n",
    "        \"lookback_weeks\": 12,\n",
    "        \"lookahead_weeks\": 6,\n",
    "        \"agg\": \"mean\",\n",
    "        \"missing_code\": \"00\",\n",
    "    },\n",
    "    \"features\": {\n",
    "        # pair-encoding is always used (present, 1-x)\n",
    "        \"covariates\": [\n",
    "            \"week_index\",\n",
    "            \"weeks_since_last_active\",\n",
    "            \"n_sessions_week\",\n",
    "            \"n_domains_week\",\n",
    "            \"week_of_year\",\n",
    "        ]\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"d_hidden\": 128,\n",
    "        \"enc_layers\": 1,\n",
    "        \"trunk_hidden\": 128,\n",
    "        \"dropout\": 0.10,\n",
    "        \"user_embed_dim\": 32,\n",
    "        \"lowrank_r\": 0,\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"epochs\": 6,\n",
    "        \"lr\": 2e-3,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"grad_clip\": 1.0,\n",
    "        \"drop_no_target\": True,\n",
    "        \"val_frac\": 0.15,\n",
    "        \"train_frac\": 0.70,\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "    \"targets\": {\n",
    "        \"outcome\": \"global\",\n",
    "    }\n",
    "}\n",
    "# =============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e922cd",
   "metadata": {},
   "source": [
    "## General Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149046e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_score(y_vec: np.ndarray, mask_vec: Optional[np.ndarray] = None) -> float:\n",
    "    \"\"\"\n",
    "    y_vec: (K,) per-domain scores in [0,1]\n",
    "    mask_vec: (K,) optional 1/0 mask of which domains are observed\n",
    "    \"\"\"\n",
    "    if mask_vec is None:\n",
    "        return float(np.mean(y_vec))\n",
    "    m = np.asarray(mask_vec, dtype=float)\n",
    "    s = m.sum()\n",
    "    return 0.0 if s <= 1e-8 else float((y_vec * m).sum() / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb979739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advance_weekly_covariates(last_x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    last_x: (D_x,) ordered as [week_index, weeks_since_last_active, n_sessions_week, n_domains_week, week_of_year]\n",
    "    MVP policy: keep volume/breadth fixed; increment week_index + week_of_year; update gap accordingly.\n",
    "    \"\"\"\n",
    "    week_index, gap, nsess, ndoms, week_of_year = last_x.tolist()\n",
    "    week_index = float(week_index) + 1.0\n",
    "    week_of_year = int(week_of_year) + 1\n",
    "    if week_of_year > 53: week_of_year = 1\n",
    "    gap = 0.0 if nsess > 0 else float(gap) + 1.0\n",
    "    return np.array([week_index, gap, nsess, ndoms, float(week_of_year)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d3ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RunConfig:\n",
    "    window: int = 32\n",
    "    horizon: int = 1\n",
    "    outcome: str = \"global\"     # or \"per_domain\"\n",
    "    lookahead_days: int = 6 * 7\n",
    "    seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5f88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_with_min_viable_weeks(\n",
    "    M_target: np.ndarray,\n",
    "    meta: dict,\n",
    "    min_weeks: int = 4,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Return a list of user indices who have at least `min_weeks` viable weeks.\n",
    "    \n",
    "    A 'viable week' is defined as a week with at least one observed domain score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M_target : np.ndarray\n",
    "        Array of shape [U, T_max, K], mask of observed scores.\n",
    "    meta : dict\n",
    "        Metadata dictionary from encoder containing \"weeks_per_user\".\n",
    "    min_weeks : int\n",
    "        Minimum number of viable weeks required.\n",
    "    verbose : bool\n",
    "        Whether to print summary information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[int]\n",
    "        User indices that satisfy the requirement.\n",
    "    \"\"\"\n",
    "    U, T_max, K = M_target.shape\n",
    "    viable_users = []\n",
    "    viable_counts = []\n",
    "\n",
    "    for u in range(U):\n",
    "        T_u = len(meta[\"weeks_per_user\"][u])\n",
    "        M_u = M_target[u, :T_u]             # slice valid weeks only\n",
    "        weekly_obs = (M_u.sum(axis=1) > 0)  # boolean: domain observed?\n",
    "        n_viable = weekly_obs.sum()\n",
    "\n",
    "        if n_viable >= min_weeks:\n",
    "            viable_users.append(u)\n",
    "            viable_counts.append(n_viable)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Users meeting >= {min_weeks} viable weeks: {len(viable_users)} / {U}\")\n",
    "        if len(viable_users) > 0:\n",
    "            print(f\"  Min viable = {min(viable_counts)}, Max viable = {max(viable_counts)}\")\n",
    "            print(f\"  Median viable = {np.median(viable_counts):.1f}\")\n",
    "        else:\n",
    "            print(\"  No users meet the criterion.\")\n",
    "\n",
    "    return viable_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ac4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_indices_from_passing_users(meta, passing_users: set[int]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Given meta['users'] and a set of patient_ids (passing_users),\n",
    "    return user indices that correspond to those patients.\n",
    "    \"\"\"\n",
    "    idxs = [\n",
    "        u_idx\n",
    "        for u_idx, pid in enumerate(meta[\"users\"])\n",
    "        if pid in passing_users\n",
    "    ]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79c663",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349301d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/wczx8z_50yn5szt1q9b333fr0000gp/T/ipykernel_51943/3211444471.py:1: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data_df = pd.read_csv('data/raw/predictor_data_20250529.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>task_type_id</th>\n",
       "      <th>task_level</th>\n",
       "      <th>domain_ids</th>\n",
       "      <th>domain_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11018577</td>\n",
       "      <td>2171</td>\n",
       "      <td>2018-04-13 17:37:55</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6,10</td>\n",
       "      <td>0.2950,0.8140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11018577</td>\n",
       "      <td>2171</td>\n",
       "      <td>2018-04-13 17:37:55</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6,10</td>\n",
       "      <td>0.2950,0.8140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11018577</td>\n",
       "      <td>2171</td>\n",
       "      <td>2018-04-13 17:37:55</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6,10</td>\n",
       "      <td>0.2950,0.8140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11018577</td>\n",
       "      <td>2171</td>\n",
       "      <td>2018-04-13 17:37:55</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6,10</td>\n",
       "      <td>0.2950,0.8140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11018577</td>\n",
       "      <td>2171</td>\n",
       "      <td>2018-04-13 17:37:55</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6,10</td>\n",
       "      <td>0.2950,0.8140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  patient_id           start_time  task_type_id  task_level  \\\n",
       "0  11018577        2171  2018-04-13 17:37:55             4           1   \n",
       "1  11018577        2171  2018-04-13 17:37:55             4           1   \n",
       "2  11018577        2171  2018-04-13 17:37:55             4           1   \n",
       "3  11018577        2171  2018-04-13 17:37:55             4           1   \n",
       "4  11018577        2171  2018-04-13 17:37:55             4           1   \n",
       "\n",
       "  domain_ids  domain_scores  \n",
       "0       6,10  0.2950,0.8140  \n",
       "1       6,10  0.2950,0.8140  \n",
       "2       6,10  0.2950,0.8140  \n",
       "3       6,10  0.2950,0.8140  \n",
       "4       6,10  0.2950,0.8140  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_df = pd.read_csv('data/raw/predictor_data_20250529.csv')\n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ce8f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80506846 entries, 0 to 80506845\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   id             int64 \n",
      " 1   patient_id     int64 \n",
      " 2   start_time     object\n",
      " 3   task_type_id   int64 \n",
      " 4   task_level     int64 \n",
      " 5   domain_ids     object\n",
      " 6   domain_scores  object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 4.2+ GB\n"
     ]
    }
   ],
   "source": [
    "raw_data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f61d0",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44271c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct.data.consolidating import HistoryEncoder\n",
    "from ct.viz.data import plot_random_patient_domain_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c41b42",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dbf9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HistoryEncoder(raw_data_df)\n",
    "weekly_df = encoder.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88e878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>domain_1_freq</th>\n",
       "      <th>domain_2_freq</th>\n",
       "      <th>domain_3_freq</th>\n",
       "      <th>domain_4_freq</th>\n",
       "      <th>domain_5_freq</th>\n",
       "      <th>domain_6_freq</th>\n",
       "      <th>domain_7_freq</th>\n",
       "      <th>domain_8_freq</th>\n",
       "      <th>domain_9_freq</th>\n",
       "      <th>domain_10_freq</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_5_inv</th>\n",
       "      <th>domain_6_inv</th>\n",
       "      <th>domain_7_inv</th>\n",
       "      <th>domain_8_inv</th>\n",
       "      <th>domain_9_inv</th>\n",
       "      <th>domain_10_inv</th>\n",
       "      <th>domain_11_inv</th>\n",
       "      <th>domain_12_inv</th>\n",
       "      <th>domain_13_inv</th>\n",
       "      <th>domain_14_inv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th>week_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2171</th>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48600</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47800</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46575</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        domain_1_freq  domain_2_freq  domain_3_freq  \\\n",
       "patient_id week_number                                                \n",
       "2171       0                        5              0              0   \n",
       "           1                        0              0              0   \n",
       "           2                        5              0              0   \n",
       "           3                       10              0              0   \n",
       "           4                       20              0              0   \n",
       "\n",
       "                        domain_4_freq  domain_5_freq  domain_6_freq  \\\n",
       "patient_id week_number                                                \n",
       "2171       0                        5              5              5   \n",
       "           1                        0              0              0   \n",
       "           2                        5              5              5   \n",
       "           3                       10             10             10   \n",
       "           4                       20             20             20   \n",
       "\n",
       "                        domain_7_freq  domain_8_freq  domain_9_freq  \\\n",
       "patient_id week_number                                                \n",
       "2171       0                        5              0              5   \n",
       "           1                        0              0              0   \n",
       "           2                        5              0              5   \n",
       "           3                       10              0             10   \n",
       "           4                       20              0             20   \n",
       "\n",
       "                        domain_10_freq  ...  domain_5_inv  domain_6_inv  \\\n",
       "patient_id week_number                  ...                               \n",
       "2171       0                         0  ...        0.7000         0.674   \n",
       "           1                         0  ...        0.7000         0.674   \n",
       "           2                         5  ...        0.7100         0.705   \n",
       "           3                        10  ...        0.7250         0.737   \n",
       "           4                        20  ...        0.7475         0.721   \n",
       "\n",
       "                        domain_7_inv  domain_8_inv domain_9_inv  \\\n",
       "patient_id week_number                                            \n",
       "2171       0                   0.790           0.0        0.370   \n",
       "           1                   0.790           0.0        0.370   \n",
       "           2                   0.820           0.0        0.460   \n",
       "           3                   0.850           0.0        0.550   \n",
       "           4                   0.835           0.0        0.505   \n",
       "\n",
       "                        domain_10_inv  domain_11_inv  domain_12_inv  \\\n",
       "patient_id week_number                                                \n",
       "2171       0                    0.000            0.0        0.00000   \n",
       "           1                    0.000            0.0        0.00000   \n",
       "           2                    0.379            0.0        0.48600   \n",
       "           3                    0.379            0.0        0.47800   \n",
       "           4                    0.232            0.0        0.46575   \n",
       "\n",
       "                        domain_13_inv  domain_14_inv  \n",
       "patient_id week_number                                \n",
       "2171       0                    0.000            0.0  \n",
       "           1                    0.000            0.0  \n",
       "           2                    0.206            0.0  \n",
       "           3                    0.224            0.0  \n",
       "           4                    0.242            0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37746501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_1_freq</th>\n",
       "      <th>domain_2_freq</th>\n",
       "      <th>domain_3_freq</th>\n",
       "      <th>domain_4_freq</th>\n",
       "      <th>domain_5_freq</th>\n",
       "      <th>domain_6_freq</th>\n",
       "      <th>domain_7_freq</th>\n",
       "      <th>domain_8_freq</th>\n",
       "      <th>domain_9_freq</th>\n",
       "      <th>domain_10_freq</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_5_inv</th>\n",
       "      <th>domain_6_inv</th>\n",
       "      <th>domain_7_inv</th>\n",
       "      <th>domain_8_inv</th>\n",
       "      <th>domain_9_inv</th>\n",
       "      <th>domain_10_inv</th>\n",
       "      <th>domain_11_inv</th>\n",
       "      <th>domain_12_inv</th>\n",
       "      <th>domain_13_inv</th>\n",
       "      <th>domain_14_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "      <td>656755.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.013842</td>\n",
       "      <td>7.446415</td>\n",
       "      <td>11.043027</td>\n",
       "      <td>15.313006</td>\n",
       "      <td>19.114266</td>\n",
       "      <td>10.678032</td>\n",
       "      <td>5.505102</td>\n",
       "      <td>2.965343</td>\n",
       "      <td>8.518805</td>\n",
       "      <td>23.710839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655286</td>\n",
       "      <td>0.381779</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.189140</td>\n",
       "      <td>0.398550</td>\n",
       "      <td>0.399089</td>\n",
       "      <td>0.118117</td>\n",
       "      <td>0.534350</td>\n",
       "      <td>0.363577</td>\n",
       "      <td>0.209011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>66.437980</td>\n",
       "      <td>35.379972</td>\n",
       "      <td>46.786699</td>\n",
       "      <td>51.349464</td>\n",
       "      <td>64.319447</td>\n",
       "      <td>53.032810</td>\n",
       "      <td>32.197931</td>\n",
       "      <td>20.929224</td>\n",
       "      <td>35.986673</td>\n",
       "      <td>83.935611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317380</td>\n",
       "      <td>0.354823</td>\n",
       "      <td>0.321833</td>\n",
       "      <td>0.314508</td>\n",
       "      <td>0.363505</td>\n",
       "      <td>0.278469</td>\n",
       "      <td>0.227269</td>\n",
       "      <td>0.298551</td>\n",
       "      <td>0.271753</td>\n",
       "      <td>0.271464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.301667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.569667</td>\n",
       "      <td>0.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4152.000000</td>\n",
       "      <td>4080.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>3720.000000</td>\n",
       "      <td>6760.000000</td>\n",
       "      <td>6912.000000</td>\n",
       "      <td>5016.000000</td>\n",
       "      <td>2328.000000</td>\n",
       "      <td>4428.000000</td>\n",
       "      <td>6744.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       domain_1_freq  domain_2_freq  domain_3_freq  domain_4_freq  \\\n",
       "count  656755.000000  656755.000000  656755.000000  656755.000000   \n",
       "mean       16.013842       7.446415      11.043027      15.313006   \n",
       "std        66.437980      35.379972      46.786699      51.349464   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         8.000000       0.000000       3.000000      10.000000   \n",
       "max      4152.000000    4080.000000    5500.000000    3720.000000   \n",
       "\n",
       "       domain_5_freq  domain_6_freq  domain_7_freq  domain_8_freq  \\\n",
       "count  656755.000000  656755.000000  656755.000000  656755.000000   \n",
       "mean       19.114266      10.678032       5.505102       2.965343   \n",
       "std        64.319447      53.032810      32.197931      20.929224   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%        14.000000       0.000000       0.000000       0.000000   \n",
       "max      6760.000000    6912.000000    5016.000000    2328.000000   \n",
       "\n",
       "       domain_9_freq  domain_10_freq  ...   domain_5_inv   domain_6_inv  \\\n",
       "count  656755.000000   656755.000000  ...  656755.000000  656755.000000   \n",
       "mean        8.518805       23.710839  ...       0.655286       0.381779   \n",
       "std        35.986673       83.935611  ...       0.317380       0.354823   \n",
       "min         0.000000        0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000        0.000000  ...       0.516000       0.000000   \n",
       "50%         0.000000        0.000000  ...       0.764500       0.301667   \n",
       "75%         0.000000       15.000000  ...       0.903000       0.720000   \n",
       "max      4428.000000     6744.000000  ...       1.000000       1.000000   \n",
       "\n",
       "        domain_7_inv   domain_8_inv   domain_9_inv  domain_10_inv  \\\n",
       "count  656755.000000  656755.000000  656755.000000  656755.000000   \n",
       "mean        0.228614       0.189140       0.398550       0.399089   \n",
       "std         0.321833       0.314508       0.363505       0.278469   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.161000   \n",
       "50%         0.000000       0.000000       0.390000       0.423000   \n",
       "75%         0.500000       0.283200       0.750000       0.600000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       domain_11_inv  domain_12_inv  domain_13_inv  domain_14_inv  \n",
       "count  656755.000000  656755.000000  656755.000000  656755.000000  \n",
       "mean        0.118117       0.534350       0.363577       0.209011  \n",
       "std         0.227269       0.298551       0.271753       0.271464  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.364000       0.108000       0.000000  \n",
       "50%         0.000000       0.622000       0.364000       0.027000  \n",
       "75%         0.160000       0.750000       0.569667       0.333000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9949c76",
   "metadata": {},
   "source": [
    "Visualize user trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "447cf101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pid, aggregate_weekly_df = plot_random_patient_domain_avg(weekly_df, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77adb885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotted patient_id: 162804\n"
     ]
    }
   ],
   "source": [
    "print(f\"Plotted patient_id: {pid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21f0d4",
   "metadata": {},
   "source": [
    "Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8272b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct.data.filtering import filter_users_by_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5c72bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter requirements\n",
    "\n",
    "min_sessions_per_week = 1\n",
    "min_weeks = 12\n",
    "require_consecutive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2967032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patient_id  week_number  domain_1_freq  domain_2_freq  domain_3_freq  \\\n",
      "0             2171            0              5              0              0   \n",
      "1             2171            1              0              0              0   \n",
      "2             2171            2              5              0              0   \n",
      "3             2171            3             10              0              0   \n",
      "4             2171            4             20              0              0   \n",
      "...            ...          ...            ...            ...            ...   \n",
      "329016      568669           34             36             24             12   \n",
      "329017      568669           35             40             16             16   \n",
      "329018      568669           36             12              4              4   \n",
      "329019      568669           37              0              0              0   \n",
      "329020      568669           38             12              4              4   \n",
      "\n",
      "        domain_4_freq  domain_5_freq  domain_6_freq  domain_7_freq  \\\n",
      "0                   5              5              5              5   \n",
      "1                   0              0              0              0   \n",
      "2                   5              5              5              5   \n",
      "3                  10             10             10             10   \n",
      "4                  20             20             20             20   \n",
      "...               ...            ...            ...            ...   \n",
      "329016             12             36             12              0   \n",
      "329017             16             48             16              0   \n",
      "329018              4             12              4              0   \n",
      "329019              0              0              0              0   \n",
      "329020              4             12              4              0   \n",
      "\n",
      "        domain_8_freq  ...  domain_5_inv  domain_6_inv  domain_7_inv  \\\n",
      "0                   0  ...      0.700000       0.67400         0.790   \n",
      "1                   0  ...      0.700000       0.67400         0.790   \n",
      "2                   0  ...      0.710000       0.70500         0.820   \n",
      "3                   0  ...      0.725000       0.73700         0.850   \n",
      "4                   0  ...      0.747500       0.72100         0.835   \n",
      "...               ...  ...           ...           ...           ...   \n",
      "329016              0  ...      0.731222       0.62700         0.000   \n",
      "329017              0  ...      0.742000       0.54625         0.000   \n",
      "329018              0  ...      0.742000       0.53300         0.000   \n",
      "329019              0  ...      0.742000       0.53300         0.000   \n",
      "329020              0  ...      0.742000       0.52000         0.000   \n",
      "\n",
      "        domain_8_inv  domain_9_inv  domain_10_inv domain_11_inv  \\\n",
      "0             0.0000      0.370000       0.000000           0.0   \n",
      "1             0.0000      0.370000       0.000000           0.0   \n",
      "2             0.0000      0.460000       0.379000           0.0   \n",
      "3             0.0000      0.550000       0.379000           0.0   \n",
      "4             0.0000      0.505000       0.232000           0.0   \n",
      "...              ...           ...            ...           ...   \n",
      "329016        0.1108      0.324333       0.092143           0.0   \n",
      "329017        0.1108      0.323250       0.136500           0.0   \n",
      "329018        0.1108      0.333000       0.154000           0.0   \n",
      "329019        0.1108      0.333000       0.154000           0.0   \n",
      "329020        0.1108      0.333000       0.154000           0.0   \n",
      "\n",
      "        domain_12_inv  domain_13_inv  domain_14_inv  \n",
      "0             0.00000       0.000000            0.0  \n",
      "1             0.00000       0.000000            0.0  \n",
      "2             0.48600       0.206000            0.0  \n",
      "3             0.47800       0.224000            0.0  \n",
      "4             0.46575       0.242000            0.0  \n",
      "...               ...            ...            ...  \n",
      "329016        0.87900       0.261833            0.0  \n",
      "329017        0.87075       0.263857            0.0  \n",
      "329018        0.81200       0.202500            0.0  \n",
      "329019        0.81200       0.202500            0.0  \n",
      "329020        0.78200       0.194500            0.0  \n",
      "\n",
      "[329021 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_weekly_df = filter_users_by_usage(\n",
    "    weekly_df,\n",
    "    min_sessions_per_week=min_sessions_per_week,\n",
    "    min_weeks=min_weeks,\n",
    "    require_consecutive=require_consecutive,\n",
    ")\n",
    "\n",
    "print(filtered_weekly_df.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf3941",
   "metadata": {},
   "source": [
    "## Data encoding: turn into model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairEncodedWindowDatasetWeek(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Dict[str, Any],\n",
    "        E_pairs: np.ndarray,     # [U, T, K, 2]\n",
    "        X_week: np.ndarray,      # [U, T, D_x]\n",
    "        Y: np.ndarray,           # [U, T, K]\n",
    "        M_target: np.ndarray,    # [U, T, K]\n",
    "        meta: Dict[str, Any],\n",
    "        actions: Optional[np.ndarray] = None,   # [U, T, Da] (optional)\n",
    "        statics: Optional[np.ndarray] = None,   # [U, Ds]   (optional)\n",
    "        user_time_slice: Optional[Dict[int, Tuple[int, int]]] = None,\n",
    "        drop_no_target: Optional[bool] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cfg = config\n",
    "        W = config[\"time\"][\"lookback_weeks\"]\n",
    "        self.window = W\n",
    "        self.horizon = 1\n",
    "\n",
    "        assert E_pairs.ndim == 4 and E_pairs.shape[-1] == 2\n",
    "        U, T, K, _ = E_pairs.shape\n",
    "        assert X_week.shape[:2] == (U, T)\n",
    "        assert Y.shape == M_target.shape == (U, T, K)\n",
    "\n",
    "        self.U, self.T, self.K = U, T, K\n",
    "        self.meta = meta\n",
    "\n",
    "        self.Dx = X_week.shape[2]\n",
    "        self.Dp = 2 * K\n",
    "        self.E_flat = E_pairs.reshape(U, T, self.Dp).astype(np.float32)\n",
    "        self.X_week = X_week.astype(np.float32)\n",
    "\n",
    "        pres = E_pairs[..., 0].astype(np.float32)\n",
    "        invv = E_pairs[..., 1].astype(np.float32)\n",
    "        self.Y_recon = pres * (1.0 - invv)   # [U,T,K]\n",
    "\n",
    "        self.Y = Y.astype(np.float32)\n",
    "        self.M = M_target.astype(np.float32)\n",
    "\n",
    "        self.actions = actions.astype(np.float32) if actions is not None else None\n",
    "        self.statics = statics.astype(np.float32) if statics is not None else None\n",
    "        self.Da = 0 if self.actions is None else self.actions.shape[2]\n",
    "        self.Ds = 0 if self.statics is None else self.statics.shape[1]\n",
    "\n",
    "        # Build anchor indices\n",
    "        self.indices: List[Tuple[int, int]] = []\n",
    "        weeks_per_user: List[pd.DatetimeIndex] = meta.get(\"weeks_per_user\", [pd.DatetimeIndex([]) for _ in range(U)])\n",
    "\n",
    "        drop_no_target = self.cfg[\"train\"][\"drop_no_target\"] if drop_no_target is None else drop_no_target\n",
    "        for u in range(U):\n",
    "            T_u = len(weeks_per_user[u])\n",
    "            if T_u == 0: continue\n",
    "            lo, hi = (0, T_u) if user_time_slice is None else user_time_slice.get(u, (0, T_u))\n",
    "            lo = max(lo, self.window)\n",
    "            hi = min(hi, T_u - self.horizon)\n",
    "            for t in range(lo, hi):\n",
    "                if drop_no_target and self.M[u, t, :].sum() < 1.0:\n",
    "                    continue\n",
    "                self.indices.append((u, t))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        u, t = self.indices[idx]\n",
    "        t0, t1 = t - self.window, t\n",
    "\n",
    "        y_hist = self.Y_recon[u, t0:t1, :]                                  # [W,K]\n",
    "        x_hist = np.concatenate([self.E_flat[u, t0:t1, :], self.X_week[u, t0:t1, :]], axis=-1)  # [W, 2K+D_x]\n",
    "\n",
    "        a_now = self.actions[u, t, :] if self.actions is not None else np.zeros((0,), dtype=np.float32)\n",
    "        s_static = self.statics[u, :]   if self.statics is not None else np.zeros((0,), dtype=np.float32)\n",
    "\n",
    "        y_next = np.nan_to_num(self.Y[u, t, :].copy(), nan=0.0)             # [K]\n",
    "        m_next = self.M[u, t, :].copy()\n",
    "\n",
    "        return {\n",
    "            \"y_hist\": torch.from_numpy(y_hist),\n",
    "            \"x_hist\": torch.from_numpy(x_hist),\n",
    "            \"a_now\": torch.from_numpy(a_now),\n",
    "            \"s_static\": torch.from_numpy(s_static),\n",
    "            \"user_idx\": torch.tensor(u, dtype=torch.long),\n",
    "            \"y_next\": torch.from_numpy(y_next),\n",
    "            \"m_next\": torch.from_numpy(m_next),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def dims(self) -> Dict[str, int]:\n",
    "        return {\n",
    "            \"U\": self.U,\n",
    "            \"K\": self.K,\n",
    "            \"Dx_total\": self.Dp + self.Dx,\n",
    "            \"Da\": self.Da,\n",
    "            \"Ds\": self.Ds,\n",
    "            \"W\": self.window,\n",
    "        }\n",
    "\n",
    "\n",
    "def build_time_slices_weekly(meta: Dict[str, Any], config: Dict[str, Any]) -> Dict[int, Dict[str, Tuple[int, int]]]:\n",
    "    train_frac = config[\"train\"][\"train_frac\"]\n",
    "    val_frac = config[\"train\"][\"val_frac\"]\n",
    "    slices: Dict[int, Dict[str, Tuple[int, int]]] = {}\n",
    "    for u, weeks in enumerate(meta[\"weeks_per_user\"]):\n",
    "        T_u = len(weeks)\n",
    "        if T_u == 0:\n",
    "            slices[u] = {\"train\": (0, 0), \"val\": (0, 0), \"test\": (0, 0)}\n",
    "            continue\n",
    "        i1 = int(np.floor(train_frac * T_u))\n",
    "        i2 = int(np.floor((train_frac + val_frac) * T_u))\n",
    "        slices[u] = {\"train\": (0, i1), \"val\": (i1, i2), \"test\": (i2, T_u)}\n",
    "    return slices\n",
    "\n",
    "\n",
    "def make_weekly_dataloaders(config: Dict[str, Any],\n",
    "                            E_pairs: np.ndarray, X_week: np.ndarray, Y: np.ndarray, M_target: np.ndarray, meta: Dict[str, Any],\n",
    "                            actions: Optional[np.ndarray] = None, statics: Optional[np.ndarray] = None):\n",
    "    slices = build_time_slices_weekly(meta, config)\n",
    "    ds_train = PairEncodedWindowDatasetWeek(config, E_pairs, X_week, Y, M_target, meta,\n",
    "                                            actions=actions, statics=statics,\n",
    "                                            user_time_slice={u: s[\"train\"] for u, s in slices.items()})\n",
    "    ds_val   = PairEncodedWindowDatasetWeek(config, E_pairs, X_week, Y, M_target, meta,\n",
    "                                            actions=actions, statics=statics,\n",
    "                                            user_time_slice={u: s[\"val\"] for u, s in slices.items()})\n",
    "    ds_test  = PairEncodedWindowDatasetWeek(config, E_pairs, X_week, Y, M_target, meta,\n",
    "                                            actions=actions, statics=statics,\n",
    "                                            user_time_slice={u: s[\"test\"] for u, s in slices.items()})\n",
    "    bs = config[\"train\"][\"batch_size\"]\n",
    "    dl_train = DataLoader(ds_train, batch_size=bs, shuffle=True)\n",
    "    dl_val   = DataLoader(ds_val,   batch_size=bs, shuffle=False)\n",
    "    dl_test  = DataLoader(ds_test,  batch_size=bs, shuffle=False)\n",
    "    return ds_train, ds_val, ds_test, dl_train, dl_val, dl_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5827d8",
   "metadata": {},
   "source": [
    "build cao map for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cao_mapping_from_weekly_encoding(config: Dict[str, Any], meta: Dict[str, Any]) -> Tuple[Dict[str, List[str]], int, List[str]]:\n",
    "    W = config[\"time\"][\"lookback_weeks\"]\n",
    "    domains: List[int] = list(meta[\"domains\"])\n",
    "    K = len(domains)\n",
    "    covs: List[str] = list(meta.get(\"x_week_feature_names\", []))\n",
    "\n",
    "    # Context (scores) with weekly lags 1..W\n",
    "    context_scores = [f\"score_domain_{d}_lag_{k}\" for k in range(1, W + 1) for d in domains]\n",
    "    # Optional extras (pair + covariates), if you want to name them for inspection\n",
    "    context_pair_presence = [f\"present_domain_{d}_lag_{k}\" for k in range(1, W + 1) for d in domains]\n",
    "    context_pair_inv1m    = [f\"inv1m_domain_{d}_lag_{k}\"  for k in range(1, W + 1) for d in domains]\n",
    "    context_covariates    = [f\"{feat}_lag_{k}\" for k in range(1, W + 1) for feat in covs]\n",
    "\n",
    "    # Final context (you can include only scores if you prefer)\n",
    "    context = list(context_scores) + context_pair_presence + context_pair_inv1m + context_covariates\n",
    "\n",
    "    # Actions: one per domain (binary selection), lag_0 convention\n",
    "    action_names = [f\"action_domain_{d}_lag_0\" for d in domains]\n",
    "    Da = len(action_names)  # == K\n",
    "    print(\"Da in build_cao_mapping_from_weekly_encoding:\", Da)\n",
    "\n",
    "    # Outcome: global or per-domain\n",
    "    if config[\"targets\"][\"outcome\"] == \"global\":\n",
    "        outcome = [\"global_score_next_week\"]\n",
    "    else:\n",
    "        outcome = [f\"score_domain_{d}_next_week\" for d in domains]\n",
    "\n",
    "    cao_mapping = {\"context\": context, \"actions\": action_names, \"outcome\": outcome}\n",
    "    return cao_mapping, Da, action_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7046e",
   "metadata": {},
   "source": [
    "Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33835e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build time-blocked slices per user (on weeks)\n",
    "slices = build_time_slices_weekly(meta, CONFIG)\n",
    "\n",
    "# Lookback window in *weeks* from CONFIG\n",
    "W = CONFIG[\"time\"][\"lookback_weeks\"]\n",
    "\n",
    "# Optional: if you have actions/statics arrays aligned to [U, T_weeks, Da] / [U, Ds],\n",
    "# pass them here; otherwise use None.\n",
    "statics = None   # or your np.ndarray\n",
    "\n",
    "# Datasets\n",
    "ds_train = PairEncodedWindowDatasetWeek(\n",
    "    config=CONFIG,\n",
    "    E_pairs=E_pairs,\n",
    "    X_week=X_week,\n",
    "    Y=Y,\n",
    "    M_target=M_target,\n",
    "    meta=meta,\n",
    "    actions=actions,\n",
    "    statics=statics,\n",
    "    user_time_slice={u: s[\"train\"] for u, s in slices.items()},\n",
    ")\n",
    "\n",
    "ds_val = PairEncodedWindowDatasetWeek(\n",
    "    config=CONFIG,\n",
    "    E_pairs=E_pairs,\n",
    "    X_week=X_week,\n",
    "    Y=Y,\n",
    "    M_target=M_target,\n",
    "    meta=meta,\n",
    "    actions=actions,\n",
    "    statics=statics,\n",
    "    user_time_slice={u: s[\"val\"] for u, s in slices.items()},\n",
    ")\n",
    "\n",
    "ds_test = PairEncodedWindowDatasetWeek(\n",
    "    config=CONFIG,\n",
    "    E_pairs=E_pairs,\n",
    "    X_week=X_week,\n",
    "    Y=Y,\n",
    "    M_target=M_target,\n",
    "    meta=meta,\n",
    "    actions=actions,\n",
    "    statics=statics,\n",
    "    user_time_slice={u: s[\"test\"] for u, s in slices.items()},\n",
    ")\n",
    "\n",
    "# DataLoaders use batch_size from CONFIG\n",
    "bs = CONFIG[\"train\"][\"batch_size\"]\n",
    "dl_train = DataLoader(ds_train, batch_size=bs, shuffle=True)\n",
    "dl_val   = DataLoader(ds_val,   batch_size=bs, shuffle=False)\n",
    "dl_test  = DataLoader(ds_test,  batch_size=bs, shuffle=False)\n",
    "\n",
    "print(\"Dataset dims:\", ds_train.dims)\n",
    "print(\"Train samples:\", len(ds_train), \"Val:\", len(ds_val), \"Test:\", len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target observation counts across train anchors (weekly)\n",
    "if len(ds_train) > 0:\n",
    "    m_counts = [int(ds_train.M[u, t].sum()) for (u, t) in ds_train.indices]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(m_counts, bins=np.arange(-0.5, ds_train.K + 1.5, 1))\n",
    "    plt.title(\"Observed domains per anchor (train, weekly)\")\n",
    "    plt.xlabel(\"# observed domains at target week\")\n",
    "    plt.ylabel(\"Count of anchors\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No training anchors available to visualize target observation counts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63dcaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cao_mapping, Da, action_names = build_cao_mapping_from_weekly_encoding(CONFIG, meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec60ae8f",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b611d2",
   "metadata": {},
   "source": [
    "Define predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalEncoderGRU(nn.Module):\n",
    "    def __init__(self, d_in: int, d_hidden: int = 128, num_layers: int = 1, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=d_in, hidden_size=d_hidden, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_hidden)\n",
    "\n",
    "    def forward(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        out, _ = self.gru(seq)\n",
    "        return self.layer_norm(out[:, -1, :])   # [B, d_hidden]\n",
    "\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, config: Dict[str, Any], K: int, Dx_total: int, Da: int, Ds: int, n_users: int):\n",
    "        super().__init__()\n",
    "        mcfg = config[\"model\"]\n",
    "        self.K = K\n",
    "        self.lowrank_r = int(mcfg[\"lowrank_r\"])\n",
    "\n",
    "        self.encoder = TemporalEncoderGRU(d_in=K + Dx_total,\n",
    "                                          d_hidden=mcfg[\"d_hidden\"],\n",
    "                                          num_layers=mcfg[\"enc_layers\"],\n",
    "                                          dropout=mcfg[\"dropout\"])\n",
    "\n",
    "        self.user_emb = None\n",
    "        uemb_dim = int(mcfg[\"user_embed_dim\"])\n",
    "        if uemb_dim > 0:\n",
    "            self.user_emb = nn.Embedding(n_users, uemb_dim)\n",
    "\n",
    "        head_in = mcfg[\"d_hidden\"] + Da + Ds + (uemb_dim if uemb_dim > 0 else 0)\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Linear(head_in, mcfg[\"trunk_hidden\"]), nn.ReLU(), nn.Dropout(mcfg[\"dropout\"]),\n",
    "            nn.Linear(mcfg[\"trunk_hidden\"], mcfg[\"trunk_hidden\"]), nn.ReLU(), nn.Dropout(mcfg[\"dropout\"])\n",
    "        )\n",
    "\n",
    "        self.mu_head    = nn.Linear(mcfg[\"trunk_hidden\"], K)\n",
    "        self.scale_head = nn.Linear(mcfg[\"trunk_hidden\"], K)\n",
    "        self.B_head     = nn.Linear(mcfg[\"trunk_hidden\"], K * self.lowrank_r) if self.lowrank_r > 0 else None\n",
    "\n",
    "    def forward(self, y_hist, x_hist, a_now, s_static, user_idx):\n",
    "        seq = torch.cat([y_hist, x_hist], dim=-1)              # [B, W, K+Dx_total]\n",
    "        h = self.encoder(seq)\n",
    "        parts = [h, a_now, s_static]\n",
    "        if self.user_emb is not None:\n",
    "            parts.append(self.user_emb(user_idx))\n",
    "        z = self.trunk(torch.cat(parts, dim=-1))\n",
    "\n",
    "        mu = self.mu_head(z)\n",
    "        sigma = F.softplus(self.scale_head(z)) + 1e-4\n",
    "\n",
    "        g_mu = mu.mean(dim=-1)\n",
    "        diag_term = (sigma ** 2).sum(dim=-1) / (self.K ** 2)\n",
    "        if self.B_head is not None:\n",
    "            B = self.B_head(z).view(-1, self.K, self.lowrank_r)\n",
    "            ones = torch.ones(self.K, device=B.device)\n",
    "            bsum = torch.einsum(\"bkr,k->br\", B, ones)\n",
    "            cross_term = (bsum ** 2).sum(dim=-1) / (self.K ** 2)\n",
    "            g_var = diag_term + cross_term\n",
    "        else:\n",
    "            B, g_var = None, diag_term\n",
    "\n",
    "        return {\"mu\": mu, \"sigma\": sigma, \"g_mu\": g_mu, \"g_var\": g_var, \"B\": B}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LossCfg:\n",
    "    lambda_scores: float = 1.0\n",
    "    lambda_g: float = 0.2\n",
    "    reduction: str = \"mean\"\n",
    "\n",
    "\n",
    "class PredictorLossMasked(nn.Module):\n",
    "    def __init__(self, cfg: LossCfg):\n",
    "        super().__init__()\n",
    "        assert cfg.reduction in (\"mean\", \"sum\")\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def forward(self, preds, y_true, m_true):\n",
    "        mu, sigma = preds[\"mu\"], torch.clamp(preds[\"sigma\"], min=1e-6)\n",
    "        log_sigma = torch.log(sigma)\n",
    "        nll_elem = 0.5 * (((y_true - mu) / sigma) ** 2 + 2.0 * log_sigma)\n",
    "        nll_masked = nll_elem * m_true\n",
    "        denom = m_true.sum().clamp_min(1e-8)\n",
    "        loss_scores = nll_masked.sum() / denom if self.cfg.reduction == \"mean\" else nll_masked.sum()\n",
    "\n",
    "        m_sum = m_true.sum(dim=-1).clamp_min(1.0)\n",
    "        g_true_obs = (y_true * m_true).sum(dim=-1) / m_sum\n",
    "        loss_g = F.mse_loss(preds[\"g_mu\"], g_true_obs, reduction=self.cfg.reduction)\n",
    "\n",
    "        loss = self.cfg.lambda_scores * loss_scores + self.cfg.lambda_g * loss_g\n",
    "        metrics = {\n",
    "            \"loss_scores\": loss_scores.detach(),\n",
    "            \"loss_g\": loss_g.detach(),\n",
    "            \"mae\": (torch.abs(mu - y_true) * m_true).sum() / denom,\n",
    "            \"g_mae\": torch.abs(preds[\"g_mu\"] - g_true_obs).mean(),\n",
    "        }\n",
    "        return loss, metrics\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config: Dict[str, Any], model: Predictor, loss_fn: PredictorLossMasked, device: Optional[str] = None):\n",
    "        self.cfg = config\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        tcfg = config[\"train\"]\n",
    "        self.optim = torch.optim.AdamW(self.model.parameters(), lr=tcfg[\"lr\"], weight_decay=tcfg[\"weight_decay\"])\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optim, T_max=tcfg[\"epochs\"])\n",
    "        self.grad_clip = tcfg[\"grad_clip\"]\n",
    "\n",
    "    def _to_device(self, batch: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        return {k: (v.to(self.device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
    "\n",
    "    def train_one_epoch(self, dl: DataLoader) -> Dict[str, float]:\n",
    "        self.model.train()\n",
    "        agg = {\"loss\": 0.0, \"mae\": 0.0, \"g_mae\": 0.0}; n = 0\n",
    "        for batch in dl:\n",
    "            b = self._to_device(batch)\n",
    "            preds = self.model(b[\"y_hist\"], b[\"x_hist\"], b[\"a_now\"], b[\"s_static\"], b[\"user_idx\"])\n",
    "            loss, metrics = self.loss_fn(preds, b[\"y_next\"], b[\"m_next\"])\n",
    "            self.optim.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\n",
    "            self.optim.step()\n",
    "            agg[\"loss\"] += float(loss.item())\n",
    "            agg[\"mae\"]  += float(metrics[\"mae\"].item())\n",
    "            agg[\"g_mae\"]+= float(metrics[\"g_mae\"].item())\n",
    "            n += 1\n",
    "        for k in agg: agg[k] /= max(n, 1)\n",
    "        self.scheduler.step()\n",
    "        return agg\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dl: DataLoader) -> Dict[str, float]:\n",
    "        self.model.eval()\n",
    "        agg = {\"loss\": 0.0, \"mae\": 0.0, \"g_mae\": 0.0}; n = 0\n",
    "        for batch in dl:\n",
    "            b = self._to_device(batch)\n",
    "            preds = self.model(b[\"y_hist\"], b[\"x_hist\"], b[\"a_now\"], b[\"s_static\"], b[\"user_idx\"])\n",
    "            loss, metrics = self.loss_fn(preds, b[\"y_next\"], b[\"m_next\"])\n",
    "            agg[\"loss\"] += float(loss.item())\n",
    "            agg[\"mae\"]  += float(metrics[\"mae\"].item())\n",
    "            agg[\"g_mae\"]+= float(metrics[\"g_mae\"].item())\n",
    "            n += 1\n",
    "        for k in agg: agg[k] /= max(n, 1)\n",
    "        return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778ddb7",
   "metadata": {},
   "source": [
    "Train predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7757226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "K = ds_train.dims[\"K\"]\n",
    "Dx_total = ds_train.dims[\"Dx_total\"]\n",
    "Da = ds_train.dims[\"Da\"]    # 0 unless you pass actions\n",
    "Ds = ds_train.dims[\"Ds\"]\n",
    "n_users = ds_train.dims[\"U\"]\n",
    "\n",
    "model = Predictor(CONFIG, K=K, Dx_total=Dx_total, Da=Da, Ds=Ds, n_users=n_users)\n",
    "loss_fn = PredictorLossMasked(LossCfg(lambda_scores=1.0, lambda_g=0.2))\n",
    "trainer = Trainer(CONFIG, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(CONFIG[\"train\"][\"epochs\"]):\n",
    "    tr = trainer.train_one_epoch(dl_train)\n",
    "    va = trainer.evaluate(dl_val)\n",
    "    print(f\"Epoch {epoch+1:02d} | train {tr['loss']:.4f} | val {va['loss']:.4f} | val gMAE {va['g_mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b06412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test metrics:\n",
    "te = trainer.evaluate(dl_test)\n",
    "print(\"TEST:\", te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f7cc6",
   "metadata": {},
   "source": [
    "## Prescriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d02a42a",
   "metadata": {},
   "source": [
    "Define zero prescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ZeroPrescriptor:\n",
    "    \"\"\"Always prescribes 0 for each intervention (one per domain).\"\"\"\n",
    "    n_interventions: int\n",
    "    action_names: Optional[List[str]] = field(default=None)\n",
    "\n",
    "    @classmethod\n",
    "    def from_cao_mapping(cls, mapping: Dict[str, List[str]]) -> \"ZeroPrescriptor\":\n",
    "        acts = list(mapping[\"actions\"])\n",
    "        return cls(n_interventions=len(acts), action_names=acts)\n",
    "\n",
    "    def prescribe(self, context_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        n = len(context_df)\n",
    "        zeros = np.zeros((n, self.n_interventions), dtype=int)\n",
    "        return pd.DataFrame(zeros, columns=self.action_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83129068",
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptor = ZeroPrescriptor.from_cao_mapping(cao_mapping)\n",
    "assert prescriptor.n_interventions == Da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd58082",
   "metadata": {},
   "source": [
    "## Unrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_predictor_weekly(\n",
    "    config: Dict[str, Any],\n",
    "    model,                               # trained Predictor (PyTorch)\n",
    "    prescriptor: ZeroPrescriptor,\n",
    "    E_pairs: np.ndarray,                 # [U, T, K, 2]\n",
    "    X_week: np.ndarray,                  # [U, T, D_x]\n",
    "    meta: Dict[str, Any],\n",
    "    user_idx: int,\n",
    "    statics_row: Optional[np.ndarray] = None,  # [Ds] or None\n",
    "    device: Optional[str] = None,\n",
    ") -> Tuple[pd.DataFrame, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Weekly unroll for `lookahead_weeks`: predict next week, treat it as observed, append, and repeat.\n",
    "    Returns:\n",
    "      pred_df: DataFrame with week_start and per-domain predicted scores + global_score\n",
    "      pred_scores: (lookahead_weeks, K)\n",
    "      pred_actions: (lookahead_weeks, Da) (zeros)\n",
    "    \"\"\"\n",
    "    W = config[\"time\"][\"lookback_weeks\"]\n",
    "    H = config[\"time\"][\"lookahead_weeks\"]\n",
    "    week_freq = meta[\"week_freq\"]\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval(); model.to(device)\n",
    "\n",
    "    U, T, K, _ = E_pairs.shape\n",
    "    D_x = X_week.shape[2]\n",
    "    Dx_total = 2 * K + D_x\n",
    "\n",
    "    E_u = E_pairs[user_idx].copy()     # [T, K, 2]\n",
    "    X_u = X_week[user_idx].copy()      # [T, D_x]\n",
    "    weeks_u: pd.DatetimeIndex = meta[\"weeks_per_user\"][user_idx]\n",
    "    if len(weeks_u) < W:\n",
    "        raise ValueError(f\"User {user_idx} has only {len(weeks_u)} weeks; need at least lookback={W}.\")\n",
    "\n",
    "    Da = len(getattr(prescriptor, \"action_names\", []))\n",
    "    pred_scores = np.zeros((H, K), dtype=np.float32)\n",
    "    pred_actions = np.zeros((H, Da), dtype=np.float32)\n",
    "\n",
    "    domain_cols = [f\"domain_{d}\" for d in meta[\"domains\"]]\n",
    "    out_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    # last week_start\n",
    "    last_week = pd.Timestamp(weeks_u[-1])\n",
    "    last_x_cov = X_u[-1, :].copy()\n",
    "\n",
    "    if statics_row is not None:\n",
    "        s_static = torch.from_numpy(statics_row.reshape(1, -1)).float().to(device)\n",
    "    else:\n",
    "        s_static = torch.zeros((1, 0), dtype=torch.float32, device=device)\n",
    "\n",
    "    for step in range(H):\n",
    "        t_end = E_u.shape[0]\n",
    "        t0, t1 = t_end - W, t_end\n",
    "        # Build window tensors\n",
    "        pres_win = E_u[t0:t1, :, 0]\n",
    "        inv_win  = E_u[t0:t1, :, 1]\n",
    "        y_hist_np = pres_win * (1.0 - inv_win)                   # [W,K]\n",
    "        E_flat_win = E_u[t0:t1].reshape(W, 2 * K)                # [W,2K]\n",
    "        x_hist_np = np.concatenate([E_flat_win, X_u[t0:t1, :]], axis=-1)  # [W, 2K + D_x]\n",
    "\n",
    "        y_hist = torch.from_numpy(y_hist_np).unsqueeze(0).float().to(device)\n",
    "        x_hist = torch.from_numpy(x_hist_np).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # Zero actions for next week\n",
    "        context_df = pd.DataFrame({\"week_start\": [last_week + pd.offsets.Week(1, weekday=0)]})\n",
    "        presc_df = prescriptor.prescribe(context_df)  # zeros\n",
    "        if Da > 0:\n",
    "            a_now_np = presc_df.iloc[0].to_numpy(dtype=np.float32).reshape(1, Da)\n",
    "            pred_actions[step, :] = a_now_np[0]\n",
    "            a_now = torch.from_numpy(a_now_np).float().to(device)\n",
    "        else:\n",
    "            a_now = torch.zeros((1, 0), dtype=torch.float32, device=device)\n",
    "\n",
    "        user_idx_t = torch.tensor([user_idx], dtype=torch.long, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(y_hist, x_hist, a_now, s_static, user_idx_t)\n",
    "            y_hat = np.clip(preds[\"mu\"].squeeze(0).cpu().numpy(), 0.0, 1.0)   # [K]\n",
    "            pred_scores[step, :] = y_hat\n",
    "\n",
    "        # Append next week as observed\n",
    "        next_week = last_week + pd.Timedelta(days=7)\n",
    "        next_pairs = np.stack([np.ones(K, dtype=np.float32), 1.0 - y_hat.astype(np.float32)], axis=-1)  # [K,2]\n",
    "        E_u = np.concatenate([E_u, next_pairs.reshape(1, K, 2)], axis=0)\n",
    "\n",
    "        # Advance covariates\n",
    "        next_x_cov = advance_weekly_covariates(last_x_cov)\n",
    "        X_u = np.concatenate([X_u, next_x_cov.reshape(1, D_x)], axis=0)\n",
    "\n",
    "        # Output row\n",
    "        row = {\"week_start\": next_week}\n",
    "        row.update({c: v for c, v in zip(domain_cols, y_hat.tolist())})\n",
    "        row[\"global_score\"] = float(np.mean(y_hat))\n",
    "        out_rows.append(row)\n",
    "\n",
    "        last_week = next_week\n",
    "        last_x_cov = next_x_cov\n",
    "\n",
    "    pred_df = pd.DataFrame(out_rows, columns=[\"week_start\"] + domain_cols + [\"global_score\"])\n",
    "    return pred_df, pred_scores, pred_actions\n",
    "\n",
    "\n",
    "# ---------- Wiring the CAO mapping + prescriptor ----------\n",
    "# After preprocessing:\n",
    "# cao_mapping, Da, action_names = build_cao_mapping_from_weekly_encoding(CONFIG, meta)\n",
    "# model.cao_mapping = cao_mapping  # optional: for compatibility with utilities\n",
    "# prescriptor = ZeroPrescriptor.from_cao_mapping(cao_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly choose a user to project\n",
    "user_idx = np.random.choice(valid_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) last week from history\n",
    "weeks_u = meta[\"weeks_per_user\"][user_idx]\n",
    "last_hist_week = weeks_u[-1]\n",
    "print(\"Last history week:\", last_hist_week)\n",
    "\n",
    "# 2) get unrolled future\n",
    "pred_df, pred_scores, pred_actions = unroll_predictor_weekly(\n",
    "    config=CONFIG,\n",
    "    model=model,\n",
    "    prescriptor=prescriptor,\n",
    "    E_pairs=E_pairs,\n",
    "    X_week=X_week,\n",
    "    meta=meta,\n",
    "    user_idx=user_idx,\n",
    "    statics_row=None,    # or statics[user_idx] if you have statics\n",
    ")\n",
    "\n",
    "print(pred_df.head())\n",
    "future_weeks = pd.to_datetime(pred_df[\"week_start\"])\n",
    "print(\"First unrolled week:\", future_weeks.iloc[0])\n",
    "\n",
    "print(\"All future weeks > last history week?\",\n",
    "      bool((future_weeks > last_hist_week).all()))\n",
    "\n",
    "print(\"pred_scores shape:\", pred_scores.shape)   # (lookahead_days, K)\n",
    "print(\"pred_actions shape:\", pred_actions.shape) # (lookahead_days, Da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a518950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot global trajectory\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(pred_df[\"week_start\"], pred_df[\"global_score\"], marker=\"o\")\n",
    "plt.title(f\"User {meta['users'][user_idx]} — unrolled global score (zero actions)\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Global score (mean of domains)\")\n",
    "plt.xticks(rotation=45); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c0eae",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_user_weekly_trajectory(\n",
    "    config: Dict[str, Any],\n",
    "    model,\n",
    "    E_pairs: np.ndarray,           # [U, T_max, K, 2]\n",
    "    X_week: np.ndarray,            # [U, T_max, D_x]\n",
    "    Y: np.ndarray,                 # [U, T_max, K]\n",
    "    M_target: np.ndarray,          # [U, T_max, K]\n",
    "    meta: Dict[str, Any],\n",
    "    prescriptor,\n",
    "    statics: Optional[np.ndarray] = None,  # [U, Ds] or None\n",
    "    user_idx: Optional[int] = None,\n",
    "    device: Optional[str] = None,\n",
    "):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    W = config[\"time\"][\"lookback_weeks\"]\n",
    "    H = config[\"time\"][\"lookahead_weeks\"]\n",
    "\n",
    "    users = meta[\"users\"]\n",
    "    weeks_per_user = meta[\"weeks_per_user\"]\n",
    "\n",
    "    # --- choose a valid user if not specified ---\n",
    "    if user_idx is None:\n",
    "        valid_candidates = [\n",
    "            u for u, weeks in enumerate(weeks_per_user)\n",
    "            if len(weeks) >= W + 1\n",
    "        ]\n",
    "        if not valid_candidates:\n",
    "            raise ValueError(f\"No users with at least {W+1} weeks of history.\")\n",
    "        user_idx = int(np.random.choice(valid_candidates))\n",
    "\n",
    "    weeks_u = weeks_per_user[user_idx]\n",
    "    T_u = len(weeks_u)\n",
    "    if T_u < W + 1:\n",
    "        raise ValueError(f\"User {user_idx} has only {T_u} weeks; need at least {W+1}.\")\n",
    "\n",
    "    # Slice per-user tensors to their valid length T_u\n",
    "    E_u = E_pairs[user_idx, :T_u]       # [T_u, K, 2]\n",
    "    X_u = X_week[user_idx, :T_u]        # [T_u, D_x]\n",
    "    Y_u = Y[user_idx, :T_u]             # [T_u, K]\n",
    "    M_u = M_target[user_idx, :T_u]      # [T_u, K]\n",
    "\n",
    "    # replace Y_u nans with 0 for computation\n",
    "    Y_u = np.nan_to_num(Y_u, nan=0.0)\n",
    "\n",
    "    # --- Ground truth global score per week ---\n",
    "    m_sum = M_u.sum(axis=1)  # [T_u]\n",
    "    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "        g_truth = np.where(m_sum > 0, (Y_u * M_u).sum(axis=1) / m_sum, np.nan)\n",
    "\n",
    "    # --- In-sample predictions (one-step ahead) ---\n",
    "    pred_in_sample = np.full(T_u, np.nan, dtype=np.float32)\n",
    "\n",
    "    Ds = 0 if statics is None else statics.shape[1]\n",
    "    if Ds > 0:\n",
    "        s_static_row = statics[user_idx].reshape(1, Ds)\n",
    "        s_static_t = torch.from_numpy(s_static_row).float().to(device)\n",
    "    else:\n",
    "        s_static_t = torch.zeros((1, 0), dtype=torch.float32, device=device)\n",
    "\n",
    "    Da = len(getattr(prescriptor, \"action_names\", []))\n",
    "\n",
    "    for t in range(W, T_u):\n",
    "        t0, t1 = t - W, t\n",
    "        # reconstruct y_hist and x_hist for [t-W, ..., t-1]\n",
    "        pres_win = E_u[t0:t1, :, 0]                    # [W, K]\n",
    "        inv_win  = E_u[t0:t1, :, 1]\n",
    "        y_hist_np = pres_win * (1.0 - inv_win)         # [W, K]\n",
    "\n",
    "        E_flat_win = E_u[t0:t1].reshape(W, -1)         # [W, 2K]\n",
    "        x_hist_np  = np.concatenate([E_flat_win, X_u[t0:t1, :]], axis=-1)  # [W, 2K + D_x]\n",
    "\n",
    "        y_hist = torch.from_numpy(y_hist_np).unsqueeze(0).float().to(device)\n",
    "        x_hist = torch.from_numpy(x_hist_np).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # action at week t: for now, zero (or derived from M_target if you want)\n",
    "        if Da > 0:\n",
    "            a_now_np = np.zeros((1, Da), dtype=np.float32)\n",
    "            a_now = torch.from_numpy(a_now_np).float().to(device)\n",
    "        else:\n",
    "            a_now = torch.zeros((1, 0), dtype=torch.float32, device=device)\n",
    "\n",
    "        user_idx_t = torch.tensor([user_idx], dtype=torch.long, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(y_hist, x_hist, a_now, s_static_t, user_idx_t)\n",
    "            g_hat = float(preds[\"g_mu\"].item())\n",
    "        pred_in_sample[t] = g_hat\n",
    "\n",
    "    # --- Unrolled future predictions (beyond T_u) ---\n",
    "    # This uses your unroll_predictor_weekly helper\n",
    "    pred_df_future, pred_scores_future, pred_actions_future = unroll_predictor_weekly(\n",
    "        config=config,\n",
    "        model=model,\n",
    "        prescriptor=prescriptor,\n",
    "        E_pairs=E_pairs,\n",
    "        X_week=X_week,\n",
    "        meta=meta,\n",
    "        user_idx=user_idx,\n",
    "        statics_row=None if statics is None else statics[user_idx],\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Expect a 'week_start' column in pred_df_future\n",
    "    future_weeks = pd.to_datetime(pred_df_future[\"week_start\"].values)\n",
    "    g_future = pred_df_future[\"global_score\"].to_numpy(dtype=float)\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Ground truth\n",
    "    plt.plot(weeks_u, g_truth, marker=\"o\", linestyle=\"-\", label=\"Ground truth (global, weekly)\")\n",
    "\n",
    "    # In-sample predictions\n",
    "    plt.plot(weeks_u, pred_in_sample, marker=\"x\", linestyle=\"--\", label=\"Predictions (in-sample)\")\n",
    "\n",
    "    # Unrolled future\n",
    "    plt.plot(future_weeks, g_future, marker=\"s\", linestyle=\"-.\", label=\"Unrolled predictions (future)\")\n",
    "\n",
    "    # Mark where ground truth ends\n",
    "    plt.axvline(weeks_u[-1], color=\"k\", linestyle=\":\", linewidth=1.5, label=\"End of ground truth\")\n",
    "\n",
    "    plt.title(f\"User {users[user_idx]} — Weekly performance and predictions\")\n",
    "    plt.xlabel(\"Week\")\n",
    "    plt.ylabel(\"Global score (mean of domains)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea651fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = np.random.choice(valid_users)\n",
    "\n",
    "visualize_user_weekly_trajectory(\n",
    "    config=CONFIG,\n",
    "    model=model,\n",
    "    E_pairs=E_pairs,\n",
    "    X_week=X_week,\n",
    "    Y=Y,\n",
    "    M_target=M_target,\n",
    "    meta=meta,\n",
    "    prescriptor=prescriptor,\n",
    "    statics=statics,\n",
    "    user_idx=user_idx,\n",
    "    device=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_user_ground_truth(user_idx, Y, M_target, meta):\n",
    "    \"\"\"\n",
    "    Print and return the ground truth weekly scores for a given user_idx.\n",
    "    \"\"\"\n",
    "    weeks_u = meta[\"weeks_per_user\"][user_idx]\n",
    "    T_u = len(weeks_u)\n",
    "\n",
    "    y_u = Y[user_idx, :T_u, :]        # [T_u, K]\n",
    "    m_u = M_target[user_idx, :T_u, :] # [T_u, K]\n",
    "\n",
    "    # replace y_u nans with 0 for computation\n",
    "    y_u = np.nan_to_num(y_u, nan=0.0)\n",
    "\n",
    "    # per-week number of observed domains\n",
    "    m_sum = m_u.sum(axis=1)\n",
    "\n",
    "    # global weekly score\n",
    "    g_truth = np.where(\n",
    "        m_sum > 0,\n",
    "        (y_u * m_u).sum(axis=1) / m_sum,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"week_start\": weeks_u,\n",
    "        \"n_observed_domains\": m_sum,\n",
    "        \"global_score\": g_truth,\n",
    "    })\n",
    "\n",
    "    # list of domains observed in each week\n",
    "    df[\"observed_domains\"] = [\n",
    "        [k for k in range(y_u.shape[1]) if m_u[t, k] == 1]\n",
    "        for t in range(T_u)\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n=== User {meta['users'][user_idx]} (index: {user_idx}) ===\")\n",
    "    print(f\"Total weeks: {T_u}\")\n",
    "    print(f\"Weeks with any domain observed: {df['n_observed_domains'].gt(0).sum()}\")\n",
    "    print(df.head(20))\n",
    "\n",
    "    return df, y_u, m_u, g_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799373c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y_u, m_u, g_truth = inspect_user_ground_truth(user_idx, Y, M_target, meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
