{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib_venn as venn\n",
    "from helper import *\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables\n",
    "time_period = (1, 2, 3, 4, 5) # 5 different implementation of progression order  \n",
    "n_patients = 0 # number of patients included in the model  \n",
    "n_sessions = 0 # number of sessions included in the model  \n",
    "usage_time: how many months the patient has been using the app  \n",
    "usage_freq: how frequent the patient uses the app  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying from the SQL database, 2 mins for q3 table\n",
    "\n",
    "from connection import *\n",
    "\n",
    "con = connect()\n",
    "df = SQL(\"select * from constant_therapy.q3\", con)\n",
    "df = df.rename(columns={'session_id':\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min, data saved from previous runs\n",
    "df = pd.read_csv(\"data/context_action.csv\")\n",
    "df.drop(df.columns[[0, 1]], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 seconds\n",
    "disorder_ids = df.groupby(\"patient_id\")[\"disorder_id\"].apply(set).reset_index()\n",
    "df = df.drop(columns=\"disorder_id\")\n",
    "df = df.merge(disorder_ids, on=\"patient_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min\n",
    "domain_ids = df.groupby(\"id\")[\"domain_id\"].apply(set).reset_index()\n",
    "df = df.drop(columns=\"domain_id\")\n",
    "df = df.merge(domain_ids, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/consolidate_data.csv\")\n",
    "## careful when reading, will read set as string\n",
    "# df = pd.read_csv(\"data/consolidate_data.csv\", index_col=[0])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data has been consolidated, there should be no duplicate sessions for different disorders/domains.\n",
    "We want to add time_period, usage_time, and usage_freq to the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This part doesn't need to be run if it's claire's data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progression_order_df = pd.read_csv(\"data/progression_order.csv\", index_col=[0])\n",
    "progression_order_df.rename(columns={'time_implemented':'end_time'}, inplace=True)\n",
    "progression_order_df[\"end_time\"] = pd.to_datetime(progression_order_df[\"end_time\"])\n",
    "df[\"end_time\"] = pd.to_datetime(df[\"end_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_period_convert(dd):\n",
    "    dates = sorted(pd.unique(progression_order_df[\"end_time\"]))\n",
    "    if dd < pd.to_datetime(dates[1]):\n",
    "        return 1\n",
    "    elif dd < pd.to_datetime(dates[2]):\n",
    "        return 2\n",
    "    elif dd < pd.to_datetime(dates[3]):\n",
    "        return 3\n",
    "    elif dd < pd.to_datetime(dates[4]):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added time period, takes around 8-9 minutes to run\n",
    "df[\"time_period\"] = df[\"end_time\"].apply(time_period_convert)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progression_order_df[\"time_period\"] = progression_order_df[\"end_time\"].apply(time_period_convert)\n",
    "progression_order_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Usage Time\n",
    "* this is by patient\n",
    "* need a patient dataframe vs session dataframe (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"end_time\"] = pd.to_datetime(df[\"end_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = (df.groupby(\"patient_id\")[\"end_time\"].max() - df.groupby(\"patient_id\")[\"end_time\"].min()).reset_index()\n",
    "patients.columns = [\"patient_id\", \"usage_time\"]\n",
    "patients[\"usage_time\"] = patients[\"usage_time\"].dt.days + 1\n",
    "patients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add usage_freq for patient dataframe\n",
    "* using the simplest way of calculating frequency\n",
    "* how to get rid of outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[\"session_count\"] = df.groupby(\"patient_id\")[\"id\"].count().reset_index(name=\"session_count\")[\"session_count\"]\n",
    "patients[\"unique_days\"] = df.groupby(\"patient_id\")[\"end_time\"].nunique().reset_index(name=\"days\")[\"days\"]\n",
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients[\"usage_freq\"] = patients[\"unique_days\"] / patients[\"usage_time\"]\n",
    "patients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://stackoverflow.com/questions/56750841/how-to-trim-outliers-in-dates-in-python\n",
    "def datetime_outlier(data):\n",
    "    qa = data[\"end_time\"].quantile(0.1) #lower 10%\n",
    "    qb = data[\"end_time\"] #higher 10%\n",
    "    #remove outliers\n",
    "    xf = data[(data.end_time >= qa) & (data.end_time <= qb)]\n",
    "    return xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about a min\n",
    "patients_v2 = df.groupby(\"patient_id\").apply(datetime_outlier).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_filtered = (patients_v2.groupby(\"patient_id\")[\"end_time\"].max() - patients_v2.groupby(\"patient_id\")[\"end_time\"].min()).reset_index()\n",
    "patients_filtered.columns = [\"patient_id\", \"usage_time\"]\n",
    "patients_filtered[\"usage_time\"] = patients_filtered[\"usage_time\"].dt.days + 1\n",
    "patients_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_filtered[\"session_count\"] = patients_v2.groupby(\"patient_id\")[\"id\"].count().reset_index(name=\"session_count\")[\"session_count\"]\n",
    "patients_filtered[\"unique_days\"] = patients_v2.groupby(\"patient_id\")[\"end_time\"].nunique().reset_index(name=\"days\")[\"days\"]\n",
    "patients_filtered[\"usage_freq\"] = patients_filtered[\"unique_days\"] / patients_filtered[\"usage_time\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the length of patients_filtered is less than the length of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERACT\n",
    "Filter seems to work for time outlier, so we using patient_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact to figure out what thresholds to use\n",
    "\n",
    "@widgets.interact_manual(usage_time=(1, 365), usage_freq=(0.0, 1.0))\n",
    "def visualize(usage_time, usage_freq):\n",
    "    temp = patients_filtered[patients_filtered.usage_time > usage_time]\n",
    "    temp = temp[temp.usage_freq > usage_freq]\n",
    "    return \"number of patients: %d\" %(temp[\"patient_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the according filtered patients dataframe\n",
    "\n",
    "usage_time = input(\"usage time: \")\n",
    "print(\"inputted \", usage_time)\n",
    "usage_freq = input(\"usage_freq: \")\n",
    "print(\"inputted \", usage_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_patients_list = patients_filtered[patients_filtered.usage_time > float(usage_time)]\n",
    "filtered_patients_list = filtered_patients_list[filtered_patients_list.usage_freq > float(usage_freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_patients_list.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filtered session dataframe from filtered patients data\n",
    "temp_lst = filtered_patients_list[\"patient_id\"]\n",
    "sessions_filter_df = df[df.patient_id.isin(temp_lst)]\n",
    "sessions_filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter based on time_period\n",
    "time_period_n = input(\"time period: \")\n",
    "sessions_filter_df = sessions_filter_df[sessions_filter_df.time_period == int(time_period_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions_filter_df.to_csv(\"data/PLACEHOLDER.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_filter_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the filtered dataframe, we want to start performance metric calculation\n",
    "* add progression order  \n",
    "**for now**  \n",
    "* calculate percentile of each session for each domain\n",
    "* for each patient, average percentile value across all domains **at the time**, which is our final performance metric calculation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part doesn not need to be run if it's claire's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand sessions due to compressed domain\n",
    "sessions_filter_df.explode(\"domain_id\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progression_order_df[progression_order_df.time_period == int(time_period_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_filter_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_to_int(s):\n",
    "    return s.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_filter_df[\"domain_id\"] = sessions_filter_df[\"domain_id\"].apply(set_to_int)\n",
    "sessions_filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add progression order\n",
    "sessions_filter_df = sessions_filter_df.merge(progression_order_df[progression_order_df.time_period == int(time_period_n)], on=[\"task_type_id\", \"task_level\", \"domain_id\"]).reset_index()\n",
    "sessions_filter_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentile of a domain\n",
    "def get_percentile(data):\n",
    "    data[\"percentile\"] = data[\"progression_order\"].rank(pct=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get percentile for each domain\n",
    "df_pct = sessions_filter_df.groupby(\"domain_id\").apply(get_percentile).reset_index(drop=True)\n",
    "df_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean dataframe, does not need to be run if Claire's data\n",
    "df_pct.drop(df_pct.columns[[0, 11, 16, 17, 19, 20]], axis=1, inplace=True)\n",
    "df_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pct.to_csv(\"data/raw_percentile.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in individual dataframe and output dataframe with overall performance metric\n",
    "def get_score(data):\n",
    "    updated_domain_pct = dict() # keeps updated domain pct\n",
    "    score = 0 # score for each session, an average of all available domains\n",
    "    scores = []\n",
    "\n",
    "    data = data.sort_values(by=\"end_time_min\").reset_index() # sort data by time\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        updated_domain_pct[row[\"domain_id\"]] = row[\"percentile\"] # update domain pct to the latest one\n",
    "        # find sum of all domain pct\n",
    "        for k, v in updated_domain_pct.items():\n",
    "            score += float(v)\n",
    "        # take average of domain pct, add to list, reset score to 0\n",
    "        score /= len(updated_domain_pct)\n",
    "        scores.append(score)\n",
    "        score = 0\n",
    "    # set score to the score list\n",
    "    data[\"score\"] = scores\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get performance metric by each patient for each session\n",
    "final_df = df_pct.groupby(\"patient_id\").apply(get_score).reset_index(drop=True)\n",
    "final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "* right now there are duplicate sessions since domain percentile was calulated separately, how do we feed this to the model?\n",
    "* task changes visualization -> try to explain the fluctuations\n",
    "* add overall timeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* update only the domains that have been practiced\n",
    "* keep other domains constant\n",
    "* how much they switch domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pid = random.choice(pd.unique(final_df[\"patient_id\"]))\n",
    "print(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = 57896\n",
    "sns.scatterplot(data=final_df[final_df.patient_id == pid], x=\"end_time_min\", y=\"score\", hue=\"domain_id\", palette=\"bright\").set_title(pid)\n",
    "plt.plot(final_df[final_df.patient_id == pid][\"end_time_min\"], final_df[final_df.patient_id == pid][\"score\"], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=final_df[final_df.patient_id == pid], x=\"end_time_min\", y=\"progression_order\", hue=\"domain_id\", palette=\"bright\").set_title(pid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second metric calculation:\n",
    "* keep other domains constant \n",
    "* how do we start off each domain -> average of when people first start out or just average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: average across all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct.groupby(\"domain_id\")[\"percentile\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in individual dataframe and output dataframe with overall performance metric\n",
    "def get_score_avg(data):\n",
    "    # initialize score with average\n",
    "    score = [0.5 for i in range(14)]\n",
    "    scores = []\n",
    "    \n",
    "\n",
    "    data = data.sort_values(by=\"end_time_min\") # sort data by time\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        score[row[\"domain_id\"] - 1] = row[\"percentile\"]\n",
    "        # set score to the score list average\n",
    "        scores.append(sum(score) / len(score))\n",
    "    data[\"score\"] = scores\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get performance metric by each patient for each session\n",
    "avg_final_df = df_pct.groupby(\"patient_id\").apply(get_score_avg).reset_index(drop=True)\n",
    "avg_final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pid = random.choice(pd.unique(avg_final_df[\"patient_id\"]))\n",
    "print(pid)\n",
    "sns.scatterplot(data=avg_final_df[avg_final_df.patient_id == pid], x=\"end_time_min\", y=\"score\", hue=\"domain_id\", palette=\"bright\").set_title(pid)\n",
    "plt.plot(avg_final_df[avg_final_df.patient_id == pid][\"end_time_min\"], avg_final_df[avg_final_df.patient_id == pid][\"score\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second average method: average starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_avg = df_pct.sort_values(by=\"end_time_min\")\n",
    "domain_avg = domain_avg.drop_duplicates(subset=[\"patient_id\", \"domain_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_avg[\"domain_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(domain_avg.groupby(\"domain_id\")[\"percentile\"].mean().reset_index()[\"percentile\"])\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in individual dataframe and output dataframe with overall performance metric\n",
    "def get_score_avg2(data):\n",
    "    # initialize score with average\n",
    "    global lst\n",
    "    score = lst\n",
    "    scores = []\n",
    "    \n",
    "    data = data.sort_values(by=\"end_time_min\") # sort data by time\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        score[row[\"domain_id\"] - 1] = row[\"percentile\"]\n",
    "        # set score to the score list average\n",
    "        scores.append(sum(score) / len(score))\n",
    "    data[\"score\"] = scores\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get performance metric by each patient for each session\n",
    "avg_final_df2 = df_pct.groupby(\"patient_id\").apply(get_score_avg2).reset_index(drop=True)\n",
    "avg_final_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pid = random.choice(pd.unique(avg_final_df2[\"patient_id\"]))\n",
    "\n",
    "print(pid)\n",
    "sns.scatterplot(data=avg_final_df2[avg_final_df2.patient_id == pid], x=\"end_time_min\", y=\"score\", hue=\"domain_id\", palette=\"bright\").set_title(pid)\n",
    "plt.plot(avg_final_df2[avg_final_df2.patient_id == pid][\"end_time_min\"], avg_final_df2[avg_final_df2.patient_id == pid][\"score\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_pct.sort_values(by=\"end_time_min\")\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial score\n",
    "initial = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"domain %d score\" % i for i in range(1, 15)]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create domain score columns, input a patient's session data\n",
    "def create_domain_scores(data):\n",
    "    global initial\n",
    "    global column_names\n",
    "    score = initial\n",
    "    data = data.sort_values(by=\"end_time_min\").reset_index() # sort data by time\n",
    "    scores = np.zeros((len(data), 14))\n",
    "    i = 0\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        score[row[\"domain_id\"] - 1] = row[\"percentile\"]\n",
    "        # set score to the score list average\n",
    "        scores[i] = score\n",
    "        i += 1\n",
    "    data = pd.concat([data, pd.DataFrame(scores, columns=column_names)], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = sorted_df.groupby(\"patient_id\").apply(create_domain_scores).reset_index(drop=True)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomralize scores\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scores only df\n",
    "scores_df_minmax = MinMaxScaler().fit_transform(scores_df[column_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_df = scores_df\n",
    "minmax_df[column_names] = scores_df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_df['score'] = minmax_df[column_names].mean(axis=1)\n",
    "minmax_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_final_df2[avg_final_df2.patient_id == pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_df[minmax_df.patient_id == pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pid = random.choice(pd.unique(minmax_df[\"patient_id\"]))\n",
    "print(pid)\n",
    "sns.scatterplot(data=minmax_df[minmax_df.patient_id == pid], x=\"end_time_min\", y=\"score\", hue=\"domain_id\", palette=\"bright\").set_title(pid)\n",
    "plt.plot(minmax_df[minmax_df.patient_id == pid][\"end_time_min\"], minmax_df[minmax_df.patient_id == pid][\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = minmax_df[minmax_df.patient_id == pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=temp, x=\"start_time_min\", y=\"score\", hue=\"domain_id\", palette=\"bright\").set_title(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=temp, x=\"start_time_min\", y=\"progression_order\", hue=\"domain_id\", palette=\"bright\").set_title(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.sort_values(by=\"start_time_min\")\n",
    "sns.lineplot(data=temp[temp.task_type_id == 11], x=\"start_time_min\", y=\"progression_order\").set_title(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[[\"domain_id\", \"task_type_id\", \"task_level\", \"score\", \"progression_order\", \"domain 14 score\", \"end_time_min\", \"id\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create day-to-day score -> combine sessions of the same domain -> average that then average across domains -> one score for each day instead of each session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out fluctations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return false if there's fluctation given a person's data\n",
    "def fluctate(data):\n",
    "    data = data.sort_values(by=\"end_time_min\").reset_index() # sort data by time\n",
    "    d = dict()\n",
    "    for idx, row in data.iterrows():\n",
    "        if row[\"start_time\"] not in d:\n",
    "            d[row[\"start_time\"]] = [row[\"domain_id\"]]\n",
    "        else:\n",
    "            if row[\"domain_id\"] in d[row[\"start_time\"]]:\n",
    "                return False\n",
    "            else:\n",
    "                d[row[\"start_time\"]].append(row[\"domain_id\"])\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_lst = minmax_df.groupby(\"patient_id\").apply(fluctate).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_lst = filter_lst.rename(columns={0: \"a\"})\n",
    "filter_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_lst[filter_lst.a][\"patient_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flutuate_data = minmax_df.loc[minmax_df[\"patient_id\"].isin(filter_lst[filter_lst.a][\"patient_id\"])].reset_index()\n",
    "flutuate_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering doesn't seem to work, work on incorporating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_score(row):\n",
    "    score = None\n",
    "    p = [1.05, 1.0, 0.9, 0.8]\n",
    "    if row.accuracy > .90:\n",
    "        score = row.percentile * p[0]\n",
    "    elif row.accuracy > .60:\n",
    "        score = row.percentile * p[1]\n",
    "    elif row.accuracy > .40:\n",
    "        score = row.percentile * p[2]\n",
    "    else:\n",
    "        score = row.percentile * p[3]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 seconds\n",
    "df_pscore = df_pct.copy(deep=True)\n",
    "df_pscore[\"percentile\"] = df_pscore.apply(new_score, axis=1)\n",
    "df_pscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(data):\n",
    "    data = data.sort_values(by=\"end_time_min\").reset_index() # sort data by time\n",
    "    return data.groupby([\"domain_id\", \"start_time\"])[\"percentile\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create domain score columns, input a patient's session data\n",
    "def create_domain_scores2(data):\n",
    "    global initial\n",
    "    global column_names\n",
    "    score = initial\n",
    "    data = data.sort_values(by=\"end_time_min\").reset_index() # sort data by time\n",
    "    i = 0\n",
    "    combined_scores = combine(data)\n",
    "    scores = np.zeros((len(combined_scores), 14))\n",
    "    combined_scores = combined_scores.sort_values(by=\"start_time\").reset_index()\n",
    "    for idx, row in combined_scores.iterrows():\n",
    "        score[row[\"domain_id\"] - 1] = row[\"percentile\"]\n",
    "        # set score to the score list average\n",
    "        scores[i] = score\n",
    "        i += 1\n",
    "    data = data.drop_duplicates(subset=[\"domain_id\", \"start_time\"]).reset_index()\n",
    "    data = pd.concat([data, pd.DataFrame(scores, columns=column_names)], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pscore2 = df_pscore.groupby(\"patient_id\").apply(create_domain_scores2).reset_index(drop=True)\n",
    "df_pscore2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_n = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_minmax2 = MinMaxScaler().fit_transform(df_pscore2[column_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_df2 = df_pscore2\n",
    "minmax_df2[column_n] = scores_df_minmax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_df2['score'] = minmax_df2[column_n].mean(axis=1)\n",
    "minmax_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pid = random.choice(pd.unique(minmax_df2[\"patient_id\"]))\n",
    "pid = 57896\n",
    "print(pid)\n",
    "sns.scatterplot(data=minmax_df2[minmax_df2.patient_id == pid], x=\"end_time_min\", y=\"score\", hue=\"domain_id\", palette=\"bright\").set_title(pid)\n",
    "plt.plot(minmax_df2[minmax_df2.patient_id == pid][\"end_time_min\"], minmax_df2[minmax_df2.patient_id == pid][\"score\"], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_pct[df_pct.patient_id == 30679]\n",
    "temp = temp.sort_values(by=\"end_time_min\").reset_index()\n",
    "temp[temp.domain_id == 10][[\"accuracy\", \"progression_order\", \"percentile\"]][temp.progression_order == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = create_domain_scores2(df_pscore[df_pscore.patient_id == 87299])\n",
    "temp[temp.domain_id == 4][[\"accuracy\", \"progression_order\", \"domain 4 score\", \"start_time\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
