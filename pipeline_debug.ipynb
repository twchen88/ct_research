{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random, sys, copy, os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Ensure deterministic algorithms\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = [\"domain %d score\" %i for i in range(1, 15)]\n",
    "encoding_columns = [\"domain %d encoding\" %i for i in range(1, 15)]\n",
    "target_columns = [\"domain %d target\" %i for i in range(1, 15)]\n",
    "repeat_columns = [\"repeat\"]\n",
    "time_columns = [\"start_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/next_step_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>domain 1 encoding</th>\n",
       "      <th>domain 2 encoding</th>\n",
       "      <th>domain 3 encoding</th>\n",
       "      <th>domain 4 encoding</th>\n",
       "      <th>domain 5 encoding</th>\n",
       "      <th>domain 6 encoding</th>\n",
       "      <th>domain 7 encoding</th>\n",
       "      <th>domain 8 encoding</th>\n",
       "      <th>domain 9 encoding</th>\n",
       "      <th>...</th>\n",
       "      <th>domain 7 target</th>\n",
       "      <th>domain 8 target</th>\n",
       "      <th>domain 9 target</th>\n",
       "      <th>domain 10 target</th>\n",
       "      <th>domain 11 target</th>\n",
       "      <th>domain 12 target</th>\n",
       "      <th>domain 13 target</th>\n",
       "      <th>domain 14 target</th>\n",
       "      <th>repeat</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513443e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513444e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513444e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.515096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.515096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835360</th>\n",
       "      <td>568669.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.687208e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835361</th>\n",
       "      <td>568669.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.687210e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835362</th>\n",
       "      <td>568669.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.687211e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835363</th>\n",
       "      <td>568669.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.687216e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835364</th>\n",
       "      <td>568669.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.687217e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5835365 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         patient_id  domain 1 encoding  domain 2 encoding  domain 3 encoding  \\\n",
       "0            2171.0                0.0                0.0                0.0   \n",
       "1            2171.0                0.0                0.0                0.0   \n",
       "2            2171.0                0.0                0.0                0.0   \n",
       "3            2171.0                1.0                0.0                0.0   \n",
       "4            2171.0                0.0                0.0                0.0   \n",
       "...             ...                ...                ...                ...   \n",
       "5835360    568669.0                1.0                0.0                0.0   \n",
       "5835361    568669.0                0.0                0.0                0.0   \n",
       "5835362    568669.0                0.0                0.0                0.0   \n",
       "5835363    568669.0                0.0                0.0                0.0   \n",
       "5835364    568669.0                0.0                0.0                0.0   \n",
       "\n",
       "         domain 4 encoding  domain 5 encoding  domain 6 encoding  \\\n",
       "0                      1.0                1.0                0.0   \n",
       "1                      0.0                0.0                1.0   \n",
       "2                      0.0                0.0                0.0   \n",
       "3                      0.0                0.0                0.0   \n",
       "4                      1.0                1.0                0.0   \n",
       "...                    ...                ...                ...   \n",
       "5835360                0.0                0.0                0.0   \n",
       "5835361                1.0                1.0                0.0   \n",
       "5835362                0.0                0.0                0.0   \n",
       "5835363                0.0                0.0                0.0   \n",
       "5835364                0.0                0.0                0.0   \n",
       "\n",
       "         domain 7 encoding  domain 8 encoding  domain 9 encoding  ...  \\\n",
       "0                      0.0                0.0                0.0  ...   \n",
       "1                      1.0                0.0                0.0  ...   \n",
       "2                      0.0                0.0                1.0  ...   \n",
       "3                      0.0                0.0                0.0  ...   \n",
       "4                      0.0                0.0                0.0  ...   \n",
       "...                    ...                ...                ...  ...   \n",
       "5835360                0.0                0.0                0.0  ...   \n",
       "5835361                0.0                0.0                0.0  ...   \n",
       "5835362                0.0                0.0                1.0  ...   \n",
       "5835363                0.0                0.0                0.0  ...   \n",
       "5835364                0.0                0.0                0.0  ...   \n",
       "\n",
       "         domain 7 target  domain 8 target  domain 9 target  domain 10 target  \\\n",
       "0                    NaN              NaN              NaN               NaN   \n",
       "1                   0.21              NaN              NaN               NaN   \n",
       "2                   0.21              NaN            0.630               NaN   \n",
       "3                   0.21              NaN            0.630               NaN   \n",
       "4                   0.21              NaN            0.630               NaN   \n",
       "...                  ...              ...              ...               ...   \n",
       "5835360             1.00            0.882            0.667             0.846   \n",
       "5835361             1.00            0.882            0.667             0.846   \n",
       "5835362             1.00            0.882            0.667             0.846   \n",
       "5835363             1.00            0.882            0.667             0.846   \n",
       "5835364             1.00            0.882            0.667             0.846   \n",
       "\n",
       "         domain 11 target  domain 12 target  domain 13 target  \\\n",
       "0                     NaN               NaN               NaN   \n",
       "1                     NaN               NaN               NaN   \n",
       "2                     NaN               NaN               NaN   \n",
       "3                     NaN               NaN               NaN   \n",
       "4                     NaN               NaN               NaN   \n",
       "...                   ...               ...               ...   \n",
       "5835360               1.0             0.188             0.827   \n",
       "5835361               1.0             0.188             0.827   \n",
       "5835362               1.0             0.188             0.827   \n",
       "5835363               1.0             0.218             0.827   \n",
       "5835364               1.0             0.218             0.784   \n",
       "\n",
       "         domain 14 target  repeat    start_time  \n",
       "0                     NaN     0.0  1.513443e+09  \n",
       "1                     NaN     0.0  1.513444e+09  \n",
       "2                     NaN     0.0  1.513444e+09  \n",
       "3                     NaN     1.0  1.515096e+09  \n",
       "4                     NaN     1.0  1.515096e+09  \n",
       "...                   ...     ...           ...  \n",
       "5835360               NaN     1.0  1.687208e+09  \n",
       "5835361               NaN     1.0  1.687210e+09  \n",
       "5835362               NaN     1.0  1.687211e+09  \n",
       "5835363               NaN     1.0  1.687216e+09  \n",
       "5835364               NaN     1.0  1.687217e+09  \n",
       "\n",
       "[5835365 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "n_samples = 100000\n",
    "\n",
    "## one sample for train, only to see if it learns that one example\n",
    "# train_data = train_data[:n_samples].copy()\n",
    "test_data = test_data[:n_samples].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>domain 1 encoding</th>\n",
       "      <th>domain 2 encoding</th>\n",
       "      <th>domain 3 encoding</th>\n",
       "      <th>domain 4 encoding</th>\n",
       "      <th>domain 5 encoding</th>\n",
       "      <th>domain 6 encoding</th>\n",
       "      <th>domain 7 encoding</th>\n",
       "      <th>domain 8 encoding</th>\n",
       "      <th>domain 9 encoding</th>\n",
       "      <th>...</th>\n",
       "      <th>domain 7 target</th>\n",
       "      <th>domain 8 target</th>\n",
       "      <th>domain 9 target</th>\n",
       "      <th>domain 10 target</th>\n",
       "      <th>domain 11 target</th>\n",
       "      <th>domain 12 target</th>\n",
       "      <th>domain 13 target</th>\n",
       "      <th>domain 14 target</th>\n",
       "      <th>repeat</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5198989</th>\n",
       "      <td>321864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.602174e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478682</th>\n",
       "      <td>268337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.672064e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108777</th>\n",
       "      <td>16506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.678826e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428722</th>\n",
       "      <td>333131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.682856e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125710</th>\n",
       "      <td>191189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.546050e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729440</th>\n",
       "      <td>70057.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.585233e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224451</th>\n",
       "      <td>24133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.585000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099919</th>\n",
       "      <td>315975.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.564950e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583513</th>\n",
       "      <td>210803.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.638079e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726344</th>\n",
       "      <td>218913.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.594231e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         patient_id  domain 1 encoding  domain 2 encoding  domain 3 encoding  \\\n",
       "5198989    321864.0                0.0                0.0                0.0   \n",
       "4478682    268337.0                0.0                0.0                0.0   \n",
       "108777      16506.0                0.0                0.0                0.0   \n",
       "5428722    333131.0                0.0                0.0                0.0   \n",
       "3125710    191189.0                0.0                0.0                0.0   \n",
       "...             ...                ...                ...                ...   \n",
       "729440      70057.0                0.0                1.0                0.0   \n",
       "224451      24133.0                0.0                0.0                0.0   \n",
       "5099919    315975.0                0.0                0.0                0.0   \n",
       "3583513    210803.0                0.0                1.0                0.0   \n",
       "3726344    218913.0                1.0                0.0                0.0   \n",
       "\n",
       "         domain 4 encoding  domain 5 encoding  domain 6 encoding  \\\n",
       "5198989                0.0                0.0                0.0   \n",
       "4478682                0.0                0.0                0.0   \n",
       "108777                 0.0                0.0                0.0   \n",
       "5428722                0.0                0.0                0.0   \n",
       "3125710                0.0                0.0                0.0   \n",
       "...                    ...                ...                ...   \n",
       "729440                 0.0                0.0                0.0   \n",
       "224451                 0.0                0.0                0.0   \n",
       "5099919                0.0                0.0                0.0   \n",
       "3583513                0.0                0.0                0.0   \n",
       "3726344                0.0                0.0                0.0   \n",
       "\n",
       "         domain 7 encoding  domain 8 encoding  domain 9 encoding  ...  \\\n",
       "5198989                0.0                0.0                0.0  ...   \n",
       "4478682                0.0                0.0                0.0  ...   \n",
       "108777                 0.0                0.0                0.0  ...   \n",
       "5428722                0.0                0.0                0.0  ...   \n",
       "3125710                0.0                0.0                0.0  ...   \n",
       "...                    ...                ...                ...  ...   \n",
       "729440                 0.0                0.0                0.0  ...   \n",
       "224451                 0.0                0.0                0.0  ...   \n",
       "5099919                0.0                0.0                0.0  ...   \n",
       "3583513                0.0                0.0                0.0  ...   \n",
       "3726344                0.0                0.0                0.0  ...   \n",
       "\n",
       "         domain 7 target  domain 8 target  domain 9 target  domain 10 target  \\\n",
       "5198989            0.022              NaN            0.080             0.454   \n",
       "4478682            0.222            0.000            0.307             0.500   \n",
       "108777             0.950              NaN            1.000             1.000   \n",
       "5428722              NaN              NaN            1.000             0.492   \n",
       "3125710            0.180              NaN            0.260             0.607   \n",
       "...                  ...              ...              ...               ...   \n",
       "729440               NaN              NaN            0.640             0.700   \n",
       "224451             0.222            0.424            0.880             0.685   \n",
       "5099919              NaN            0.917              NaN             0.464   \n",
       "3583513            1.000            0.894            0.640             0.785   \n",
       "3726344            0.560            0.671            0.613             0.862   \n",
       "\n",
       "         domain 11 target  domain 12 target  domain 13 target  \\\n",
       "5198989              0.80             0.127             0.081   \n",
       "4478682              0.64             0.364             0.644   \n",
       "108777               1.00             0.740             1.000   \n",
       "5428722              0.76             0.333             0.881   \n",
       "3125710              1.00             0.457             0.291   \n",
       "...                   ...               ...               ...   \n",
       "729440               0.88             0.667             0.908   \n",
       "224451               1.00             0.545             0.865   \n",
       "5099919              0.40               NaN               NaN   \n",
       "3583513              1.00             0.346             0.865   \n",
       "3726344              1.00             0.939             0.546   \n",
       "\n",
       "         domain 14 target  repeat    start_time  \n",
       "5198989             1.000     1.0  1.602174e+09  \n",
       "4478682             0.200     1.0  1.672064e+09  \n",
       "108777                NaN     1.0  1.678826e+09  \n",
       "5428722             0.200     1.0  1.682856e+09  \n",
       "3125710             0.474     1.0  1.546050e+09  \n",
       "...                   ...     ...           ...  \n",
       "729440                NaN     1.0  1.585233e+09  \n",
       "224451              0.300     1.0  1.585000e+09  \n",
       "5099919             0.522     1.0  1.564950e+09  \n",
       "3583513               NaN     1.0  1.638079e+09  \n",
       "3726344             1.000     1.0  1.594231e+09  \n",
       "\n",
       "[100000 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific sessions to track\n",
    "# session_id = [4478682, 5198989, 3511929, 4134494, 217809, 108777, 4313511, 4184746, 3694380, 2051828, 5151980, 5447081, 3640067, 4856734, 5313162, 4203617, 1813788, 3485634, 4876271, 2213497, 5025916, 274747, 4621927, 3888559, 2592816, 4325322, 3673390]\n",
    "# test_data = test_data.loc[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing indicator when given the score data\n",
    "def create_missing_indicator(data):\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    (l, w) = data.shape\n",
    "    temp = np.zeros((l, w*2))\n",
    "    for i in range(l):\n",
    "        for d in range(w):\n",
    "            p = data[i, d]\n",
    "            # update output array\n",
    "            # if p == 0:\n",
    "            if np.isnan(p):\n",
    "                missing_ind = np.random.choice(2, 1)[0]\n",
    "                temp[i, d*2] = missing_ind\n",
    "                temp[i, d*2+1] = missing_ind\n",
    "            else:\n",
    "                temp[i, d*2] = p # score\n",
    "                temp[i, d*2+1] = 1-p # 1-score\n",
    "    assert not np.isnan(temp).any(), \"nans exists!!!\"\n",
    "    return copy.deepcopy(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a processed dataframe, return data and target numpy arrays\n",
    "def create_model_data(data : pd.DataFrame):\n",
    "    target = data[target_columns].copy().to_numpy() * data[encoding_columns].copy().to_numpy()\n",
    "    print(\"===== from create_model_data ======\")\n",
    "    data_scores = create_missing_indicator(data[score_columns].copy().to_numpy())\n",
    "    print(\"data_scores: \", data_scores)\n",
    "    print(\"target: \", target)\n",
    "    return data_scores, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add encoding to scores and return a tensor that can be put directly into the model\n",
    "def add_encoding(scores : np.ndarray, encoding : np.ndarray):\n",
    "    return torch.from_numpy(np.hstack((encoding, scores))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input : 14 domain encodings + 14 domains (28 total features with missing indicator)\n",
    "## output: 28 score (prediction for the scores after next domain)\n",
    "## copied from next_step.py, which was used to train the model\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        n_domains = 14\n",
    "        \n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_domains * 3, 100),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(100, n_domains)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# used for batch training\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index, :], self.target[index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = NN()\n",
    "model = torch.load(\"output/experiment4/model.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out the non-repeats first for ground truth as the base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find whether it is a repeat domain or not\n",
    "def assign_repeat(df):\n",
    "    print(\"================= assign_repeat =============\")\n",
    "    # default to false\n",
    "    df[repeat_columns] = True\n",
    "    for idx, row in df.iterrows():\n",
    "        assignment = True\n",
    "        # print(\"the row \", row)\n",
    "        for encoding_col, score_col in zip(encoding_columns, score_columns):\n",
    "            # print(\"columns:\" , encoding_col, score_col)\n",
    "            # Find rows where encoding column is 1\n",
    "            encoding_is_1 = row[encoding_col] == 1\n",
    "            \n",
    "            # Check if the corresponding score column is NaN for those rows\n",
    "            is_nan = pd.isna(row[score_col])\n",
    "            # print(\"encoding is 1 and is nan: \", encoding_is_1, is_nan)\n",
    "            # Combine the conditions: where encoding column is 1 and score column is NaN\n",
    "            condition = encoding_is_1 & is_nan\n",
    "            # print(\"condition: \", condition)\n",
    "            if condition:\n",
    "                assignment = False\n",
    "                break\n",
    "            \n",
    "        # Set the 'repeat' column to True where the condition is met, False otherwise\n",
    "        # print(\"assignment: \", assignment)\n",
    "        df.loc[idx, 'repeat'] = assignment\n",
    "    # print(\"after assignment: \", df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= assign_repeat =============\n"
     ]
    }
   ],
   "source": [
    "test_data_assigned  = assign_repeat(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_nonrepeat = test_data_assigned[test_data_assigned.repeat == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test data copies\n",
    "ground_truth_test_data = test_data_assigned.copy()\n",
    "random_test_data = test_data_assigned.copy()\n",
    "best_test_data = test_data_assigned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create encoding and find prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return predictions, loss, and mae\n",
    "def predict(model, x, y):\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(x)\n",
    "        loss = loss_function(predictions, y.reshape(predictions.shape))    \n",
    "        return predictions.clone().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_encoding(df):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of the same shape as df with 0s everywhere except for \n",
    "    a randomly chosen NaN position in each row, which is marked with a 1.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array with the same shape as df, containing 0s and a single 1 in a NaN position per row.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    # Create an output array of zeros\n",
    "    output = np.zeros(df.shape, dtype=int)\n",
    "\n",
    "    # Iterate over each row\n",
    "    for i, row in enumerate(df.isna().values):\n",
    "        nan_indices = np.where(row)[0]  # Find indices where NaN is present\n",
    "        if len(nan_indices) > 0:\n",
    "            chosen_index = np.random.choice(nan_indices)  # Pick one at random\n",
    "            output[i, chosen_index] = 1  # Set the chosen position to 1\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_random_predictions(data):\n",
    "    x, y = create_model_data(data) # create scores with missing indicators and target\n",
    "    e = data[encoding_columns].to_numpy()\n",
    "    x_random = add_encoding(x, e)\n",
    "    predictions = predict(model, x_random, torch.from_numpy(y).float())\n",
    "    return predictions, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random encoding\n",
    "random_encoding = create_random_encoding(random_test_data[score_columns])\n",
    "random_test_data[encoding_columns] = random_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== from create_model_data ======\n",
      "data_scores:  [[0.526 0.474 0.02  ... 0.919 1.    0.   ]\n",
      " [0.526 0.474 0.11  ... 0.356 0.2   0.8  ]\n",
      " [1.    0.    1.    ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.214 0.786 0.    ... 0.    0.533 0.467]\n",
      " [0.779 0.221 0.91  ... 0.135 0.    0.   ]\n",
      " [1.    0.    1.    ... 0.454 1.    0.   ]]\n",
      "target:  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0. nan]\n",
      " ...\n",
      " [ 0. nan nan ... nan nan  0.]\n",
      " [ 0.  0.  0. ...  0.  0. nan]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>domain 1 encoding</th>\n",
       "      <th>domain 2 encoding</th>\n",
       "      <th>domain 3 encoding</th>\n",
       "      <th>domain 4 encoding</th>\n",
       "      <th>domain 5 encoding</th>\n",
       "      <th>domain 6 encoding</th>\n",
       "      <th>domain 7 encoding</th>\n",
       "      <th>domain 8 encoding</th>\n",
       "      <th>domain 9 encoding</th>\n",
       "      <th>...</th>\n",
       "      <th>domain 7 target</th>\n",
       "      <th>domain 8 target</th>\n",
       "      <th>domain 9 target</th>\n",
       "      <th>domain 10 target</th>\n",
       "      <th>domain 11 target</th>\n",
       "      <th>domain 12 target</th>\n",
       "      <th>domain 13 target</th>\n",
       "      <th>domain 14 target</th>\n",
       "      <th>repeat</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5198989</th>\n",
       "      <td>321864.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>0.487917</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>-0.025731</td>\n",
       "      <td>-0.005009</td>\n",
       "      <td>-0.004148</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>-0.006646</td>\n",
       "      <td>True</td>\n",
       "      <td>1.602174e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478682</th>\n",
       "      <td>268337.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>-0.010454</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.008678</td>\n",
       "      <td>-0.011196</td>\n",
       "      <td>True</td>\n",
       "      <td>1.672064e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108777</th>\n",
       "      <td>16506.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>-0.007262</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>0.572504</td>\n",
       "      <td>True</td>\n",
       "      <td>1.678826e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428722</th>\n",
       "      <td>333131.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009555</td>\n",
       "      <td>-0.004032</td>\n",
       "      <td>0.028013</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>-0.013470</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>-0.014447</td>\n",
       "      <td>True</td>\n",
       "      <td>1.682856e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125710</th>\n",
       "      <td>191189.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.496710</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>-0.007925</td>\n",
       "      <td>-0.003851</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>-0.003738</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>True</td>\n",
       "      <td>1.546050e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729440</th>\n",
       "      <td>70057.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558813</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>-0.007180</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>-0.009354</td>\n",
       "      <td>-0.001303</td>\n",
       "      <td>-0.002102</td>\n",
       "      <td>True</td>\n",
       "      <td>1.585233e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224451</th>\n",
       "      <td>24133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>-0.008998</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>-0.012078</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>-0.011907</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>True</td>\n",
       "      <td>1.585000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099919</th>\n",
       "      <td>315975.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007039</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.471864</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>-0.009894</td>\n",
       "      <td>-0.002801</td>\n",
       "      <td>True</td>\n",
       "      <td>1.564950e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583513</th>\n",
       "      <td>210803.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>-0.009153</td>\n",
       "      <td>-0.007750</td>\n",
       "      <td>-0.003159</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>0.577158</td>\n",
       "      <td>True</td>\n",
       "      <td>1.638079e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726344</th>\n",
       "      <td>218913.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>-0.006693</td>\n",
       "      <td>-0.003499</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>True</td>\n",
       "      <td>1.594231e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         patient_id  domain 1 encoding  domain 2 encoding  domain 3 encoding  \\\n",
       "5198989    321864.0                  0                  0                  0   \n",
       "4478682    268337.0                  0                  0                  0   \n",
       "108777      16506.0                  0                  0                  0   \n",
       "5428722    333131.0                  0                  0                  0   \n",
       "3125710    191189.0                  0                  0                  0   \n",
       "...             ...                ...                ...                ...   \n",
       "729440      70057.0                  0                  0                  0   \n",
       "224451      24133.0                  0                  0                  0   \n",
       "5099919    315975.0                  0                  0                  0   \n",
       "3583513    210803.0                  0                  0                  0   \n",
       "3726344    218913.0                  0                  0                  0   \n",
       "\n",
       "         domain 4 encoding  domain 5 encoding  domain 6 encoding  \\\n",
       "5198989                  0                  0                  0   \n",
       "4478682                  0                  0                  0   \n",
       "108777                   0                  0                  0   \n",
       "5428722                  0                  0                  1   \n",
       "3125710                  0                  0                  0   \n",
       "...                    ...                ...                ...   \n",
       "729440                   0                  0                  0   \n",
       "224451                   0                  0                  0   \n",
       "5099919                  0                  0                  0   \n",
       "3583513                  0                  0                  0   \n",
       "3726344                  0                  0                  0   \n",
       "\n",
       "         domain 7 encoding  domain 8 encoding  domain 9 encoding  ...  \\\n",
       "5198989                  0                  1                  0  ...   \n",
       "4478682                  0                  0                  0  ...   \n",
       "108777                   0                  0                  0  ...   \n",
       "5428722                  0                  0                  0  ...   \n",
       "3125710                  0                  1                  0  ...   \n",
       "...                    ...                ...                ...  ...   \n",
       "729440                   1                  0                  0  ...   \n",
       "224451                   0                  0                  0  ...   \n",
       "5099919                  0                  0                  1  ...   \n",
       "3583513                  0                  0                  0  ...   \n",
       "3726344                  0                  0                  0  ...   \n",
       "\n",
       "         domain 7 target  domain 8 target  domain 9 target  domain 10 target  \\\n",
       "5198989        -0.014390         0.487917         0.004378         -0.025731   \n",
       "4478682         0.002268        -0.010454         0.011160         -0.000309   \n",
       "108777          0.006116        -0.001323         0.004081          0.003141   \n",
       "5428722        -0.009555        -0.004032         0.028013          0.005450   \n",
       "3125710         0.000806         0.496710         0.011231         -0.007925   \n",
       "...                  ...              ...              ...               ...   \n",
       "729440          0.558813         0.013916        -0.007180          0.000774   \n",
       "224451         -0.003193        -0.008998         0.015561         -0.012078   \n",
       "5099919        -0.007039         0.007109         0.471864          0.002792   \n",
       "3583513         0.005274        -0.005830        -0.009153         -0.007750   \n",
       "3726344        -0.003485        -0.006693        -0.003499         -0.005677   \n",
       "\n",
       "         domain 11 target  domain 12 target  domain 13 target  \\\n",
       "5198989         -0.005009         -0.004148          0.002992   \n",
       "4478682         -0.006795         -0.000049         -0.008678   \n",
       "108777           0.001826         -0.007262         -0.002123   \n",
       "5428722         -0.013470          0.007487         -0.003746   \n",
       "3125710         -0.003851          0.001144         -0.003738   \n",
       "...                   ...               ...               ...   \n",
       "729440           0.009747         -0.009354         -0.001303   \n",
       "224451          -0.003376         -0.005563         -0.011907   \n",
       "5099919         -0.000910          0.009378         -0.009894   \n",
       "3583513         -0.003159          0.001168         -0.002273   \n",
       "3726344          0.003882          0.035295          0.005313   \n",
       "\n",
       "         domain 14 target  repeat    start_time  \n",
       "5198989         -0.006646    True  1.602174e+09  \n",
       "4478682         -0.011196    True  1.672064e+09  \n",
       "108777           0.572504    True  1.678826e+09  \n",
       "5428722         -0.014447    True  1.682856e+09  \n",
       "3125710          0.001925    True  1.546050e+09  \n",
       "...                   ...     ...           ...  \n",
       "729440          -0.002102    True  1.585233e+09  \n",
       "224451           0.003639    True  1.585000e+09  \n",
       "5099919         -0.002801    True  1.564950e+09  \n",
       "3583513          0.577158    True  1.638079e+09  \n",
       "3726344          0.009120    True  1.594231e+09  \n",
       "\n",
       "[100000 rows x 45 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find random prediction\n",
    "random_prediction, random_encoding = find_random_predictions(random_test_data)\n",
    "random_test_data[target_columns] = random_prediction\n",
    "random_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_encoding(rows, cols, column_index):\n",
    "    if column_index < 0 or column_index >= cols:\n",
    "        raise ValueError(\"Column index is out of bounds.\")\n",
    "\n",
    "    # Create a zero matrix\n",
    "    matrix = np.zeros((rows, cols), dtype=int)\n",
    "\n",
    "    # Set all values in the specified column to 1\n",
    "    matrix[:, column_index] = 1\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_domains(x, y):\n",
    "    prediction_list = []\n",
    "    rows, cols = y.shape\n",
    "    # loop through fourteen domains, get the predictions and store the predictions for that domain only in a list\n",
    "    for domain in range(14):\n",
    "        encoding = create_single_encoding(rows, cols, domain)\n",
    "        x_single = add_encoding(x, encoding)\n",
    "        single_prediction = predict(model, x_single, torch.from_numpy(y).float())\n",
    "        prediction_list.append(single_prediction[:, domain])\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_idx_pred(x, y, original):\n",
    "    prediction_lst = predict_all_domains(x, y)\n",
    "    prediction_matrix = np.column_stack(prediction_lst)  # Shape: (100000, 14)\n",
    "    difference = prediction_matrix - original\n",
    "    # Find the index of the max difference for each row\n",
    "    max_indices = np.argmax(difference, axis=1)  # Shape: (100000,)\n",
    "    rows, cols = y.shape\n",
    "    # Create a zero matrix of shape (100000, 14)\n",
    "    encoding = np.zeros((rows, cols), dtype=int)\n",
    "    # Assign 1s at the max_indices positions to create the full encoding matrix with best domains\n",
    "    encoding[np.arange(rows), max_indices] = 1\n",
    "    # create a zero matrix of shape (100000, 14)\n",
    "    predictions = np.zeros((rows, cols), dtype=prediction_matrix.dtype)  # Keep same data type\n",
    "    # Fill in the max values at their corresponding positions\n",
    "    predictions[np.arange(rows), max_indices] = prediction_matrix[np.arange(rows), max_indices]\n",
    "    return encoding, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_prediction_from_difference(difference_matrix, prediction_matrix, current_matrix):\n",
    "    nan_mask = np.isnan(current_matrix)  # Boolean mask where True indicates NaN\n",
    "\n",
    "    # Initialize arrays to store results\n",
    "    max_indices = np.full(difference_matrix.shape[0], np.nan)  # Store max indices\n",
    "    max_values = np.full(difference_matrix.shape[0], np.nan)  # Store corresponding prediction values\n",
    "\n",
    "    # Iterate through each row\n",
    "    for i in range(difference_matrix.shape[0]):\n",
    "        valid_indices = np.where(nan_mask[i])[0]  # Get column indices where current_matrix has NaN\n",
    "        if valid_indices.size > 0:\n",
    "            valid_differences = difference_matrix[i, valid_indices]  # Select values where NaN exists in current_matrix\n",
    "            max_idx = np.argmax(valid_differences)  # Find index of max value (relative to valid_indices)\n",
    "            max_indices[i] = valid_indices[max_idx]  # Store original column index\n",
    "            max_values[i] = prediction_matrix[i, valid_indices[max_idx]]  # Get corresponding prediction value\n",
    "\n",
    "    return max_values, max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_max_matrices(max_values, max_indices, shape):\n",
    "    max_values_matrix = np.zeros(shape)  # Matrix for max values\n",
    "    max_indices_matrix = np.zeros(shape, dtype=int)  # Matrix for 1s at max indices\n",
    "\n",
    "    # Iterate through rows\n",
    "    for i in range(shape[0]):\n",
    "        if not np.isnan(max_indices[i]):  # Ensure there's a valid index\n",
    "            col_idx = int(max_indices[i])\n",
    "            max_values_matrix[i, col_idx] = max_values[i]\n",
    "            max_indices_matrix[i, col_idx] = 1  # Mark the index with 1\n",
    "\n",
    "    return max_values_matrix, max_indices_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== from create_model_data ======\n",
      "data_scores:  [[0.526 0.474 0.02  ... 0.919 1.    0.   ]\n",
      " [0.526 0.474 0.11  ... 0.356 0.2   0.8  ]\n",
      " [1.    0.    1.    ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.214 0.786 0.    ... 0.    0.533 0.467]\n",
      " [0.779 0.221 0.91  ... 0.135 0.    0.   ]\n",
      " [1.    0.    1.    ... 0.454 1.    0.   ]]\n",
      "target:  [[0.    0.    0.    ... 0.    0.081 0.   ]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.    0.      nan]\n",
      " ...\n",
      " [0.      nan   nan ...   nan   nan 0.522]\n",
      " [0.    0.9   0.    ... 0.    0.      nan]\n",
      " [0.989 0.    0.    ... 0.    0.546 0.   ]]\n",
      "============= domain 1\n",
      "encoding:  [[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[1.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 4.2421883e-01  1.0744184e-03 -2.5437921e-03 ... -3.1367317e-03\n",
      "  -1.8766318e-03  2.5135819e-03]\n",
      " [ 5.0496089e-01  8.0489963e-03 -3.7455931e-04 ...  4.7651082e-03\n",
      "  -1.1813411e-02 -3.8102558e-03]\n",
      " [ 9.7796780e-01  2.2694170e-03 -4.4480879e-03 ... -8.7167099e-03\n",
      "   8.7604281e-03  4.8760083e-03]\n",
      " ...\n",
      " [ 2.6921099e-01  2.0847693e-03 -4.8270524e-03 ...  9.9416450e-03\n",
      "  -5.3291186e-03 -6.2189596e-03]\n",
      " [ 7.8067255e-01 -1.5094653e-03  3.3875108e-03 ...  1.6912818e-05\n",
      "   3.1793313e-03  1.8174769e-03]\n",
      " [ 9.7796673e-01  1.0294832e-02  2.1301519e-02 ...  5.0734729e-04\n",
      "   1.3055729e-02  3.3748010e-03]]\n",
      "============= domain 2\n",
      "encoding:  [[0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 1.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 7.0633590e-03  5.3161412e-02 -1.5045892e-02 ...  9.8743588e-03\n",
      "  -1.3803916e-02  3.6677029e-03]\n",
      " [ 5.8550313e-03  1.4838290e-01 -8.2859173e-03 ...  6.7216977e-03\n",
      "   3.7342804e-03 -6.3713258e-03]\n",
      " [ 9.6850842e-03  9.8007566e-01 -8.4722023e-03 ... -1.7054416e-02\n",
      "   7.8226998e-03 -2.5036274e-03]\n",
      " ...\n",
      " [-6.8583563e-03  5.8799732e-01 -5.1951446e-03 ...  4.9327835e-03\n",
      "  -2.7179220e-03  9.8952092e-05]\n",
      " [ 9.0786815e-04  9.0676308e-01  4.3031992e-03 ...  7.3911548e-03\n",
      "   1.8941676e-03  3.6705527e-03]\n",
      " [ 1.1035301e-02  9.7662175e-01  2.5037264e-02 ... -1.3185740e-03\n",
      "   2.0035645e-03  7.7167004e-03]]\n",
      "============= domain 3\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 1.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 0.00388268 -0.00575855  0.1462817  ...  0.00671218 -0.0438077\n",
      "  -0.00532449]\n",
      " [ 0.01730849 -0.00276068  0.9476464  ...  0.00722156  0.00453429\n",
      "  -0.00818166]\n",
      " [ 0.02230154 -0.00583002  0.96433383 ... -0.00581372 -0.0022949\n",
      "   0.00166811]\n",
      " ...\n",
      " [-0.01565185 -0.00240509  0.7481566  ...  0.01910124 -0.01118737\n",
      "  -0.00304429]\n",
      " [ 0.00213451 -0.00749992  0.95601016 ...  0.00208243 -0.01108092\n",
      "   0.00657251]\n",
      " [ 0.03251195  0.01532863  0.6405007  ...  0.01766163 -0.00341055\n",
      "   0.02068323]]\n",
      "============= domain 4\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 0.00730526 -0.00415564 -0.00806263 ...  0.00157578 -0.0168497\n",
      "  -0.00280061]\n",
      " [ 0.00649312 -0.00450143  0.00321972 ...  0.00377388 -0.00474906\n",
      "  -0.01131416]\n",
      " [ 0.0282115   0.00425288  0.00319496 ... -0.00750437  0.00419345\n",
      "   0.00642996]\n",
      " ...\n",
      " [-0.02008556 -0.00230066 -0.00306478 ...  0.0207886  -0.00596059\n",
      "   0.00300453]\n",
      " [ 0.0107819   0.01033463  0.01198161 ... -0.0114766  -0.00247758\n",
      "   0.00484656]\n",
      " [ 0.03015831  0.02384084  0.01315491 ...  0.0208018   0.00585177\n",
      "   0.00984043]]\n",
      "============= domain 5\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 0.00051687  0.00436528 -0.0112779  ... -0.00211864 -0.01448337\n",
      "   0.00458455]\n",
      " [ 0.00613683  0.00487525  0.00143171 ... -0.00359318 -0.00314594\n",
      "   0.00038808]\n",
      " [ 0.00310734  0.00398319 -0.00351572 ... -0.01321986  0.00548141\n",
      "  -0.00166394]\n",
      " ...\n",
      " [-0.01095084 -0.00717498 -0.00392237 ...  0.01351833 -0.00391441\n",
      "  -0.00307216]\n",
      " [-0.0018812  -0.00351886  0.00459533 ...  0.00074547 -0.00110559\n",
      "   0.00461448]\n",
      " [ 0.01283599  0.00749964  0.01447434 ...  0.0054359   0.00280287\n",
      "  -0.00218951]]\n",
      "============= domain 6\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 0.00025159 -0.00907159 -0.00950857 ... -0.00137821 -0.00965223\n",
      "   0.00432999]\n",
      " [-0.00185286  0.00507983  0.00020816 ...  0.00439389 -0.00491876\n",
      "  -0.0151262 ]\n",
      " [ 0.00942918 -0.00415568  0.00483037 ... -0.00289017  0.00629845\n",
      "  -0.00328865]\n",
      " ...\n",
      " [-0.01322854 -0.00712971 -0.00375225 ...  0.00359425 -0.01265349\n",
      "   0.00427542]\n",
      " [ 0.00319596 -0.00358054 -0.00093307 ... -0.0003344  -0.00231088\n",
      "  -0.00192887]\n",
      " [ 0.01828076  0.01015697  0.01207685 ...  0.00519866  0.00132607\n",
      "   0.00348763]]\n",
      "============= domain 7\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[-4.99301404e-03  1.12367421e-03 -9.79056023e-03 ...  1.83188915e-03\n",
      "  -5.69331693e-03  5.31541184e-03]\n",
      " [ 4.98689711e-03  2.33861804e-03 -3.97366472e-03 ...  5.93359023e-03\n",
      "   4.30191215e-03 -1.38928834e-03]\n",
      " [ 8.01996142e-03  3.24845314e-06  5.80512267e-03 ... -8.45847279e-03\n",
      "   3.93454824e-03  1.23842526e-03]\n",
      " ...\n",
      " [-1.32007822e-02 -1.63103640e-03 -7.23114237e-04 ...  1.13473982e-02\n",
      "   8.25058669e-05 -8.11592676e-04]\n",
      " [-1.88897550e-03  6.41846657e-03  8.95688776e-03 ...  4.94855642e-03\n",
      "  -2.08602869e-03 -7.95518048e-04]\n",
      " [ 2.00109929e-02 -1.31130964e-03  2.42779087e-02 ...  2.75870413e-03\n",
      "   1.48256365e-02  1.92051269e-02]]\n",
      "============= domain 8\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[-0.00802054  0.01634586 -0.01980276 ... -0.00414816  0.00299156\n",
      "  -0.00664595]\n",
      " [ 0.00362496  0.0127096   0.00016417 ... -0.00060847 -0.00234177\n",
      "  -0.00528955]\n",
      " [ 0.01738683 -0.00349233  0.00282324 ... -0.0044166   0.00280244\n",
      "  -0.00285995]\n",
      " ...\n",
      " [-0.00470074 -0.00269514  0.00111087 ...  0.01267451 -0.00680529\n",
      "   0.00570373]\n",
      " [-0.00707585 -0.00028478  0.01405129 ...  0.01042962  0.00437481\n",
      "   0.00781477]\n",
      " [ 0.01536749  0.03206746 -0.00179889 ...  0.00130499  0.00100447\n",
      "   0.00482455]]\n",
      "============= domain 9\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[-0.00020572  0.00965156 -0.01445122 ... -0.0023731  -0.02278376\n",
      "  -0.01558512]\n",
      " [ 0.00183468  0.00166975 -0.00585762 ...  0.00530406 -0.00387148\n",
      "  -0.00213185]\n",
      " [ 0.00694529 -0.01388696 -0.00366751 ... -0.00865524  0.00370017\n",
      "   0.00557277]\n",
      " ...\n",
      " [-0.02077471 -0.01026579 -0.00930912 ...  0.00937819 -0.00989397\n",
      "  -0.00280138]\n",
      " [-0.0013158   0.00416531  0.00264707 ... -0.00141755 -0.00263141\n",
      "  -0.00231633]\n",
      " [ 0.00366125  0.00229669  0.02157526 ...  0.00020336  0.00640961\n",
      "   0.00179575]]\n",
      "============= domain 10\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 2.5275499e-03  2.4834946e-03 -4.3674428e-03 ... -3.4096837e-04\n",
      "  -1.3227754e-02 -2.6161135e-03]\n",
      " [ 6.5111816e-03  7.3743910e-03 -1.9268319e-03 ... -1.1782646e-03\n",
      "  -6.7958608e-06 -8.1396122e-03]\n",
      " [ 4.5764968e-03 -2.2682622e-03 -1.7891452e-03 ... -1.4196888e-02\n",
      "   4.6094917e-03 -4.3047033e-04]\n",
      " ...\n",
      " [-5.9712604e-03 -2.0260960e-03  2.9587150e-03 ...  6.5885261e-03\n",
      "  -3.2199468e-03  4.1637504e-03]\n",
      " [-3.4410432e-03 -4.2426735e-03  4.2713787e-03 ...  5.1742047e-04\n",
      "  -2.0064753e-03  1.8737605e-03]\n",
      " [ 1.0629378e-02  6.6373423e-03  9.1877962e-03 ... -1.3493150e-03\n",
      "   3.6331965e-04  5.7325894e-03]]\n",
      "============= domain 11\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 0.02190442 -0.01478922 -0.03196196 ...  0.00606296 -0.02065611\n",
      "  -0.00106418]\n",
      " [ 0.0121427  -0.00572313  0.00408752 ...  0.00803469  0.00119969\n",
      "  -0.01039862]\n",
      " [ 0.09674397  0.02680961  0.00893444 ...  0.01495112  0.00437149\n",
      "   0.02192629]\n",
      " ...\n",
      " [-0.01579402  0.00144202 -0.01707606 ...  0.04987199 -0.00854502\n",
      "   0.0049817 ]\n",
      " [ 0.03134382  0.02770334  0.01087623 ... -0.01240773  0.00191502\n",
      "   0.00930742]\n",
      " [ 0.09651057  0.06160948  0.00168571 ...  0.06193946  0.01929251\n",
      "  -0.00732703]]\n",
      "============= domain 12\n",
      "encoding:  [[0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 2.6381761e-03 -6.5903887e-03 -3.6315322e-03 ...  1.3206464e-01\n",
      "  -7.6694191e-03  4.6658283e-03]\n",
      " [ 9.1131926e-03  4.9662739e-03  1.8183906e-03 ...  3.6525524e-01\n",
      "  -4.7324765e-03 -2.8037592e-03]\n",
      " [ 5.6251809e-03  2.8649643e-03 -5.3899400e-03 ...  7.3680300e-01\n",
      "   5.5180853e-03 -1.4480650e-03]\n",
      " ...\n",
      " [-6.2823594e-03 -9.5026270e-03 -1.5205260e-02 ...  5.9306163e-01\n",
      "   6.2083825e-04 -6.0583805e-03]\n",
      " [-6.2900856e-03 -6.9665909e-04  5.9440276e-03 ...  3.5314584e-01\n",
      "  -3.7821804e-03  3.1136498e-03]\n",
      " [ 1.5665568e-02  2.3142993e-04  2.4030700e-02 ...  8.8227177e-01\n",
      "  -2.6495848e-04  4.3151118e-03]]\n",
      "============= domain 13\n",
      "encoding:  [[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 1.10634416e-03 -3.62209976e-03 -5.84394485e-03 ... -4.36246395e-03\n",
      "   1.29307255e-01 -2.60783220e-03]\n",
      " [ 6.11276180e-03 -5.73240221e-04  1.83936767e-03 ... -3.05233896e-03\n",
      "   6.53261065e-01 -1.26377484e-02]\n",
      " [ 2.33397335e-02 -9.39041376e-04  1.72351860e-03 ... -5.50549477e-03\n",
      "   9.71063375e-01  1.45777129e-04]\n",
      " ...\n",
      " [-7.99755007e-03 -5.39384782e-03 -1.20489504e-02 ...  2.35910192e-02\n",
      "   6.72212183e-01  1.10263936e-04]\n",
      " [-6.91801310e-04 -4.40015644e-03  4.34231013e-03 ... -2.79240310e-03\n",
      "   8.72119009e-01  1.85240712e-03]\n",
      " [ 3.40834409e-02  5.94843179e-03 -9.86993313e-04 ...  2.78090984e-02\n",
      "   5.49663186e-01  1.81333348e-03]]\n",
      "============= domain 14\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n",
      "prediction:  [[ 7.1509480e-03 -4.9590617e-03 -1.1059968e-02 ... -6.9057867e-03\n",
      "  -1.8648155e-02  9.7681773e-01]\n",
      " [ 3.7536025e-03  9.3382522e-03  1.0678917e-03 ...  1.0590479e-03\n",
      "  -1.8676282e-03  2.0339200e-01]\n",
      " [ 8.1266239e-03 -2.6156828e-03  8.1057288e-04 ... -7.2615072e-03\n",
      "  -2.1228455e-03  5.7250416e-01]\n",
      " ...\n",
      " [-8.8118017e-04 -2.0579472e-03 -6.1331447e-03 ...  4.5366138e-03\n",
      "  -2.8866688e-03  5.3496802e-01]\n",
      " [-3.3339113e-03 -7.3945597e-03  5.2731065e-03 ...  1.1684895e-03\n",
      "  -2.2728576e-03  5.7715791e-01]\n",
      " [ 9.4032064e-03  1.2257963e-02  1.1737892e-02 ...  3.0961633e-04\n",
      "   5.0627533e-03  9.7340238e-01]]\n"
     ]
    }
   ],
   "source": [
    "# create best encoding\n",
    "x_tmp, y_tmp = create_model_data(best_test_data) # create scores with missing indicators and target\n",
    "rows, cols = y_tmp.shape\n",
    "prediction_list = []\n",
    "# loop through fourteen domains, get the predictions and store the predictions for that domain only in a list\n",
    "for domain in range(14):\n",
    "    print(\"============= domain %d\" % (domain + 1))\n",
    "    encoding = create_single_encoding(rows, cols, domain)\n",
    "    print(\"encoding: \", encoding)\n",
    "    tmp_single = add_encoding(x_tmp, encoding)\n",
    "    print(\"data put in model\", tmp_single)\n",
    "    single_prediction = predict(model, tmp_single, torch.from_numpy(y_tmp).float())\n",
    "    print(\"prediction: \", single_prediction)\n",
    "    prediction_list.append(single_prediction[:, domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.526, 0.474, 0.02 , ..., 0.919, 1.   , 0.   ],\n",
       "       [0.526, 0.474, 0.11 , ..., 0.356, 0.2  , 0.8  ],\n",
       "       [1.   , 0.   , 1.   , ..., 0.   , 0.   , 0.   ],\n",
       "       ...,\n",
       "       [0.214, 0.786, 0.   , ..., 0.   , 0.533, 0.467],\n",
       "       [0.779, 0.221, 0.91 , ..., 0.135, 0.   , 0.   ],\n",
       "       [1.   , 0.   , 1.   , ..., 0.454, 1.   , 0.   ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.42421883, 0.5049609 , 0.9779678 , ..., 0.269211  , 0.78067255,\n",
       "        0.9779667 ], dtype=float32),\n",
       " array([0.05316141, 0.1483829 , 0.98007566, ..., 0.5879973 , 0.9067631 ,\n",
       "        0.97662175], dtype=float32),\n",
       " array([0.1462817 , 0.9476464 , 0.96433383, ..., 0.7481566 , 0.95601016,\n",
       "        0.6405007 ], dtype=float32),\n",
       " array([0.3306931 , 0.37153944, 0.90246654, ..., 0.23649427, 0.90181524,\n",
       "        0.89480066], dtype=float32),\n",
       " array([0.11111826, 0.17349893, 0.93166447, ..., 0.08682654, 0.5743863 ,\n",
       "        0.92185   ], dtype=float32),\n",
       " array([0.06135439, 0.06429052, 0.4675113 , ..., 0.46072373, 0.9171147 ,\n",
       "        0.6734154 ], dtype=float32),\n",
       " array([0.04934064, 0.19785866, 0.913955  , ..., 0.45046207, 0.9563673 ,\n",
       "        0.59028465], dtype=float32),\n",
       " array([0.48791665, 0.10046811, 0.528789  , ..., 0.9120596 , 0.9114108 ,\n",
       "        0.6317404 ], dtype=float32),\n",
       " array([0.09235591, 0.28050837, 0.9787704 , ..., 0.47186366, 0.6655221 ,\n",
       "        0.6369015 ], dtype=float32),\n",
       " array([0.3924424 , 0.4210424 , 0.9702444 , ..., 0.409122  , 0.80263174,\n",
       "        0.8768853 ], dtype=float32),\n",
       " array([0.8225147 , 0.63235795, 0.9894878 , ..., 0.48598796, 0.98975307,\n",
       "        0.9934528 ], dtype=float32),\n",
       " array([0.13206464, 0.36525524, 0.736803  , ..., 0.5930616 , 0.35314584,\n",
       "        0.88227177], dtype=float32),\n",
       " array([0.12930726, 0.65326107, 0.9710634 , ..., 0.6722122 , 0.872119  ,\n",
       "        0.5496632 ], dtype=float32),\n",
       " array([0.9768177 , 0.203392  , 0.57250416, ..., 0.534968  , 0.5771579 ,\n",
       "        0.9734024 ], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrows, cols = prediction_matrix.shape\\n# Find the index of the max difference for each row\\nmax_indices = np.argmax(difference, axis=1)  # Shape: (100000,)\\n# Create a zero matrix of shape (100000, 14)\\nbest_encoding = np.zeros((rows, cols), dtype=int)\\n# Assign 1s at the max_indices positions to create the full encoding matrix with best domains\\nbest_encoding[np.arange(rows), max_indices] = 1\\n# create a zero matrix of shape (100000, 14)\\nbest_predictions = np.zeros((rows, cols), dtype=prediction_matrix.dtype)  # Keep same data type\\n# Fill in the max values at their corresponding positions\\nbest_predictions[np.arange(rows), max_indices] = prediction_matrix[np.arange(rows), max_indices]\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_matrix = np.column_stack(prediction_list)  # Shape: (100000, 14)\n",
    "difference = prediction_matrix - np.nan_to_num(best_test_data[score_columns].to_numpy())\n",
    "\n",
    "# find max indices\n",
    "max_values, max_indices = max_prediction_from_difference(difference, prediction_matrix, best_test_data[score_columns].to_numpy())\n",
    "# reconstruct matrices\n",
    "best_predictions, best_encoding = reconstruct_max_matrices(max_values, max_indices, prediction_matrix.shape)\n",
    "\n",
    "'''\n",
    "rows, cols = prediction_matrix.shape\n",
    "# Find the index of the max difference for each row\n",
    "max_indices = np.argmax(difference, axis=1)  # Shape: (100000,)\n",
    "# Create a zero matrix of shape (100000, 14)\n",
    "best_encoding = np.zeros((rows, cols), dtype=int)\n",
    "# Assign 1s at the max_indices positions to create the full encoding matrix with best domains\n",
    "best_encoding[np.arange(rows), max_indices] = 1\n",
    "# create a zero matrix of shape (100000, 14)\n",
    "best_predictions = np.zeros((rows, cols), dtype=prediction_matrix.dtype)  # Keep same data type\n",
    "# Fill in the max values at their corresponding positions\n",
    "best_predictions[np.arange(rows), max_indices] = prediction_matrix[np.arange(rows), max_indices]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42421883, 0.05316141, 0.1462817 , ..., 0.13206464, 0.12930726,\n",
       "        0.9768177 ],\n",
       "       [0.5049609 , 0.1483829 , 0.9476464 , ..., 0.36525524, 0.65326107,\n",
       "        0.203392  ],\n",
       "       [0.9779678 , 0.98007566, 0.96433383, ..., 0.736803  , 0.9710634 ,\n",
       "        0.57250416],\n",
       "       ...,\n",
       "       [0.269211  , 0.5879973 , 0.7481566 , ..., 0.5930616 , 0.6722122 ,\n",
       "        0.534968  ],\n",
       "       [0.78067255, 0.9067631 , 0.95601016, ..., 0.35314584, 0.872119  ,\n",
       "        0.5771579 ],\n",
       "       [0.9779667 , 0.97662175, 0.6405007 , ..., 0.88227177, 0.5496632 ,\n",
       "        0.9734024 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain 1 target</th>\n",
       "      <th>domain 2 target</th>\n",
       "      <th>domain 3 target</th>\n",
       "      <th>domain 4 target</th>\n",
       "      <th>domain 5 target</th>\n",
       "      <th>domain 6 target</th>\n",
       "      <th>domain 7 target</th>\n",
       "      <th>domain 8 target</th>\n",
       "      <th>domain 9 target</th>\n",
       "      <th>domain 10 target</th>\n",
       "      <th>domain 11 target</th>\n",
       "      <th>domain 12 target</th>\n",
       "      <th>domain 13 target</th>\n",
       "      <th>domain 14 target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5198989</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478682</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108777</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428722</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125710</th>\n",
       "      <td>0.428</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729440</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224451</th>\n",
       "      <td>0.473</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099919</th>\n",
       "      <td>0.214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583513</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.561</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.865</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726344</th>\n",
       "      <td>0.989</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.593</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain 1 target  domain 2 target  domain 3 target  domain 4 target  \\\n",
       "5198989            0.526             0.02            0.148            0.375   \n",
       "4478682            0.526             0.11            1.000            0.400   \n",
       "108777             1.000             1.00            1.000            1.000   \n",
       "5428722            0.516             0.73            1.000            1.000   \n",
       "3125710            0.428             0.42            0.880            0.243   \n",
       "...                  ...              ...              ...              ...   \n",
       "729440             0.884             1.00            1.000            0.900   \n",
       "224451             0.473             0.92            0.889            1.000   \n",
       "5099919            0.214              NaN              NaN            0.214   \n",
       "3583513            0.779             0.90            1.000            0.950   \n",
       "3726344            0.989             1.00            0.593            1.000   \n",
       "\n",
       "         domain 5 target  domain 6 target  domain 7 target  domain 8 target  \\\n",
       "5198989            0.129            0.000            0.022              NaN   \n",
       "4478682            0.168            0.013            0.222            0.000   \n",
       "108777             1.000              NaN            0.950              NaN   \n",
       "5428722            0.658              NaN              NaN              NaN   \n",
       "3125710            0.170            0.263            0.180              NaN   \n",
       "...                  ...              ...              ...              ...   \n",
       "729440             0.594              NaN              NaN              NaN   \n",
       "224451             0.639            0.133            0.222            0.424   \n",
       "5099919            0.050            0.474              NaN            0.917   \n",
       "3583513            0.561            1.000            1.000            0.894   \n",
       "3726344            1.000            0.684            0.560            0.671   \n",
       "\n",
       "         domain 9 target  domain 10 target  domain 11 target  \\\n",
       "5198989            0.080             0.454              0.80   \n",
       "4478682            0.307             0.500              0.64   \n",
       "108777             1.000             1.000              1.00   \n",
       "5428722            1.000             0.492              0.76   \n",
       "3125710            0.260             0.607              1.00   \n",
       "...                  ...               ...               ...   \n",
       "729440             0.640             0.700              0.88   \n",
       "224451             0.880             0.685              1.00   \n",
       "5099919              NaN             0.464              0.40   \n",
       "3583513            0.640             0.785              1.00   \n",
       "3726344            0.613             0.862              1.00   \n",
       "\n",
       "         domain 12 target  domain 13 target  domain 14 target  \n",
       "5198989             0.127             0.081             1.000  \n",
       "4478682             0.364             0.644             0.200  \n",
       "108777              0.740             1.000               NaN  \n",
       "5428722             0.333             0.881             0.200  \n",
       "3125710             0.457             0.291             0.474  \n",
       "...                   ...               ...               ...  \n",
       "729440              0.667             0.908               NaN  \n",
       "224451              0.545             0.865             0.300  \n",
       "5099919               NaN               NaN             0.522  \n",
       "3583513             0.346             0.865               NaN  \n",
       "3726344             0.939             0.546             1.000  \n",
       "\n",
       "[100000 rows x 14 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_test_data[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain 1 score</th>\n",
       "      <th>domain 2 score</th>\n",
       "      <th>domain 3 score</th>\n",
       "      <th>domain 4 score</th>\n",
       "      <th>domain 5 score</th>\n",
       "      <th>domain 6 score</th>\n",
       "      <th>domain 7 score</th>\n",
       "      <th>domain 8 score</th>\n",
       "      <th>domain 9 score</th>\n",
       "      <th>domain 10 score</th>\n",
       "      <th>domain 11 score</th>\n",
       "      <th>domain 12 score</th>\n",
       "      <th>domain 13 score</th>\n",
       "      <th>domain 14 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5198989</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478682</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108777</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428722</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125710</th>\n",
       "      <td>0.428</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729440</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224451</th>\n",
       "      <td>0.473</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099919</th>\n",
       "      <td>0.214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583513</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.561</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.865</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726344</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.593</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain 1 score  domain 2 score  domain 3 score  domain 4 score  \\\n",
       "5198989           0.526            0.02           0.148           0.375   \n",
       "4478682           0.526            0.11           1.000           0.400   \n",
       "108777            1.000            1.00           1.000           1.000   \n",
       "5428722           0.516            0.73           1.000           1.000   \n",
       "3125710           0.428            0.42           0.880           0.243   \n",
       "...                 ...             ...             ...             ...   \n",
       "729440            0.884            1.00           1.000           0.900   \n",
       "224451            0.473            0.92           0.889           1.000   \n",
       "5099919           0.214             NaN             NaN           0.214   \n",
       "3583513           0.779            0.91           1.000           0.950   \n",
       "3726344           1.000            1.00           0.593           1.000   \n",
       "\n",
       "         domain 5 score  domain 6 score  domain 7 score  domain 8 score  \\\n",
       "5198989           0.129           0.000           0.022             NaN   \n",
       "4478682           0.168           0.013           0.222           0.000   \n",
       "108777            1.000             NaN           0.950             NaN   \n",
       "5428722           0.658             NaN             NaN             NaN   \n",
       "3125710           0.170           0.263           0.180             NaN   \n",
       "...                 ...             ...             ...             ...   \n",
       "729440            0.594             NaN             NaN             NaN   \n",
       "224451            0.639           0.133           0.222           0.424   \n",
       "5099919           0.050           0.474             NaN           0.917   \n",
       "3583513           0.561           1.000           1.000           0.894   \n",
       "3726344           1.000           0.684           0.560           0.671   \n",
       "\n",
       "         domain 9 score  domain 10 score  domain 11 score  domain 12 score  \\\n",
       "5198989           0.080            0.454             0.80            0.127   \n",
       "4478682           0.307            0.485             0.64            0.364   \n",
       "108777            1.000            1.000             1.00            0.740   \n",
       "5428722           1.000            0.500             0.80            0.333   \n",
       "3125710           0.260            0.607             1.00            0.457   \n",
       "...                 ...              ...              ...              ...   \n",
       "729440            0.640            0.700             0.88            0.667   \n",
       "224451            0.880            0.685             1.00            0.545   \n",
       "5099919             NaN            0.464             0.40              NaN   \n",
       "3583513           0.640            0.785             1.00            0.346   \n",
       "3726344           0.613            0.862             1.00            0.939   \n",
       "\n",
       "         domain 13 score  domain 14 score  \n",
       "5198989            0.081            1.000  \n",
       "4478682            0.644            0.200  \n",
       "108777             1.000              NaN  \n",
       "5428722            0.881            0.200  \n",
       "3125710            0.291            0.474  \n",
       "...                  ...              ...  \n",
       "729440             0.908              NaN  \n",
       "224451             0.865            0.300  \n",
       "5099919              NaN            0.533  \n",
       "3583513            0.865              NaN  \n",
       "3726344            0.546            1.000  \n",
       "\n",
       "[100000 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test_data[score_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10178117,  0.03316141, -0.0017183 , ...,  0.00506464,\n",
       "         0.04830726, -0.02318227],\n",
       "       [-0.02103911,  0.0383829 , -0.05235362, ...,  0.00125524,\n",
       "         0.00926107,  0.003392  ],\n",
       "       [-0.0220322 , -0.01992434, -0.03566617, ..., -0.003197  ,\n",
       "        -0.02893662,  0.57250416],\n",
       "       ...,\n",
       "       [ 0.05521099,  0.58799732,  0.74815661, ...,  0.59306163,\n",
       "         0.67221218,  0.00196802],\n",
       "       [ 0.00167255, -0.00323692, -0.04398984, ...,  0.00714584,\n",
       "         0.00711901,  0.57715791],\n",
       "       [-0.02203327, -0.02337825,  0.04750072, ..., -0.05672823,\n",
       "         0.00366319, -0.02659762]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7., nan, 13., ...,  2., 13., nan])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.57250416],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.74815661, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.57715791],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_data[encoding_columns] = best_encoding\n",
    "best_test_data[target_columns] = best_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate by repeat vs non repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth\n",
      "================= assign_repeat =============\n",
      "random\n",
      "================= assign_repeat =============\n",
      "best\n",
      "================= assign_repeat =============\n"
     ]
    }
   ],
   "source": [
    "# random assignment\n",
    "print(\"ground truth\")\n",
    "ground_truth_test_data_final  = assign_repeat(ground_truth_test_data)\n",
    "print(\"random\")\n",
    "random_test_data_final  = assign_repeat(random_test_data)\n",
    "print(\"best\")\n",
    "best_test_data_final  = assign_repeat(best_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter depending on number of known domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows based on number of missing values (denoted by nans) the session has\n",
    "def filter_n_missing(df, n_missing):\n",
    "    global score_columns\n",
    "    # only use the score columns when counting 0s\n",
    "    scores = df[score_columns]\n",
    "    # Count number of nans in each row\n",
    "    missing_count = scores.isna().sum(axis=1)\n",
    "    \n",
    "    # Filter rows with n_zeros number of zeros\n",
    "    filtered_rows = df[missing_count == n_missing]\n",
    "    return filtered_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug print\n",
    "def debug_filter_print(df):\n",
    "    n = df.iloc[0][score_columns].isna().sum()\n",
    "    total_sessions = df.shape[0]\n",
    "    print(\"# of missing = %d, # of total sessions = %d\" % (n, total_sessions))\n",
    "    print(np.isnan(df[score_columns]).sum(axis=1).sum() == n * total_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_test_data_n = dict()\n",
    "random_test_data_n = dict()\n",
    "best_test_data_n = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= filter n missing: n = 1 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 1, # of total sessions = 21428\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 1, # of total sessions = 21428\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 1, # of total sessions = 21428\n",
      "True\n",
      "======================= filter n missing: n = 2 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 2, # of total sessions = 14721\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 2, # of total sessions = 14721\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 2, # of total sessions = 14721\n",
      "True\n",
      "======================= filter n missing: n = 3 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 3, # of total sessions = 10891\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 3, # of total sessions = 10891\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 3, # of total sessions = 10891\n",
      "True\n",
      "======================= filter n missing: n = 4 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 4, # of total sessions = 8722\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 4, # of total sessions = 8722\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 4, # of total sessions = 8722\n",
      "True\n",
      "======================= filter n missing: n = 5 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 5, # of total sessions = 6264\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 5, # of total sessions = 6264\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 5, # of total sessions = 6264\n",
      "True\n",
      "======================= filter n missing: n = 6 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 6, # of total sessions = 3995\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 6, # of total sessions = 3995\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 6, # of total sessions = 3995\n",
      "True\n",
      "======================= filter n missing: n = 7 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 7, # of total sessions = 2515\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 7, # of total sessions = 2515\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 7, # of total sessions = 2515\n",
      "True\n",
      "======================= filter n missing: n = 8 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 8, # of total sessions = 1424\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 8, # of total sessions = 1424\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 8, # of total sessions = 1424\n",
      "True\n",
      "======================= filter n missing: n = 9 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 9, # of total sessions = 728\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 9, # of total sessions = 728\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 9, # of total sessions = 728\n",
      "True\n",
      "======================= filter n missing: n = 10 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 10, # of total sessions = 480\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 10, # of total sessions = 480\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 10, # of total sessions = 480\n",
      "True\n",
      "======================= filter n missing: n = 11 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 11, # of total sessions = 160\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 11, # of total sessions = 160\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 11, # of total sessions = 160\n",
      "True\n",
      "======================= filter n missing: n = 12 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 12, # of total sessions = 88\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 12, # of total sessions = 88\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 12, # of total sessions = 88\n",
      "True\n",
      "======================= filter n missing: n = 13 =========================\n",
      "============ ground truth ===============\n",
      "# of missing = 13, # of total sessions = 49\n",
      "True\n",
      "============ random ================\n",
      "# of missing = 13, # of total sessions = 49\n",
      "True\n",
      "============= best ==================\n",
      "# of missing = 13, # of total sessions = 49\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 14):\n",
    "    print(\"======================= filter n missing: n = %d =========================\" % n)\n",
    "    print(\"============ ground truth ===============\")\n",
    "    tmp = filter_n_missing(ground_truth_test_data, n_missing=n)\n",
    "    ground_truth_test_data_n[n] = tmp.copy()\n",
    "    debug_filter_print(tmp)\n",
    "\n",
    "    print(\"============ random ================\")\n",
    "    tmp = filter_n_missing(random_test_data, n_missing=n)\n",
    "    random_test_data_n[n] = tmp.copy()\n",
    "    debug_filter_print(tmp)\n",
    "\n",
    "    print(\"============= best ==================\")\n",
    "    tmp = filter_n_missing(best_test_data, n_missing=n)\n",
    "    best_test_data_n[n] = tmp.copy()\n",
    "    debug_filter_print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain 1 score</th>\n",
       "      <th>domain 2 score</th>\n",
       "      <th>domain 3 score</th>\n",
       "      <th>domain 4 score</th>\n",
       "      <th>domain 5 score</th>\n",
       "      <th>domain 6 score</th>\n",
       "      <th>domain 7 score</th>\n",
       "      <th>domain 8 score</th>\n",
       "      <th>domain 9 score</th>\n",
       "      <th>domain 10 score</th>\n",
       "      <th>domain 11 score</th>\n",
       "      <th>domain 12 score</th>\n",
       "      <th>domain 13 score</th>\n",
       "      <th>domain 14 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5198989</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478682</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108777</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428722</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125710</th>\n",
       "      <td>0.428</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729440</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224451</th>\n",
       "      <td>0.473</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099919</th>\n",
       "      <td>0.214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583513</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.561</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.865</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726344</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.593</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain 1 score  domain 2 score  domain 3 score  domain 4 score  \\\n",
       "5198989           0.526            0.02           0.148           0.375   \n",
       "4478682           0.526            0.11           1.000           0.400   \n",
       "108777            1.000            1.00           1.000           1.000   \n",
       "5428722           0.516            0.73           1.000           1.000   \n",
       "3125710           0.428            0.42           0.880           0.243   \n",
       "...                 ...             ...             ...             ...   \n",
       "729440            0.884            1.00           1.000           0.900   \n",
       "224451            0.473            0.92           0.889           1.000   \n",
       "5099919           0.214             NaN             NaN           0.214   \n",
       "3583513           0.779            0.91           1.000           0.950   \n",
       "3726344           1.000            1.00           0.593           1.000   \n",
       "\n",
       "         domain 5 score  domain 6 score  domain 7 score  domain 8 score  \\\n",
       "5198989           0.129           0.000           0.022             NaN   \n",
       "4478682           0.168           0.013           0.222           0.000   \n",
       "108777            1.000             NaN           0.950             NaN   \n",
       "5428722           0.658             NaN             NaN             NaN   \n",
       "3125710           0.170           0.263           0.180             NaN   \n",
       "...                 ...             ...             ...             ...   \n",
       "729440            0.594             NaN             NaN             NaN   \n",
       "224451            0.639           0.133           0.222           0.424   \n",
       "5099919           0.050           0.474             NaN           0.917   \n",
       "3583513           0.561           1.000           1.000           0.894   \n",
       "3726344           1.000           0.684           0.560           0.671   \n",
       "\n",
       "         domain 9 score  domain 10 score  domain 11 score  domain 12 score  \\\n",
       "5198989           0.080            0.454             0.80            0.127   \n",
       "4478682           0.307            0.485             0.64            0.364   \n",
       "108777            1.000            1.000             1.00            0.740   \n",
       "5428722           1.000            0.500             0.80            0.333   \n",
       "3125710           0.260            0.607             1.00            0.457   \n",
       "...                 ...              ...              ...              ...   \n",
       "729440            0.640            0.700             0.88            0.667   \n",
       "224451            0.880            0.685             1.00            0.545   \n",
       "5099919             NaN            0.464             0.40              NaN   \n",
       "3583513           0.640            0.785             1.00            0.346   \n",
       "3726344           0.613            0.862             1.00            0.939   \n",
       "\n",
       "         domain 13 score  domain 14 score  \n",
       "5198989            0.081            1.000  \n",
       "4478682            0.644            0.200  \n",
       "108777             1.000              NaN  \n",
       "5428722            0.881            0.200  \n",
       "3125710            0.291            0.474  \n",
       "...                  ...              ...  \n",
       "729440             0.908              NaN  \n",
       "224451             0.865            0.300  \n",
       "5099919              NaN            0.533  \n",
       "3583513            0.865              NaN  \n",
       "3726344            0.546            1.000  \n",
       "\n",
       "[100000 rows x 14 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_test_data_final[score_columns] ## all three should be the same -> current score shouldn't be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain 1 score</th>\n",
       "      <th>domain 2 score</th>\n",
       "      <th>domain 3 score</th>\n",
       "      <th>domain 4 score</th>\n",
       "      <th>domain 5 score</th>\n",
       "      <th>domain 6 score</th>\n",
       "      <th>domain 7 score</th>\n",
       "      <th>domain 8 score</th>\n",
       "      <th>domain 9 score</th>\n",
       "      <th>domain 10 score</th>\n",
       "      <th>domain 11 score</th>\n",
       "      <th>domain 12 score</th>\n",
       "      <th>domain 13 score</th>\n",
       "      <th>domain 14 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5198989</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478682</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108777</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428722</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125710</th>\n",
       "      <td>0.428</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729440</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224451</th>\n",
       "      <td>0.473</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.685</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099919</th>\n",
       "      <td>0.214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583513</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.561</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.865</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726344</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.593</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.862</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain 1 score  domain 2 score  domain 3 score  domain 4 score  \\\n",
       "5198989           0.526            0.02           0.148           0.375   \n",
       "4478682           0.526            0.11           1.000           0.400   \n",
       "108777            1.000            1.00           1.000           1.000   \n",
       "5428722           0.516            0.73           1.000           1.000   \n",
       "3125710           0.428            0.42           0.880           0.243   \n",
       "...                 ...             ...             ...             ...   \n",
       "729440            0.884            1.00           1.000           0.900   \n",
       "224451            0.473            0.92           0.889           1.000   \n",
       "5099919           0.214             NaN             NaN           0.214   \n",
       "3583513           0.779            0.91           1.000           0.950   \n",
       "3726344           1.000            1.00           0.593           1.000   \n",
       "\n",
       "         domain 5 score  domain 6 score  domain 7 score  domain 8 score  \\\n",
       "5198989           0.129           0.000           0.022             NaN   \n",
       "4478682           0.168           0.013           0.222           0.000   \n",
       "108777            1.000             NaN           0.950             NaN   \n",
       "5428722           0.658             NaN             NaN             NaN   \n",
       "3125710           0.170           0.263           0.180             NaN   \n",
       "...                 ...             ...             ...             ...   \n",
       "729440            0.594             NaN             NaN             NaN   \n",
       "224451            0.639           0.133           0.222           0.424   \n",
       "5099919           0.050           0.474             NaN           0.917   \n",
       "3583513           0.561           1.000           1.000           0.894   \n",
       "3726344           1.000           0.684           0.560           0.671   \n",
       "\n",
       "         domain 9 score  domain 10 score  domain 11 score  domain 12 score  \\\n",
       "5198989           0.080            0.454             0.80            0.127   \n",
       "4478682           0.307            0.485             0.64            0.364   \n",
       "108777            1.000            1.000             1.00            0.740   \n",
       "5428722           1.000            0.500             0.80            0.333   \n",
       "3125710           0.260            0.607             1.00            0.457   \n",
       "...                 ...              ...              ...              ...   \n",
       "729440            0.640            0.700             0.88            0.667   \n",
       "224451            0.880            0.685             1.00            0.545   \n",
       "5099919             NaN            0.464             0.40              NaN   \n",
       "3583513           0.640            0.785             1.00            0.346   \n",
       "3726344           0.613            0.862             1.00            0.939   \n",
       "\n",
       "         domain 13 score  domain 14 score  \n",
       "5198989            0.081            1.000  \n",
       "4478682            0.644            0.200  \n",
       "108777             1.000              NaN  \n",
       "5428722            0.881            0.200  \n",
       "3125710            0.291            0.474  \n",
       "...                  ...              ...  \n",
       "729440             0.908              NaN  \n",
       "224451             0.865            0.300  \n",
       "5099919              NaN            0.533  \n",
       "3583513            0.865              NaN  \n",
       "3726344            0.546            1.000  \n",
       "\n",
       "[100000 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_data_final[score_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_avg_improvement_with_std(df):\n",
    "    pred_score = df[target_columns].to_numpy()\n",
    "    cur_score = df[score_columns].to_numpy()\n",
    "    encoding = df[encoding_columns].to_numpy()\n",
    "\n",
    "    print(\"prediction score: \", pred_score)\n",
    "    print(\"current score: \", cur_score)\n",
    "    print(\"encoding: \", encoding)\n",
    "\n",
    "    pred_score = np.nan_to_num(pred_score, nan=0) * encoding\n",
    "    cur_score = np.nan_to_num(cur_score, nan=0) * encoding\n",
    "    assert pred_score.shape == cur_score.shape and cur_score.shape == encoding.shape\n",
    "\n",
    "    # Compute improvement\n",
    "    improvement = encoding * (pred_score - cur_score)\n",
    "\n",
    "    # Extract nonzero values\n",
    "    nonzero_improvement = improvement[improvement != 0]\n",
    "\n",
    "    if len(nonzero_improvement) == 0:\n",
    "        avg_improvement = 0\n",
    "        std_dev = 0\n",
    "        print(\"No sessions with nonzero improvement\")\n",
    "    else:\n",
    "        avg_improvement = np.mean(nonzero_improvement)\n",
    "        std_dev = np.std(nonzero_improvement, ddof=1)  # Using sample standard deviation (ddof=1)\n",
    "\n",
    "        print(\"Number of predicted domains:\", len(nonzero_improvement))\n",
    "        print(\"Average improvement:\", avg_improvement)\n",
    "        print(\"Standard deviation:\", std_dev)\n",
    "\n",
    "    return avg_improvement, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonrepeat_ground_truth_avg = []\n",
    "nonrepeat_random_avg = []\n",
    "nonrepeat_best_avg = []\n",
    "\n",
    "nonrepeat_ground_truth_std = []\n",
    "nonrepeat_random_std = []\n",
    "nonrepeat_best_std = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 1 missing\n",
      "----ground truth----\n",
      "prediction score:  [[0.632 0.36  1.    1.    0.361 0.667 0.278 0.333 0.16  0.538 1.    0.376\n",
      "  0.806 0.3  ]\n",
      " [0.429 0.05  1.    0.2   0.04  0.568 0.57  0.817 0.05  0.493 1.    0.286\n",
      "  0.582 0.554]\n",
      " [1.    0.    1.    0.157 0.    0.053 0.55  0.85  0.16  0.272 1.    0.143\n",
      "  0.206 0.874]\n",
      " [0.443 0.55  0.815 0.95  0.477 0.12  0.844 0.917 0.42  0.823 0.76  0.382\n",
      "  0.47  0.853]\n",
      " [1.    1.    0.415 0.388 0.174 0.88  0.278 0.647 1.    1.    1.    0.182\n",
      "  0.773 0.96 ]\n",
      " [0.429 0.35  1.    0.172 0.04  0.232 0.5   0.55  0.2   0.4   1.    0.364\n",
      "  0.218 0.047]\n",
      " [1.    1.    1.    1.    0.755 0.347 0.889 1.    1.    1.    1.    0.794\n",
      "  1.    1.   ]\n",
      " [0.571 0.263 0.787 0.257 0.125 0.652 0.563 0.283 0.85  0.357 0.4   0.571\n",
      "  0.682 0.92 ]\n",
      " [0.968 0.15  0.593 1.    0.419 0.737 0.34  0.667 0.813 1.    1.    0.545\n",
      "  0.984 1.   ]\n",
      " [0.632 0.    1.    0.5   0.484 1.    0.53  1.    0.25  0.846 0.84  0.343\n",
      "  0.93  0.487]\n",
      " [0.937 0.54  1.    0.963 0.664 0.027 1.    0.    0.467 1.    1.    0.721\n",
      "  0.935 1.   ]\n",
      " [1.    0.25  0.763 1.    1.    1.    0.556 1.    0.34  1.    1.    0.455\n",
      "  1.    0.907]\n",
      " [0.743 0.55  1.    0.5   0.25  0.6   0.64  1.    0.49  0.7   0.2   0.571\n",
      "  0.806 0.907]\n",
      " [0.158 0.16  0.63  0.488 0.271 0.442 0.153 0.353 0.05  0.415 0.8   0.697\n",
      "  0.437 0.3  ]\n",
      " [0.714 1.    1.    0.214 0.2   0.19  0.85  0.05  0.2   0.2   0.    0.464\n",
      "  0.545 0.467]\n",
      " [0.829 0.61  1.    0.585 0.33  0.537 0.37  1.    0.35  0.386 0.4   0.421\n",
      "  0.794 0.927]\n",
      " [0.629 0.18  1.    0.386 0.19  0.61  0.275 0.25  0.9   0.728 1.    0.357\n",
      "  0.594 1.   ]]\n",
      "current score:  [[0.632 0.36  1.    1.    0.361 0.667   nan 0.333 0.16  0.538 1.    0.376\n",
      "  0.806 0.3  ]\n",
      " [0.429   nan 1.    0.2   0.04  0.568 0.57  0.817 0.05  0.493 1.    0.286\n",
      "  0.582 0.554]\n",
      " [1.      nan 1.    0.157 0.    0.053 0.55  0.85  0.16  0.272 1.    0.143\n",
      "  0.206 0.874]\n",
      " [0.443   nan 0.815 0.95  0.477 0.12  0.844 0.917 0.42  0.823 0.76  0.382\n",
      "  0.47  0.853]\n",
      " [1.    1.    0.415 0.388 0.174 0.88    nan 0.647 1.    1.    1.    0.182\n",
      "  0.773 0.96 ]\n",
      " [0.429   nan 1.    0.172 0.04  0.232 0.5   0.55  0.2   0.4   1.    0.364\n",
      "  0.218 0.047]\n",
      " [1.    1.    1.    1.    0.755 0.347   nan 1.    1.    1.    1.    0.794\n",
      "  1.    1.   ]\n",
      " [0.571 0.263 0.787 0.257 0.125 0.652 0.563 0.283   nan 0.357 0.4   0.571\n",
      "  0.682 0.92 ]\n",
      " [0.968 0.15    nan 1.    0.419 0.737 0.34  0.667 0.813 1.    1.    0.545\n",
      "  0.984 1.   ]\n",
      " [0.632   nan 1.    0.5   0.484 1.    0.53  1.    0.25  0.846 0.84  0.343\n",
      "  0.93  0.487]\n",
      " [0.937 0.54  1.    0.963 0.664 0.027 1.      nan 0.467 1.    1.    0.721\n",
      "  0.935 1.   ]\n",
      " [1.    0.25  0.763 1.    1.    1.      nan 1.    0.34  1.    1.    0.455\n",
      "  1.    0.907]\n",
      " [0.743   nan 1.    0.5   0.25  0.6   0.64  1.    0.49  0.7   0.2   0.571\n",
      "  0.806 0.907]\n",
      " [0.158 0.16  0.63  0.488 0.271 0.442 0.153 0.353 0.05  0.415 0.8     nan\n",
      "  0.437 0.3  ]\n",
      " [  nan 1.    1.    0.214 0.2   0.19  0.85  0.05  0.2   0.2   0.    0.464\n",
      "  0.455 0.467]\n",
      " [0.829 0.61  1.    0.585 0.33  0.537 0.37  1.    0.35  0.371   nan 0.421\n",
      "  0.794 0.927]\n",
      " [0.629 0.18  1.    0.386 0.19  0.61  0.275 0.25    nan 0.728 1.    0.357\n",
      "  0.594 1.   ]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 16\n",
      "Average improvement: 0.485\n",
      "Standard deviation: 0.2908039431186127\n",
      "prediction score:  [[0.632 0.36  1.    1.    0.361 0.667 0.278 0.333 0.16  0.538 1.    0.376\n",
      "  0.806 0.3  ]\n",
      " [0.429 0.05  1.    0.2   0.04  0.568 0.57  0.817 0.05  0.493 1.    0.286\n",
      "  0.582 0.554]\n",
      " [1.    0.    1.    0.157 0.    0.053 0.55  0.85  0.16  0.272 1.    0.143\n",
      "  0.206 0.874]\n",
      " [0.443 0.55  0.815 0.95  0.477 0.12  0.844 0.917 0.42  0.823 0.76  0.382\n",
      "  0.47  0.853]\n",
      " [1.    1.    0.415 0.388 0.174 0.88  0.278 0.647 1.    1.    1.    0.182\n",
      "  0.773 0.96 ]\n",
      " [0.429 0.35  1.    0.172 0.04  0.232 0.5   0.55  0.2   0.4   1.    0.364\n",
      "  0.218 0.047]\n",
      " [1.    1.    1.    1.    0.755 0.347 0.889 1.    1.    1.    1.    0.794\n",
      "  1.    1.   ]\n",
      " [0.571 0.263 0.787 0.257 0.125 0.652 0.563 0.283 0.85  0.357 0.4   0.571\n",
      "  0.682 0.92 ]\n",
      " [0.968 0.15  0.593 1.    0.419 0.737 0.34  0.667 0.813 1.    1.    0.545\n",
      "  0.984 1.   ]\n",
      " [0.632 0.    1.    0.5   0.484 1.    0.53  1.    0.25  0.846 0.84  0.343\n",
      "  0.93  0.487]\n",
      " [0.937 0.54  1.    0.963 0.664 0.027 1.    0.    0.467 1.    1.    0.721\n",
      "  0.935 1.   ]\n",
      " [1.    0.25  0.763 1.    1.    1.    0.556 1.    0.34  1.    1.    0.455\n",
      "  1.    0.907]\n",
      " [0.743 0.55  1.    0.5   0.25  0.6   0.64  1.    0.49  0.7   0.2   0.571\n",
      "  0.806 0.907]\n",
      " [0.158 0.16  0.63  0.488 0.271 0.442 0.153 0.353 0.05  0.415 0.8   0.697\n",
      "  0.437 0.3  ]\n",
      " [0.714 1.    1.    0.214 0.2   0.19  0.85  0.05  0.2   0.2   0.    0.464\n",
      "  0.545 0.467]\n",
      " [0.829 0.61  1.    0.585 0.33  0.537 0.37  1.    0.35  0.386 0.4   0.421\n",
      "  0.794 0.927]\n",
      " [0.629 0.18  1.    0.386 0.19  0.61  0.275 0.25  0.9   0.728 1.    0.357\n",
      "  0.594 1.   ]]\n",
      "current score:  [[0.632 0.36  1.    1.    0.361 0.667   nan 0.333 0.16  0.538 1.    0.376\n",
      "  0.806 0.3  ]\n",
      " [0.429   nan 1.    0.2   0.04  0.568 0.57  0.817 0.05  0.493 1.    0.286\n",
      "  0.582 0.554]\n",
      " [1.      nan 1.    0.157 0.    0.053 0.55  0.85  0.16  0.272 1.    0.143\n",
      "  0.206 0.874]\n",
      " [0.443   nan 0.815 0.95  0.477 0.12  0.844 0.917 0.42  0.823 0.76  0.382\n",
      "  0.47  0.853]\n",
      " [1.    1.    0.415 0.388 0.174 0.88    nan 0.647 1.    1.    1.    0.182\n",
      "  0.773 0.96 ]\n",
      " [0.429   nan 1.    0.172 0.04  0.232 0.5   0.55  0.2   0.4   1.    0.364\n",
      "  0.218 0.047]\n",
      " [1.    1.    1.    1.    0.755 0.347   nan 1.    1.    1.    1.    0.794\n",
      "  1.    1.   ]\n",
      " [0.571 0.263 0.787 0.257 0.125 0.652 0.563 0.283   nan 0.357 0.4   0.571\n",
      "  0.682 0.92 ]\n",
      " [0.968 0.15    nan 1.    0.419 0.737 0.34  0.667 0.813 1.    1.    0.545\n",
      "  0.984 1.   ]\n",
      " [0.632   nan 1.    0.5   0.484 1.    0.53  1.    0.25  0.846 0.84  0.343\n",
      "  0.93  0.487]\n",
      " [0.937 0.54  1.    0.963 0.664 0.027 1.      nan 0.467 1.    1.    0.721\n",
      "  0.935 1.   ]\n",
      " [1.    0.25  0.763 1.    1.    1.      nan 1.    0.34  1.    1.    0.455\n",
      "  1.    0.907]\n",
      " [0.743   nan 1.    0.5   0.25  0.6   0.64  1.    0.49  0.7   0.2   0.571\n",
      "  0.806 0.907]\n",
      " [0.158 0.16  0.63  0.488 0.271 0.442 0.153 0.353 0.05  0.415 0.8     nan\n",
      "  0.437 0.3  ]\n",
      " [  nan 1.    1.    0.214 0.2   0.19  0.85  0.05  0.2   0.2   0.    0.464\n",
      "  0.455 0.467]\n",
      " [0.829 0.61  1.    0.585 0.33  0.537 0.37  1.    0.35  0.371   nan 0.421\n",
      "  0.794 0.927]\n",
      " [0.629 0.18  1.    0.386 0.19  0.61  0.275 0.25    nan 0.728 1.    0.357\n",
      "  0.594 1.   ]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 16\n",
      "Average improvement: 0.485\n",
      "Standard deviation: 0.2908039431186127\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[-8.02054256e-03  1.63458586e-02 -1.98027603e-02 ... -4.14815545e-03\n",
      "   2.99156271e-03 -6.64595049e-03]\n",
      " [-8.12599808e-03  1.11320615e-02 -1.57452077e-02 ...  1.14369392e-03\n",
      "  -3.73756280e-03  1.92474015e-03]\n",
      " [-9.03429091e-03  5.86763024e-04 -2.07874887e-02 ... -9.53594595e-03\n",
      "  -1.27486978e-02  5.62111437e-01]\n",
      " ...\n",
      " [ 1.19310021e-02 -3.34338844e-03 -8.30385834e-05 ...  1.14395097e-02\n",
      "  -7.98163377e-03 -3.06342077e-03]\n",
      " [-2.90708989e-03 -8.88518989e-04 -3.16262804e-03 ...  6.95768744e-03\n",
      "  -1.18913725e-02  5.60878575e-01]\n",
      " [-3.33391130e-03 -7.39455968e-03  5.27310651e-03 ...  1.16848946e-03\n",
      "  -2.27285759e-03  5.77157915e-01]]\n",
      "current score:  [[0.526 0.02  0.148 ... 0.127 0.081 1.   ]\n",
      " [0.428 0.42  0.88  ... 0.457 0.291 0.474]\n",
      " [0.789 0.39  0.852 ... 0.758 0.784   nan]\n",
      " ...\n",
      " [0.586 0.15  0.84  ... 0.286 0.515 0.633]\n",
      " [0.474 0.16  0.948 ... 0.394 0.297   nan]\n",
      " [0.779 0.91  1.    ... 0.346 0.865   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 21428\n",
      "Average improvement: 0.4948536288149659\n",
      "Standard deviation: 0.07699843921899606\n",
      "prediction score:  [[-8.02054256e-03  1.63458586e-02 -1.98027603e-02 ... -4.14815545e-03\n",
      "   2.99156271e-03 -6.64595049e-03]\n",
      " [-8.12599808e-03  1.11320615e-02 -1.57452077e-02 ...  1.14369392e-03\n",
      "  -3.73756280e-03  1.92474015e-03]\n",
      " [-9.03429091e-03  5.86763024e-04 -2.07874887e-02 ... -9.53594595e-03\n",
      "  -1.27486978e-02  5.62111437e-01]\n",
      " ...\n",
      " [ 1.19310021e-02 -3.34338844e-03 -8.30385834e-05 ...  1.14395097e-02\n",
      "  -7.98163377e-03 -3.06342077e-03]\n",
      " [-2.90708989e-03 -8.88518989e-04 -3.16262804e-03 ...  6.95768744e-03\n",
      "  -1.18913725e-02  5.60878575e-01]\n",
      " [-3.33391130e-03 -7.39455968e-03  5.27310651e-03 ...  1.16848946e-03\n",
      "  -2.27285759e-03  5.77157915e-01]]\n",
      "current score:  [[0.526 0.02  0.148 ... 0.127 0.081 1.   ]\n",
      " [0.428 0.42  0.88  ... 0.457 0.291 0.474]\n",
      " [0.789 0.39  0.852 ... 0.758 0.784   nan]\n",
      " ...\n",
      " [0.586 0.15  0.84  ... 0.286 0.515 0.633]\n",
      " [0.474 0.16  0.948 ... 0.394 0.297   nan]\n",
      " [0.779 0.91  1.    ... 0.346 0.865   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 21428\n",
      "Average improvement: 0.4948536288149659\n",
      "Standard deviation: 0.07699843921899606\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.56211144]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.56087857]\n",
      " [0.         0.         0.         ... 0.         0.         0.57715791]]\n",
      "current score:  [[0.526 0.02  0.148 ... 0.127 0.081 1.   ]\n",
      " [0.428 0.42  0.88  ... 0.457 0.291 0.474]\n",
      " [0.789 0.39  0.852 ... 0.758 0.784   nan]\n",
      " ...\n",
      " [0.586 0.15  0.84  ... 0.286 0.515 0.633]\n",
      " [0.474 0.16  0.948 ... 0.394 0.297   nan]\n",
      " [0.779 0.91  1.    ... 0.346 0.865   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 21428\n",
      "Average improvement: 0.4948536288149659\n",
      "Standard deviation: 0.07699843921899606\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.56211144]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.56087857]\n",
      " [0.         0.         0.         ... 0.         0.         0.57715791]]\n",
      "current score:  [[0.526 0.02  0.148 ... 0.127 0.081 1.   ]\n",
      " [0.428 0.42  0.88  ... 0.457 0.291 0.474]\n",
      " [0.789 0.39  0.852 ... 0.758 0.784   nan]\n",
      " ...\n",
      " [0.586 0.15  0.84  ... 0.286 0.515 0.633]\n",
      " [0.474 0.16  0.948 ... 0.394 0.297   nan]\n",
      " [0.779 0.91  1.    ... 0.346 0.865   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 21428\n",
      "Average improvement: 0.4948536288149659\n",
      "Standard deviation: 0.07699843921899606\n",
      "========= 2 missing\n",
      "----ground truth----\n",
      "prediction score:  [[0.705 0.24  1.    0.463 0.22  0.4   0.86  0.388 0.12  0.435 0.76  0.429\n",
      "  0.667   nan]\n",
      " [0.557 0.37  0.96  0.571 0.3   0.463 0.79  0.75  0.15  0.6   1.    0.428\n",
      "  0.618   nan]\n",
      " [0.486 0.45  0.587 0.2   0.04  0.326 0.23  1.    0.37  0.393 0.84    nan\n",
      "  0.515 0.507]\n",
      " [0.357 0.78  0.907 0.286 0.2   0.8   1.    0.316 0.1   0.686   nan 0.136\n",
      "  0.473 0.5  ]\n",
      " [0.714 0.6     nan 0.571 0.3   0.863 0.88  1.    0.67  0.943 1.    0.864\n",
      "  0.782 0.9  ]\n",
      " [0.463 0.44  0.867 0.338 0.11  0.    0.278   nan 0.173 0.308 0.8   0.236\n",
      "  0.568 0.414]\n",
      " [0.357   nan 0.667 0.214 0.05  0.343 0.5   0.667 0.15  0.536 0.8   0.214\n",
      "  0.455 0.7  ]\n",
      " [0.415 0.16  0.773 0.228 0.06  0.684 0.2     nan 0.66  0.643 0.96  0.293\n",
      "  0.437 0.733]\n",
      " [0.737   nan 0.667 0.475 0.22  0.373 1.    0.059 0.267 0.715 1.    0.157\n",
      "  0.459 0.693]\n",
      " [1.    0.05  1.    0.328 0.05  0.105 0.2   1.      nan 0.393 1.    0.571\n",
      "  0.594 0.194]\n",
      " [0.671   nan 1.    0.371 0.25  1.    0.3   1.    0.05  0.5   1.    0.343\n",
      "  0.557 0.9  ]\n",
      " [  nan 0.25  0.096 0.475 0.219 0.013 0.133 0.118 0.155 0.354 0.04  0.\n",
      "  0.049 0.233]\n",
      " [0.089 0.4   0.4   0.157 0.03  0.316 0.5     nan 0.14  0.2   0.2   0.186\n",
      "  0.218 0.   ]\n",
      " [0.415   nan 0.534 0.229 0.06  0.716 0.    0.    0.05  0.643 1.    0.214\n",
      "  0.315 0.7  ]\n",
      " [0.071   nan 0.893 0.563 0.323 0.053 0.478 0.5   0.293 0.385 0.16  0.564\n",
      "  0.854 0.433]\n",
      " [0.585 1.    0.467 0.4   0.42  0.369 0.25  1.    0.65  0.286   nan 0.5\n",
      "  0.727 0.8  ]\n",
      " [1.      nan 0.933 0.643 0.35  0.81  0.76  0.533 0.43  0.736 1.    0.743\n",
      "  0.691 0.567]\n",
      " [0.429   nan 1.    0.386 0.27  0.295 0.35  1.    0.35  0.543 1.    0.379\n",
      "  0.691 0.533]\n",
      " [0.    0.01  0.    0.25  0.    0.    0.222   nan 0.    0.077 0.04  0.\n",
      "  0.    0.207]\n",
      " [0.5     nan 1.    0.343 0.26  0.716 0.2   0.667 0.42  0.514 1.    0.364\n",
      "  0.6   0.907]\n",
      " [0.663 0.17  0.726 0.575 0.322 0.067 0.944 0.635 0.253 0.777 1.    0.485\n",
      "  0.892   nan]\n",
      " [0.329 0.55  0.573 0.129   nan 0.39  0.38  0.    0.2   0.514 1.    0.264\n",
      "  0.431 0.707]\n",
      " [0.053 0.07  0.893 0.143 0.    0.158 0.15  0.417 0.05  0.143   nan 0.3\n",
      "  0.533 0.067]\n",
      " [0.585   nan 1.    0.571 0.3   0.842 0.93  0.667 0.5   0.765 1.    0.393\n",
      "  0.721 0.68 ]\n",
      " [0.571   nan 1.    0.243 0.12  0.179 0.57  0.917 0.25  0.357 0.76  0.357\n",
      "  0.667 0.333]\n",
      " [0.357 0.31  0.827 0.2   0.04  0.221 0.56    nan 0.04  0.364 0.8   0.357\n",
      "  0.309 0.534]\n",
      " [0.114 0.4   0.213 0.2   0.04  0.537   nan 0.683 0.21  0.557 0.68  0.086\n",
      "  0.091 0.433]\n",
      " [0.271 0.01  0.733 0.172 0.03  0.2   0.17    nan 0.12  0.364 0.36  0.143\n",
      "  0.418 0.547]]\n",
      "current score:  [[0.705 0.24  1.    0.463 0.22  0.4   0.86    nan 0.12  0.435 0.76  0.429\n",
      "  0.667   nan]\n",
      " [0.557 0.37  0.96  0.571 0.3   0.463 0.79    nan 0.15  0.6   1.    0.428\n",
      "  0.618   nan]\n",
      " [0.486   nan 0.587 0.2   0.04  0.326 0.23  1.    0.37  0.393 0.84    nan\n",
      "  0.515 0.507]\n",
      " [0.357 0.78  0.907 0.286 0.2   0.8   1.      nan 0.1   0.686   nan 0.136\n",
      "  0.473 0.5  ]\n",
      " [0.714   nan   nan 0.571 0.3   0.863 0.88  1.    0.67  0.943 1.    0.864\n",
      "  0.782 0.9  ]\n",
      " [0.463 0.44  0.867 0.338 0.11  0.      nan   nan 0.173 0.308 0.8   0.236\n",
      "  0.568 0.414]\n",
      " [0.357   nan 0.667 0.214 0.05  0.053   nan 0.667 0.15  0.536 0.8   0.214\n",
      "  0.455 0.7  ]\n",
      " [0.415 0.16  0.773 0.228 0.06  0.684   nan   nan 0.66  0.643 0.96  0.293\n",
      "  0.437 0.733]\n",
      " [0.737   nan 0.667 0.475 0.22  0.373 1.      nan 0.267 0.715 1.    0.157\n",
      "  0.459 0.693]\n",
      " [1.      nan 1.    0.328 0.05  0.105 0.2   1.      nan 0.393 1.    0.571\n",
      "  0.594 0.194]\n",
      " [0.671   nan 1.    0.371 0.25  1.    0.3   1.      nan 0.5   1.    0.343\n",
      "  0.557 0.9  ]\n",
      " [  nan   nan 0.096 0.475 0.219 0.013 0.133 0.118 0.155 0.354 0.04  0.\n",
      "  0.049 0.233]\n",
      " [0.089   nan 0.4   0.157 0.03  0.316 0.5     nan 0.14  0.2   0.2   0.186\n",
      "  0.218 0.   ]\n",
      " [0.415   nan 0.534 0.229 0.06  0.716 0.    0.      nan 0.643 1.    0.214\n",
      "  0.315 0.7  ]\n",
      " [0.071   nan 0.893 0.563 0.323 0.053 0.478 0.5     nan 0.385 0.16  0.564\n",
      "  0.854 0.433]\n",
      " [0.585 1.      nan 0.4   0.42  0.369 0.25  1.    0.65  0.286   nan 0.5\n",
      "  0.727 0.8  ]\n",
      " [1.      nan 0.933 0.643 0.35  0.81  0.76  0.533 0.43  0.736 1.    0.743\n",
      "  0.691   nan]\n",
      " [0.429   nan 1.    0.386 0.27  0.295 0.35  1.      nan 0.543 1.    0.379\n",
      "  0.691 0.533]\n",
      " [0.    0.01  0.    0.25  0.    0.      nan   nan 0.    0.077 0.04  0.\n",
      "  0.    0.207]\n",
      " [0.5     nan 1.    0.343 0.26  0.705 0.2     nan 0.42  0.514 1.    0.364\n",
      "  0.6   0.907]\n",
      " [0.663 0.17  0.726 0.575 0.322 0.067 0.944   nan 0.253 0.777 1.    0.485\n",
      "  0.892   nan]\n",
      " [0.329 0.55  0.573 0.129   nan 0.39  0.38    nan 0.2   0.514 1.    0.264\n",
      "  0.431 0.707]\n",
      " [  nan 0.07  0.893 0.143 0.    0.158 0.15  0.417 0.05  0.143   nan 0.3\n",
      "  0.533 0.067]\n",
      " [0.585   nan 1.    0.571 0.3   0.821 0.93    nan 0.5   0.765 1.    0.393\n",
      "  0.721 0.68 ]\n",
      " [0.571   nan 1.    0.243 0.12  0.179 0.57  0.917   nan 0.357 0.76  0.357\n",
      "  0.685 0.333]\n",
      " [0.357 0.31  0.827 0.2   0.04  0.221 0.56    nan 0.04  0.364 0.8   0.357\n",
      "  0.309   nan]\n",
      " [0.114   nan 0.213 0.2   0.04  0.537   nan 0.683 0.21  0.557 0.68  0.086\n",
      "  0.091 0.433]\n",
      " [0.271 0.01  0.733 0.172 0.03  0.2   0.17    nan 0.12  0.364 0.36  0.143\n",
      "  0.418   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Number of predicted domains: 31\n",
      "Average improvement: 0.33216129032258074\n",
      "Standard deviation: 0.22662554971791293\n",
      "prediction score:  [[0.705 0.24  1.    0.463 0.22  0.4   0.86  0.388 0.12  0.435 0.76  0.429\n",
      "  0.667   nan]\n",
      " [0.557 0.37  0.96  0.571 0.3   0.463 0.79  0.75  0.15  0.6   1.    0.428\n",
      "  0.618   nan]\n",
      " [0.486 0.45  0.587 0.2   0.04  0.326 0.23  1.    0.37  0.393 0.84    nan\n",
      "  0.515 0.507]\n",
      " [0.357 0.78  0.907 0.286 0.2   0.8   1.    0.316 0.1   0.686   nan 0.136\n",
      "  0.473 0.5  ]\n",
      " [0.714 0.6     nan 0.571 0.3   0.863 0.88  1.    0.67  0.943 1.    0.864\n",
      "  0.782 0.9  ]\n",
      " [0.463 0.44  0.867 0.338 0.11  0.    0.278   nan 0.173 0.308 0.8   0.236\n",
      "  0.568 0.414]\n",
      " [0.357   nan 0.667 0.214 0.05  0.343 0.5   0.667 0.15  0.536 0.8   0.214\n",
      "  0.455 0.7  ]\n",
      " [0.415 0.16  0.773 0.228 0.06  0.684 0.2     nan 0.66  0.643 0.96  0.293\n",
      "  0.437 0.733]\n",
      " [0.737   nan 0.667 0.475 0.22  0.373 1.    0.059 0.267 0.715 1.    0.157\n",
      "  0.459 0.693]\n",
      " [1.    0.05  1.    0.328 0.05  0.105 0.2   1.      nan 0.393 1.    0.571\n",
      "  0.594 0.194]\n",
      " [0.671   nan 1.    0.371 0.25  1.    0.3   1.    0.05  0.5   1.    0.343\n",
      "  0.557 0.9  ]\n",
      " [  nan 0.25  0.096 0.475 0.219 0.013 0.133 0.118 0.155 0.354 0.04  0.\n",
      "  0.049 0.233]\n",
      " [0.089 0.4   0.4   0.157 0.03  0.316 0.5     nan 0.14  0.2   0.2   0.186\n",
      "  0.218 0.   ]\n",
      " [0.415   nan 0.534 0.229 0.06  0.716 0.    0.    0.05  0.643 1.    0.214\n",
      "  0.315 0.7  ]\n",
      " [0.071   nan 0.893 0.563 0.323 0.053 0.478 0.5   0.293 0.385 0.16  0.564\n",
      "  0.854 0.433]\n",
      " [0.585 1.    0.467 0.4   0.42  0.369 0.25  1.    0.65  0.286   nan 0.5\n",
      "  0.727 0.8  ]\n",
      " [1.      nan 0.933 0.643 0.35  0.81  0.76  0.533 0.43  0.736 1.    0.743\n",
      "  0.691 0.567]\n",
      " [0.429   nan 1.    0.386 0.27  0.295 0.35  1.    0.35  0.543 1.    0.379\n",
      "  0.691 0.533]\n",
      " [0.    0.01  0.    0.25  0.    0.    0.222   nan 0.    0.077 0.04  0.\n",
      "  0.    0.207]\n",
      " [0.5     nan 1.    0.343 0.26  0.716 0.2   0.667 0.42  0.514 1.    0.364\n",
      "  0.6   0.907]\n",
      " [0.663 0.17  0.726 0.575 0.322 0.067 0.944 0.635 0.253 0.777 1.    0.485\n",
      "  0.892   nan]\n",
      " [0.329 0.55  0.573 0.129   nan 0.39  0.38  0.    0.2   0.514 1.    0.264\n",
      "  0.431 0.707]\n",
      " [0.053 0.07  0.893 0.143 0.    0.158 0.15  0.417 0.05  0.143   nan 0.3\n",
      "  0.533 0.067]\n",
      " [0.585   nan 1.    0.571 0.3   0.842 0.93  0.667 0.5   0.765 1.    0.393\n",
      "  0.721 0.68 ]\n",
      " [0.571   nan 1.    0.243 0.12  0.179 0.57  0.917 0.25  0.357 0.76  0.357\n",
      "  0.667 0.333]\n",
      " [0.357 0.31  0.827 0.2   0.04  0.221 0.56    nan 0.04  0.364 0.8   0.357\n",
      "  0.309 0.534]\n",
      " [0.114 0.4   0.213 0.2   0.04  0.537   nan 0.683 0.21  0.557 0.68  0.086\n",
      "  0.091 0.433]\n",
      " [0.271 0.01  0.733 0.172 0.03  0.2   0.17    nan 0.12  0.364 0.36  0.143\n",
      "  0.418 0.547]]\n",
      "current score:  [[0.705 0.24  1.    0.463 0.22  0.4   0.86    nan 0.12  0.435 0.76  0.429\n",
      "  0.667   nan]\n",
      " [0.557 0.37  0.96  0.571 0.3   0.463 0.79    nan 0.15  0.6   1.    0.428\n",
      "  0.618   nan]\n",
      " [0.486   nan 0.587 0.2   0.04  0.326 0.23  1.    0.37  0.393 0.84    nan\n",
      "  0.515 0.507]\n",
      " [0.357 0.78  0.907 0.286 0.2   0.8   1.      nan 0.1   0.686   nan 0.136\n",
      "  0.473 0.5  ]\n",
      " [0.714   nan   nan 0.571 0.3   0.863 0.88  1.    0.67  0.943 1.    0.864\n",
      "  0.782 0.9  ]\n",
      " [0.463 0.44  0.867 0.338 0.11  0.      nan   nan 0.173 0.308 0.8   0.236\n",
      "  0.568 0.414]\n",
      " [0.357   nan 0.667 0.214 0.05  0.053   nan 0.667 0.15  0.536 0.8   0.214\n",
      "  0.455 0.7  ]\n",
      " [0.415 0.16  0.773 0.228 0.06  0.684   nan   nan 0.66  0.643 0.96  0.293\n",
      "  0.437 0.733]\n",
      " [0.737   nan 0.667 0.475 0.22  0.373 1.      nan 0.267 0.715 1.    0.157\n",
      "  0.459 0.693]\n",
      " [1.      nan 1.    0.328 0.05  0.105 0.2   1.      nan 0.393 1.    0.571\n",
      "  0.594 0.194]\n",
      " [0.671   nan 1.    0.371 0.25  1.    0.3   1.      nan 0.5   1.    0.343\n",
      "  0.557 0.9  ]\n",
      " [  nan   nan 0.096 0.475 0.219 0.013 0.133 0.118 0.155 0.354 0.04  0.\n",
      "  0.049 0.233]\n",
      " [0.089   nan 0.4   0.157 0.03  0.316 0.5     nan 0.14  0.2   0.2   0.186\n",
      "  0.218 0.   ]\n",
      " [0.415   nan 0.534 0.229 0.06  0.716 0.    0.      nan 0.643 1.    0.214\n",
      "  0.315 0.7  ]\n",
      " [0.071   nan 0.893 0.563 0.323 0.053 0.478 0.5     nan 0.385 0.16  0.564\n",
      "  0.854 0.433]\n",
      " [0.585 1.      nan 0.4   0.42  0.369 0.25  1.    0.65  0.286   nan 0.5\n",
      "  0.727 0.8  ]\n",
      " [1.      nan 0.933 0.643 0.35  0.81  0.76  0.533 0.43  0.736 1.    0.743\n",
      "  0.691   nan]\n",
      " [0.429   nan 1.    0.386 0.27  0.295 0.35  1.      nan 0.543 1.    0.379\n",
      "  0.691 0.533]\n",
      " [0.    0.01  0.    0.25  0.    0.      nan   nan 0.    0.077 0.04  0.\n",
      "  0.    0.207]\n",
      " [0.5     nan 1.    0.343 0.26  0.705 0.2     nan 0.42  0.514 1.    0.364\n",
      "  0.6   0.907]\n",
      " [0.663 0.17  0.726 0.575 0.322 0.067 0.944   nan 0.253 0.777 1.    0.485\n",
      "  0.892   nan]\n",
      " [0.329 0.55  0.573 0.129   nan 0.39  0.38    nan 0.2   0.514 1.    0.264\n",
      "  0.431 0.707]\n",
      " [  nan 0.07  0.893 0.143 0.    0.158 0.15  0.417 0.05  0.143   nan 0.3\n",
      "  0.533 0.067]\n",
      " [0.585   nan 1.    0.571 0.3   0.821 0.93    nan 0.5   0.765 1.    0.393\n",
      "  0.721 0.68 ]\n",
      " [0.571   nan 1.    0.243 0.12  0.179 0.57  0.917   nan 0.357 0.76  0.357\n",
      "  0.685 0.333]\n",
      " [0.357 0.31  0.827 0.2   0.04  0.221 0.56    nan 0.04  0.364 0.8   0.357\n",
      "  0.309   nan]\n",
      " [0.114   nan 0.213 0.2   0.04  0.537   nan 0.683 0.21  0.557 0.68  0.086\n",
      "  0.091 0.433]\n",
      " [0.271 0.01  0.733 0.172 0.03  0.2   0.17    nan 0.12  0.364 0.36  0.143\n",
      "  0.418   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Number of predicted domains: 31\n",
      "Average improvement: 0.33216129032258074\n",
      "Standard deviation: 0.22662554971791293\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[-1.1279359e-03  4.3785647e-03  4.6243062e-03 ...  8.2330853e-03\n",
      "   2.2454243e-03 -6.3229408e-03]\n",
      " [ 5.1338077e-03 -7.9809129e-04  1.0759812e-03 ... -8.8808388e-03\n",
      "   1.0761055e-03  1.0433998e-03]\n",
      " [-1.0360666e-02  3.5547465e-04  1.1567541e-02 ... -1.5127875e-02\n",
      "   1.9370117e-03  4.7205454e-03]\n",
      " ...\n",
      " [ 1.7551564e-02  5.4880306e-03  5.4145316e-03 ...  2.2415966e-03\n",
      "   1.0740623e-02 -7.2421962e-03]\n",
      " [-2.6762486e-05 -7.0646331e-03 -2.2122916e-03 ...  1.3565421e-03\n",
      "  -4.7620032e-03  1.6278205e-03]\n",
      " [ 1.1778899e-02 -1.5743673e-02  4.1975873e-03 ...  1.6993210e-02\n",
      "  -1.0571217e-02 -5.3438162e-03]]\n",
      "current score:  [[0.857 0.85  0.947 ... 0.286 0.758   nan]\n",
      " [0.514 0.78  0.814 ... 0.464 0.388   nan]\n",
      " [0.916 1.    1.    ... 0.715 0.935   nan]\n",
      " ...\n",
      " [1.    1.    1.    ... 0.667 1.    0.74 ]\n",
      " [0.642 0.71  1.    ... 0.455 0.865 1.   ]\n",
      " [0.8     nan 0.926 ... 0.34  0.811 0.826]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 14721\n",
      "Average improvement: 0.49111671153516456\n",
      "Standard deviation: 0.0827273517548758\n",
      "prediction score:  [[-1.1279359e-03  4.3785647e-03  4.6243062e-03 ...  8.2330853e-03\n",
      "   2.2454243e-03 -6.3229408e-03]\n",
      " [ 5.1338077e-03 -7.9809129e-04  1.0759812e-03 ... -8.8808388e-03\n",
      "   1.0761055e-03  1.0433998e-03]\n",
      " [-1.0360666e-02  3.5547465e-04  1.1567541e-02 ... -1.5127875e-02\n",
      "   1.9370117e-03  4.7205454e-03]\n",
      " ...\n",
      " [ 1.7551564e-02  5.4880306e-03  5.4145316e-03 ...  2.2415966e-03\n",
      "   1.0740623e-02 -7.2421962e-03]\n",
      " [-2.6762486e-05 -7.0646331e-03 -2.2122916e-03 ...  1.3565421e-03\n",
      "  -4.7620032e-03  1.6278205e-03]\n",
      " [ 1.1778899e-02 -1.5743673e-02  4.1975873e-03 ...  1.6993210e-02\n",
      "  -1.0571217e-02 -5.3438162e-03]]\n",
      "current score:  [[0.857 0.85  0.947 ... 0.286 0.758   nan]\n",
      " [0.514 0.78  0.814 ... 0.464 0.388   nan]\n",
      " [0.916 1.    1.    ... 0.715 0.935   nan]\n",
      " ...\n",
      " [1.    1.    1.    ... 0.667 1.    0.74 ]\n",
      " [0.642 0.71  1.    ... 0.455 0.865 1.   ]\n",
      " [0.8     nan 0.926 ... 0.34  0.811 0.826]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 14721\n",
      "Average improvement: 0.49111671153516456\n",
      "Standard deviation: 0.0827273517548758\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "current score:  [[0.857 0.85  0.947 ... 0.286 0.758   nan]\n",
      " [0.514 0.78  0.814 ... 0.464 0.388   nan]\n",
      " [0.916 1.    1.    ... 0.715 0.935   nan]\n",
      " ...\n",
      " [1.    1.    1.    ... 0.667 1.    0.74 ]\n",
      " [0.642 0.71  1.    ... 0.455 0.865 1.   ]\n",
      " [0.8     nan 0.926 ... 0.34  0.811 0.826]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 14721\n",
      "Average improvement: 0.5300208905085574\n",
      "Standard deviation: 0.07796602677625232\n",
      "prediction score:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "current score:  [[0.857 0.85  0.947 ... 0.286 0.758   nan]\n",
      " [0.514 0.78  0.814 ... 0.464 0.388   nan]\n",
      " [0.916 1.    1.    ... 0.715 0.935   nan]\n",
      " ...\n",
      " [1.    1.    1.    ... 0.667 1.    0.74 ]\n",
      " [0.642 0.71  1.    ... 0.455 0.865 1.   ]\n",
      " [0.8     nan 0.926 ... 0.34  0.811 0.826]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 14721\n",
      "Average improvement: 0.5300208905085574\n",
      "Standard deviation: 0.07796602677625232\n",
      "========= 3 missing\n",
      "----ground truth----\n",
      "prediction score:  [[0.105 0.2   0.526 0.213 0.032 0.19  0.133   nan 0.16  0.215 0.64    nan\n",
      "  0.373 0.74 ]\n",
      " [0.486   nan 0.817 0.25  0.175 0.747 0.2     nan 0.25  0.585 1.    0.304\n",
      "  0.44  0.8  ]\n",
      " [0.211 0.37  0.63  0.725 0.432 0.013 0.5     nan 0.267 0.731 1.    0.346\n",
      "  0.427   nan]\n",
      " [1.    0.81  0.896 1.    0.587 0.667   nan 1.    0.933 0.315 0.2   0.509\n",
      "  0.892   nan]\n",
      " [0.632 0.41  0.682 0.575 0.161 0.      nan 0.    0.28  0.316   nan 0.152\n",
      "  0.568 0.713]\n",
      " [0.528   nan 0.6   0.228 0.08  0.326   nan 0.667 0.22  0.328 1.    0.226\n",
      "  0.358 0.774]\n",
      " [0.829 0.    0.667 0.529 0.27  1.    0.85  1.    0.92  0.729 1.    0.214\n",
      "    nan 0.7  ]\n",
      " [0.357 0.    0.667 0.214 0.05  0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.529   nan 0.76  0.429 0.3   0.789 0.41  0.854   nan 0.621 1.    0.257\n",
      "  0.648 0.893]\n",
      " [0.357 0.    0.667 0.    0.    0.684   nan   nan 0.    0.25  0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.5   0.3   1.    0.157   nan 0.158 0.2     nan 0.3   0.629 1.    0.328\n",
      "  0.63  1.   ]\n",
      " [1.    0.35  0.867 0.4     nan 0.579 0.64  1.    0.52  0.486 1.      nan\n",
      "  0.545 0.926]\n",
      " [0.337   nan 0.867 0.613 0.49  0.2     nan 0.071 0.866 0.569 0.92  0.455\n",
      "  0.676 0.94 ]\n",
      " [0.428 0.31    nan 0.143 0.    0.579 0.05  0.433 0.42  0.364   nan 0.036\n",
      "  0.376 0.28 ]\n",
      " [0.415   nan   nan 0.2   0.04  0.947 0.82  0.383 0.025 0.564 1.    0.107\n",
      "  0.212 0.52 ]\n",
      " [1.      nan 1.    0.871 0.8   0.158 0.5     nan 0.49  0.679 1.    0.929\n",
      "  0.788 0.733]\n",
      " [0.557   nan 0.747 0.5   0.39  0.516   nan 1.    0.35  0.521 1.    0.314\n",
      "  0.448 0.813]\n",
      " [0.429 0.    0.037 0.388 0.258 0.    0.39  0.616   nan 0.516 0.76    nan\n",
      "  0.    0.267]\n",
      " [0.571 0.6   1.    0.214 0.05  0.926   nan 0.833 0.26  0.957   nan 0.036\n",
      "  0.636 1.   ]\n",
      " [0.789   nan 1.    0.6   0.284 1.    0.9   1.    0.746 0.415 1.    0.624\n",
      "  0.897   nan]\n",
      " [0.371   nan 0.8   0.214 0.05  0.274 0.5   0.3     nan 0.478 0.84  0.257\n",
      "  0.576 0.18 ]\n",
      " [1.    0.    0.44  0.5   0.25  0.706 0.51  1.    0.    0.807   nan   nan\n",
      "  0.442 0.893]\n",
      " [0.171 0.18  0.413 0.214 0.05  0.39  0.51    nan 0.02  0.328 0.4     nan\n",
      "  0.273 0.74 ]\n",
      " [0.3   0.33  0.894 0.057   nan 0.137 0.47    nan 0.15  0.028 0.48  0.286\n",
      "  0.467 0.667]\n",
      " [0.429   nan 0.467 0.586 0.31  0.211 0.2     nan 0.55  0.378 1.    0.607\n",
      "  0.455 0.893]\n",
      " [0.779   nan 0.333 0.438 0.155 1.    0.111 1.    0.2   0.562 0.96  0.036\n",
      "  0.498   nan]\n",
      " [0.393 0.23  0.741 0.157 0.    0.179 0.25    nan 0.04  0.386 0.76    nan\n",
      "  0.514 0.667]\n",
      " [0.543   nan 0.933 0.3   0.05  0.59  0.46  0.583 0.32  0.657 1.    0.393\n",
      "  0.351   nan]\n",
      " [0.357 0.4   0.72  0.272 0.088 0.758   nan   nan 0.163 0.479 0.8   0.243\n",
      "  0.327 0.858]\n",
      " [1.      nan 0.667 0.271 0.15  0.706 0.51  1.      nan 0.664 1.    0.857\n",
      "  0.679 0.953]\n",
      " [0.29  0.1   0.413 0.214 0.05  0.126 0.51  0.317 0.    0.115 0.4     nan\n",
      "  0.188 0.667]\n",
      " [0.557 0.72  0.68  0.228 0.27  0.221 0.19    nan 0.62  0.593 1.    0.036\n",
      "  0.515   nan]\n",
      " [0.6   0.5   1.      nan   nan 0.484 0.36  0.15  0.31  0.45  0.84  0.393\n",
      "  0.703 0.707]\n",
      " [0.357 0.43  0.667 0.228 0.1   0.284   nan   nan 0.1   0.243 0.32  0.657\n",
      "  0.242 0.74 ]\n",
      " [0.571 0.22  1.    0.228 0.08  0.726   nan 0.367 0.35  0.714   nan 0.515\n",
      "  0.551 0.46 ]\n",
      " [0.916   nan   nan 0.95  0.69  0.707 1.    0.    0.307 1.    1.    0.121\n",
      "  0.779 0.687]\n",
      " [0.5   0.51  0.733 0.543 0.29  0.737   nan   nan 0.    0.554 0.8   0.879\n",
      "  0.591 0.817]\n",
      " [0.329 0.1   0.496 0.2   0.077 0.295 0.111   nan 0.022 0.254 0.64    nan\n",
      "  0.432 0.527]\n",
      " [0.757 0.05  0.4   0.186 0.03  0.084 0.36  0.117   nan 0.307 1.    0.214\n",
      "  0.77    nan]\n",
      " [0.671   nan 1.    0.585 0.31  1.      nan 1.    0.27  0.728 1.    0.478\n",
      "  0.624 1.   ]\n",
      " [0.957   nan 0.6   0.286 0.125 0.284 0.66  1.    0.25  0.328   nan 0.179\n",
      "  0.406 0.587]\n",
      " [0.357 0.4   0.667 0.    0.    0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.733]\n",
      " [1.    0.05  0.587 0.643 0.5   0.368 0.317   nan   nan 0.279 1.    0.614\n",
      "  0.448 0.96 ]\n",
      " [1.    1.      nan 1.    0.6   0.8   0.74  1.    0.7   1.      nan 0.664\n",
      "  0.891 1.   ]\n",
      " [0.571 0.25  0.533 0.372 0.21  0.137   nan   nan 0.22  0.543 1.    0.286\n",
      "  0.255 0.78 ]\n",
      " [0.4   0.77  0.96  0.243 0.2   0.295 0.      nan 0.44  0.479 0.76  0.372\n",
      "  0.436   nan]\n",
      " [0.357   nan 0.667 0.214 0.05  0.158 0.5     nan 0.2   0.357 0.8   0.214\n",
      "  0.273 0.   ]]\n",
      "current score:  [[0.105 0.2     nan 0.213 0.032 0.19  0.133   nan 0.16  0.215 0.64    nan\n",
      "  0.438 0.74 ]\n",
      " [0.486   nan 0.817 0.25  0.175 0.737   nan   nan 0.25  0.585 1.    0.304\n",
      "  0.44  0.8  ]\n",
      " [0.211 0.37  0.63  0.725 0.432 0.013 0.5     nan   nan 0.731 1.    0.346\n",
      "  0.546   nan]\n",
      " [1.    0.81  0.896 1.    0.587 0.667   nan 1.    0.933 0.285   nan 0.509\n",
      "  0.892   nan]\n",
      " [  nan 0.41  0.682 0.575 0.161 0.      nan 0.    0.28  0.316   nan 0.152\n",
      "  0.568 0.713]\n",
      " [0.528   nan 0.6   0.228 0.08  0.326   nan   nan 0.22  0.328 1.    0.226\n",
      "  0.358 0.774]\n",
      " [0.829 0.      nan 0.529 0.27  1.    0.85  1.    0.92  0.729 1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.357   nan 0.667 0.214 0.05  0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.529   nan 0.76  0.429 0.3   0.789 0.41  0.854   nan 0.6     nan 0.257\n",
      "  0.648 0.893]\n",
      " [0.357   nan 0.667 0.    0.    0.684   nan   nan 0.    0.25  0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.5   0.3   1.    0.157   nan 0.158   nan   nan 0.3   0.629 1.    0.328\n",
      "  0.63  1.   ]\n",
      " [1.    0.35    nan 0.4     nan 0.579 0.64  1.    0.52  0.486 1.      nan\n",
      "  0.503 0.926]\n",
      " [0.337   nan 0.867 0.613 0.49    nan   nan 0.071 0.866 0.569 0.92  0.455\n",
      "  0.676 0.94 ]\n",
      " [0.428 0.31    nan 0.143 0.    0.579   nan 0.433 0.42  0.364   nan 0.036\n",
      "  0.376 0.28 ]\n",
      " [0.415   nan   nan 0.2   0.04  0.947 0.82  0.383 0.025 0.564 1.      nan\n",
      "  0.212 0.52 ]\n",
      " [1.      nan 1.    0.871 0.8   0.158   nan   nan 0.49  0.679 1.    0.929\n",
      "  0.788 0.733]\n",
      " [0.557   nan 0.747 0.5   0.39  0.516   nan   nan 0.35  0.521 1.    0.314\n",
      "  0.448 0.813]\n",
      " [0.429   nan 0.037 0.388 0.258 0.    0.39  0.616   nan 0.516 0.76    nan\n",
      "  0.    0.267]\n",
      " [0.571 0.6   1.    0.214 0.05  0.926   nan 0.833 0.26    nan   nan 0.036\n",
      "  0.636 1.   ]\n",
      " [0.789   nan 1.    0.6   0.284 1.    0.9   1.    0.746 0.354   nan 0.624\n",
      "  0.897   nan]\n",
      " [0.371   nan 0.773 0.214 0.05  0.274 0.5   0.3     nan 0.478 0.84  0.257\n",
      "    nan 0.18 ]\n",
      " [1.      nan 0.44  0.5   0.25  0.706 0.51  1.    0.    0.807   nan   nan\n",
      "  0.442 0.893]\n",
      " [0.171 0.18  0.413 0.214 0.05  0.39  0.51    nan   nan 0.328 0.4     nan\n",
      "  0.273 0.74 ]\n",
      " [0.3   0.33  0.894 0.057   nan 0.011   nan   nan 0.15  0.028 0.48  0.286\n",
      "  0.467 0.667]\n",
      " [0.429   nan 0.467 0.586 0.31  0.2     nan   nan 0.55  0.378 1.    0.607\n",
      "  0.455 0.893]\n",
      " [0.779   nan 0.333 0.438 0.155 1.      nan 1.    0.2   0.562 0.96  0.036\n",
      "  0.498   nan]\n",
      " [0.393 0.23    nan 0.157 0.    0.179 0.25    nan 0.04  0.386 0.76    nan\n",
      "  0.273 0.667]\n",
      " [0.543   nan 0.933 0.3   0.05  0.59  0.46    nan 0.32  0.657 1.    0.393\n",
      "  0.351   nan]\n",
      " [0.357   nan 0.72  0.272 0.088 0.758   nan   nan 0.163 0.479 0.8   0.243\n",
      "  0.327 0.858]\n",
      " [1.      nan   nan 0.271 0.15  0.706 0.51  1.      nan 0.664 1.    0.857\n",
      "  0.679 0.953]\n",
      " [  nan 0.1   0.413 0.214 0.05  0.126 0.51  0.317 0.    0.214   nan   nan\n",
      "  0.188 0.667]\n",
      " [0.557 0.72  0.68  0.228 0.27  0.221 0.19    nan 0.62  0.514   nan 0.036\n",
      "  0.515   nan]\n",
      " [0.6     nan 1.      nan   nan 0.484 0.36  0.15  0.31  0.45  0.84  0.393\n",
      "  0.703 0.707]\n",
      " [0.357 0.43  0.667 0.228   nan 0.284   nan   nan 0.1   0.243 0.32  0.657\n",
      "  0.242 0.74 ]\n",
      " [0.571 0.22  1.    0.228 0.08    nan   nan 0.367 0.35  0.714   nan 0.515\n",
      "  0.551 0.46 ]\n",
      " [0.916   nan   nan 0.95  0.69  0.707 1.    0.    0.307 1.    1.      nan\n",
      "  0.806 0.687]\n",
      " [0.5   0.51  0.733 0.543 0.29  0.737   nan   nan   nan 0.554 0.8   0.879\n",
      "  0.591 0.817]\n",
      " [0.329   nan 0.496 0.2   0.077 0.295 0.111   nan 0.022 0.254 0.64    nan\n",
      "  0.432 0.527]\n",
      " [0.757 0.05  0.4   0.186 0.03  0.084 0.36  0.117   nan 0.307 1.    0.214\n",
      "    nan   nan]\n",
      " [0.671   nan 1.    0.585 0.31  0.726   nan   nan 0.27  0.728 1.    0.478\n",
      "  0.624 1.   ]\n",
      " [0.957   nan 0.6   0.286 0.125 0.284 0.66  1.    0.25  0.328   nan   nan\n",
      "  0.406 0.587]\n",
      " [0.357   nan 0.667 0.    0.    0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.733]\n",
      " [1.      nan 0.587 0.643 0.5   0.368 0.317   nan   nan 0.279 1.    0.614\n",
      "  0.448 0.96 ]\n",
      " [1.    1.      nan 1.    0.6   0.8   0.74    nan 0.7   1.      nan 0.664\n",
      "  0.891 1.   ]\n",
      " [0.571   nan 0.533 0.372 0.21  0.137   nan   nan 0.22  0.543 1.    0.286\n",
      "  0.255 0.78 ]\n",
      " [0.4   0.77  0.96  0.243 0.2   0.284   nan   nan 0.44  0.479 0.76  0.372\n",
      "  0.436   nan]\n",
      " [0.357   nan 0.667 0.214 0.05  0.158   nan   nan 0.2   0.357 0.8   0.214\n",
      "  0.273 0.   ]]\n",
      "encoding:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 59\n",
      "Average improvement: 0.35645762711864404\n",
      "Standard deviation: 0.34050901664267574\n",
      "prediction score:  [[0.105 0.2   0.526 0.213 0.032 0.19  0.133   nan 0.16  0.215 0.64    nan\n",
      "  0.373 0.74 ]\n",
      " [0.486   nan 0.817 0.25  0.175 0.747 0.2     nan 0.25  0.585 1.    0.304\n",
      "  0.44  0.8  ]\n",
      " [0.211 0.37  0.63  0.725 0.432 0.013 0.5     nan 0.267 0.731 1.    0.346\n",
      "  0.427   nan]\n",
      " [1.    0.81  0.896 1.    0.587 0.667   nan 1.    0.933 0.315 0.2   0.509\n",
      "  0.892   nan]\n",
      " [0.632 0.41  0.682 0.575 0.161 0.      nan 0.    0.28  0.316   nan 0.152\n",
      "  0.568 0.713]\n",
      " [0.528   nan 0.6   0.228 0.08  0.326   nan 0.667 0.22  0.328 1.    0.226\n",
      "  0.358 0.774]\n",
      " [0.829 0.    0.667 0.529 0.27  1.    0.85  1.    0.92  0.729 1.    0.214\n",
      "    nan 0.7  ]\n",
      " [0.357 0.    0.667 0.214 0.05  0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.529   nan 0.76  0.429 0.3   0.789 0.41  0.854   nan 0.621 1.    0.257\n",
      "  0.648 0.893]\n",
      " [0.357 0.    0.667 0.    0.    0.684   nan   nan 0.    0.25  0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.5   0.3   1.    0.157   nan 0.158 0.2     nan 0.3   0.629 1.    0.328\n",
      "  0.63  1.   ]\n",
      " [1.    0.35  0.867 0.4     nan 0.579 0.64  1.    0.52  0.486 1.      nan\n",
      "  0.545 0.926]\n",
      " [0.337   nan 0.867 0.613 0.49  0.2     nan 0.071 0.866 0.569 0.92  0.455\n",
      "  0.676 0.94 ]\n",
      " [0.428 0.31    nan 0.143 0.    0.579 0.05  0.433 0.42  0.364   nan 0.036\n",
      "  0.376 0.28 ]\n",
      " [0.415   nan   nan 0.2   0.04  0.947 0.82  0.383 0.025 0.564 1.    0.107\n",
      "  0.212 0.52 ]\n",
      " [1.      nan 1.    0.871 0.8   0.158 0.5     nan 0.49  0.679 1.    0.929\n",
      "  0.788 0.733]\n",
      " [0.557   nan 0.747 0.5   0.39  0.516   nan 1.    0.35  0.521 1.    0.314\n",
      "  0.448 0.813]\n",
      " [0.429 0.    0.037 0.388 0.258 0.    0.39  0.616   nan 0.516 0.76    nan\n",
      "  0.    0.267]\n",
      " [0.571 0.6   1.    0.214 0.05  0.926   nan 0.833 0.26  0.957   nan 0.036\n",
      "  0.636 1.   ]\n",
      " [0.789   nan 1.    0.6   0.284 1.    0.9   1.    0.746 0.415 1.    0.624\n",
      "  0.897   nan]\n",
      " [0.371   nan 0.8   0.214 0.05  0.274 0.5   0.3     nan 0.478 0.84  0.257\n",
      "  0.576 0.18 ]\n",
      " [1.    0.    0.44  0.5   0.25  0.706 0.51  1.    0.    0.807   nan   nan\n",
      "  0.442 0.893]\n",
      " [0.171 0.18  0.413 0.214 0.05  0.39  0.51    nan 0.02  0.328 0.4     nan\n",
      "  0.273 0.74 ]\n",
      " [0.3   0.33  0.894 0.057   nan 0.137 0.47    nan 0.15  0.028 0.48  0.286\n",
      "  0.467 0.667]\n",
      " [0.429   nan 0.467 0.586 0.31  0.211 0.2     nan 0.55  0.378 1.    0.607\n",
      "  0.455 0.893]\n",
      " [0.779   nan 0.333 0.438 0.155 1.    0.111 1.    0.2   0.562 0.96  0.036\n",
      "  0.498   nan]\n",
      " [0.393 0.23  0.741 0.157 0.    0.179 0.25    nan 0.04  0.386 0.76    nan\n",
      "  0.514 0.667]\n",
      " [0.543   nan 0.933 0.3   0.05  0.59  0.46  0.583 0.32  0.657 1.    0.393\n",
      "  0.351   nan]\n",
      " [0.357 0.4   0.72  0.272 0.088 0.758   nan   nan 0.163 0.479 0.8   0.243\n",
      "  0.327 0.858]\n",
      " [1.      nan 0.667 0.271 0.15  0.706 0.51  1.      nan 0.664 1.    0.857\n",
      "  0.679 0.953]\n",
      " [0.29  0.1   0.413 0.214 0.05  0.126 0.51  0.317 0.    0.115 0.4     nan\n",
      "  0.188 0.667]\n",
      " [0.557 0.72  0.68  0.228 0.27  0.221 0.19    nan 0.62  0.593 1.    0.036\n",
      "  0.515   nan]\n",
      " [0.6   0.5   1.      nan   nan 0.484 0.36  0.15  0.31  0.45  0.84  0.393\n",
      "  0.703 0.707]\n",
      " [0.357 0.43  0.667 0.228 0.1   0.284   nan   nan 0.1   0.243 0.32  0.657\n",
      "  0.242 0.74 ]\n",
      " [0.571 0.22  1.    0.228 0.08  0.726   nan 0.367 0.35  0.714   nan 0.515\n",
      "  0.551 0.46 ]\n",
      " [0.916   nan   nan 0.95  0.69  0.707 1.    0.    0.307 1.    1.    0.121\n",
      "  0.779 0.687]\n",
      " [0.5   0.51  0.733 0.543 0.29  0.737   nan   nan 0.    0.554 0.8   0.879\n",
      "  0.591 0.817]\n",
      " [0.329 0.1   0.496 0.2   0.077 0.295 0.111   nan 0.022 0.254 0.64    nan\n",
      "  0.432 0.527]\n",
      " [0.757 0.05  0.4   0.186 0.03  0.084 0.36  0.117   nan 0.307 1.    0.214\n",
      "  0.77    nan]\n",
      " [0.671   nan 1.    0.585 0.31  1.      nan 1.    0.27  0.728 1.    0.478\n",
      "  0.624 1.   ]\n",
      " [0.957   nan 0.6   0.286 0.125 0.284 0.66  1.    0.25  0.328   nan 0.179\n",
      "  0.406 0.587]\n",
      " [0.357 0.4   0.667 0.    0.    0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.733]\n",
      " [1.    0.05  0.587 0.643 0.5   0.368 0.317   nan   nan 0.279 1.    0.614\n",
      "  0.448 0.96 ]\n",
      " [1.    1.      nan 1.    0.6   0.8   0.74  1.    0.7   1.      nan 0.664\n",
      "  0.891 1.   ]\n",
      " [0.571 0.25  0.533 0.372 0.21  0.137   nan   nan 0.22  0.543 1.    0.286\n",
      "  0.255 0.78 ]\n",
      " [0.4   0.77  0.96  0.243 0.2   0.295 0.      nan 0.44  0.479 0.76  0.372\n",
      "  0.436   nan]\n",
      " [0.357   nan 0.667 0.214 0.05  0.158 0.5     nan 0.2   0.357 0.8   0.214\n",
      "  0.273 0.   ]]\n",
      "current score:  [[0.105 0.2     nan 0.213 0.032 0.19  0.133   nan 0.16  0.215 0.64    nan\n",
      "  0.438 0.74 ]\n",
      " [0.486   nan 0.817 0.25  0.175 0.737   nan   nan 0.25  0.585 1.    0.304\n",
      "  0.44  0.8  ]\n",
      " [0.211 0.37  0.63  0.725 0.432 0.013 0.5     nan   nan 0.731 1.    0.346\n",
      "  0.546   nan]\n",
      " [1.    0.81  0.896 1.    0.587 0.667   nan 1.    0.933 0.285   nan 0.509\n",
      "  0.892   nan]\n",
      " [  nan 0.41  0.682 0.575 0.161 0.      nan 0.    0.28  0.316   nan 0.152\n",
      "  0.568 0.713]\n",
      " [0.528   nan 0.6   0.228 0.08  0.326   nan   nan 0.22  0.328 1.    0.226\n",
      "  0.358 0.774]\n",
      " [0.829 0.      nan 0.529 0.27  1.    0.85  1.    0.92  0.729 1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.357   nan 0.667 0.214 0.05  0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.529   nan 0.76  0.429 0.3   0.789 0.41  0.854   nan 0.6     nan 0.257\n",
      "  0.648 0.893]\n",
      " [0.357   nan 0.667 0.    0.    0.684   nan   nan 0.    0.25  0.8   0.214\n",
      "  0.    0.   ]\n",
      " [0.5   0.3   1.    0.157   nan 0.158   nan   nan 0.3   0.629 1.    0.328\n",
      "  0.63  1.   ]\n",
      " [1.    0.35    nan 0.4     nan 0.579 0.64  1.    0.52  0.486 1.      nan\n",
      "  0.503 0.926]\n",
      " [0.337   nan 0.867 0.613 0.49    nan   nan 0.071 0.866 0.569 0.92  0.455\n",
      "  0.676 0.94 ]\n",
      " [0.428 0.31    nan 0.143 0.    0.579   nan 0.433 0.42  0.364   nan 0.036\n",
      "  0.376 0.28 ]\n",
      " [0.415   nan   nan 0.2   0.04  0.947 0.82  0.383 0.025 0.564 1.      nan\n",
      "  0.212 0.52 ]\n",
      " [1.      nan 1.    0.871 0.8   0.158   nan   nan 0.49  0.679 1.    0.929\n",
      "  0.788 0.733]\n",
      " [0.557   nan 0.747 0.5   0.39  0.516   nan   nan 0.35  0.521 1.    0.314\n",
      "  0.448 0.813]\n",
      " [0.429   nan 0.037 0.388 0.258 0.    0.39  0.616   nan 0.516 0.76    nan\n",
      "  0.    0.267]\n",
      " [0.571 0.6   1.    0.214 0.05  0.926   nan 0.833 0.26    nan   nan 0.036\n",
      "  0.636 1.   ]\n",
      " [0.789   nan 1.    0.6   0.284 1.    0.9   1.    0.746 0.354   nan 0.624\n",
      "  0.897   nan]\n",
      " [0.371   nan 0.773 0.214 0.05  0.274 0.5   0.3     nan 0.478 0.84  0.257\n",
      "    nan 0.18 ]\n",
      " [1.      nan 0.44  0.5   0.25  0.706 0.51  1.    0.    0.807   nan   nan\n",
      "  0.442 0.893]\n",
      " [0.171 0.18  0.413 0.214 0.05  0.39  0.51    nan   nan 0.328 0.4     nan\n",
      "  0.273 0.74 ]\n",
      " [0.3   0.33  0.894 0.057   nan 0.011   nan   nan 0.15  0.028 0.48  0.286\n",
      "  0.467 0.667]\n",
      " [0.429   nan 0.467 0.586 0.31  0.2     nan   nan 0.55  0.378 1.    0.607\n",
      "  0.455 0.893]\n",
      " [0.779   nan 0.333 0.438 0.155 1.      nan 1.    0.2   0.562 0.96  0.036\n",
      "  0.498   nan]\n",
      " [0.393 0.23    nan 0.157 0.    0.179 0.25    nan 0.04  0.386 0.76    nan\n",
      "  0.273 0.667]\n",
      " [0.543   nan 0.933 0.3   0.05  0.59  0.46    nan 0.32  0.657 1.    0.393\n",
      "  0.351   nan]\n",
      " [0.357   nan 0.72  0.272 0.088 0.758   nan   nan 0.163 0.479 0.8   0.243\n",
      "  0.327 0.858]\n",
      " [1.      nan   nan 0.271 0.15  0.706 0.51  1.      nan 0.664 1.    0.857\n",
      "  0.679 0.953]\n",
      " [  nan 0.1   0.413 0.214 0.05  0.126 0.51  0.317 0.    0.214   nan   nan\n",
      "  0.188 0.667]\n",
      " [0.557 0.72  0.68  0.228 0.27  0.221 0.19    nan 0.62  0.514   nan 0.036\n",
      "  0.515   nan]\n",
      " [0.6     nan 1.      nan   nan 0.484 0.36  0.15  0.31  0.45  0.84  0.393\n",
      "  0.703 0.707]\n",
      " [0.357 0.43  0.667 0.228   nan 0.284   nan   nan 0.1   0.243 0.32  0.657\n",
      "  0.242 0.74 ]\n",
      " [0.571 0.22  1.    0.228 0.08    nan   nan 0.367 0.35  0.714   nan 0.515\n",
      "  0.551 0.46 ]\n",
      " [0.916   nan   nan 0.95  0.69  0.707 1.    0.    0.307 1.    1.      nan\n",
      "  0.806 0.687]\n",
      " [0.5   0.51  0.733 0.543 0.29  0.737   nan   nan   nan 0.554 0.8   0.879\n",
      "  0.591 0.817]\n",
      " [0.329   nan 0.496 0.2   0.077 0.295 0.111   nan 0.022 0.254 0.64    nan\n",
      "  0.432 0.527]\n",
      " [0.757 0.05  0.4   0.186 0.03  0.084 0.36  0.117   nan 0.307 1.    0.214\n",
      "    nan   nan]\n",
      " [0.671   nan 1.    0.585 0.31  0.726   nan   nan 0.27  0.728 1.    0.478\n",
      "  0.624 1.   ]\n",
      " [0.957   nan 0.6   0.286 0.125 0.284 0.66  1.    0.25  0.328   nan   nan\n",
      "  0.406 0.587]\n",
      " [0.357   nan 0.667 0.    0.    0.684   nan   nan 0.    0.    0.8   0.214\n",
      "  0.    0.733]\n",
      " [1.      nan 0.587 0.643 0.5   0.368 0.317   nan   nan 0.279 1.    0.614\n",
      "  0.448 0.96 ]\n",
      " [1.    1.      nan 1.    0.6   0.8   0.74    nan 0.7   1.      nan 0.664\n",
      "  0.891 1.   ]\n",
      " [0.571   nan 0.533 0.372 0.21  0.137   nan   nan 0.22  0.543 1.    0.286\n",
      "  0.255 0.78 ]\n",
      " [0.4   0.77  0.96  0.243 0.2   0.284   nan   nan 0.44  0.479 0.76  0.372\n",
      "  0.436   nan]\n",
      " [0.357   nan 0.667 0.214 0.05  0.158   nan   nan 0.2   0.357 0.8   0.214\n",
      "  0.273 0.   ]]\n",
      "encoding:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 59\n",
      "Average improvement: 0.35645762711864404\n",
      "Standard deviation: 0.34050901664267574\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 8.1266239e-03 -2.6156828e-03  8.1057288e-04 ... -7.2615072e-03\n",
      "  -2.1228455e-03  5.7250416e-01]\n",
      " [-1.2685955e-03 -5.0838664e-03 -2.8720498e-04 ...  7.4866265e-03\n",
      "  -3.7461082e-03 -1.4446549e-02]\n",
      " [ 3.2409623e-02  1.9664541e-03 -9.1459975e-03 ... -3.9034635e-03\n",
      "   3.5938853e-03  1.0160524e-03]\n",
      " ...\n",
      " [ 7.2972253e-03  4.3526095e-01  3.7817424e-03 ... -3.3292398e-03\n",
      "   6.9519533e-03 -4.6796924e-03]\n",
      " [-6.5827370e-03 -1.2767687e-03  7.0011895e-03 ... -3.7379190e-03\n",
      "   1.7260988e-03  4.6732450e-01]\n",
      " [ 1.0367632e-03  3.8567930e-04  3.6606733e-03 ...  2.0290986e-03\n",
      "   6.2140124e-04  1.7764181e-02]]\n",
      "current score:  [[1.    1.    1.    ... 0.74  1.      nan]\n",
      " [0.516 0.73  1.    ... 0.333 0.881 0.2  ]\n",
      " [0.8     nan 0.889 ... 0.273 0.978 0.447]\n",
      " ...\n",
      " [0.357   nan 0.613 ... 0.186 0.515   nan]\n",
      " [0.779 0.36  1.    ... 0.485 0.973   nan]\n",
      " [0.495 0.72  0.882 ... 0.345 0.649 1.   ]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 10891\n",
      "Average improvement: 0.48365558330874375\n",
      "Standard deviation: 0.08271485512177115\n",
      "prediction score:  [[ 8.1266239e-03 -2.6156828e-03  8.1057288e-04 ... -7.2615072e-03\n",
      "  -2.1228455e-03  5.7250416e-01]\n",
      " [-1.2685955e-03 -5.0838664e-03 -2.8720498e-04 ...  7.4866265e-03\n",
      "  -3.7461082e-03 -1.4446549e-02]\n",
      " [ 3.2409623e-02  1.9664541e-03 -9.1459975e-03 ... -3.9034635e-03\n",
      "   3.5938853e-03  1.0160524e-03]\n",
      " ...\n",
      " [ 7.2972253e-03  4.3526095e-01  3.7817424e-03 ... -3.3292398e-03\n",
      "   6.9519533e-03 -4.6796924e-03]\n",
      " [-6.5827370e-03 -1.2767687e-03  7.0011895e-03 ... -3.7379190e-03\n",
      "   1.7260988e-03  4.6732450e-01]\n",
      " [ 1.0367632e-03  3.8567930e-04  3.6606733e-03 ...  2.0290986e-03\n",
      "   6.2140124e-04  1.7764181e-02]]\n",
      "current score:  [[1.    1.    1.    ... 0.74  1.      nan]\n",
      " [0.516 0.73  1.    ... 0.333 0.881 0.2  ]\n",
      " [0.8     nan 0.889 ... 0.273 0.978 0.447]\n",
      " ...\n",
      " [0.357   nan 0.613 ... 0.186 0.515   nan]\n",
      " [0.779 0.36  1.    ... 0.485 0.973   nan]\n",
      " [0.495 0.72  0.882 ... 0.345 0.649 1.   ]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 10891\n",
      "Average improvement: 0.48365558330874375\n",
      "Standard deviation: 0.08271485512177115\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.57250416]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.54440373]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[1.    1.    1.    ... 0.74  1.      nan]\n",
      " [0.516 0.73  1.    ... 0.333 0.881 0.2  ]\n",
      " [0.8     nan 0.889 ... 0.273 0.978 0.447]\n",
      " ...\n",
      " [0.357   nan 0.613 ... 0.186 0.515   nan]\n",
      " [0.779 0.36  1.    ... 0.485 0.973   nan]\n",
      " [0.495 0.72  0.882 ... 0.345 0.649 1.   ]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 10891\n",
      "Average improvement: 0.5434102548316933\n",
      "Standard deviation: 0.07981431501405584\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.57250416]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.54440373]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[1.    1.    1.    ... 0.74  1.      nan]\n",
      " [0.516 0.73  1.    ... 0.333 0.881 0.2  ]\n",
      " [0.8     nan 0.889 ... 0.273 0.978 0.447]\n",
      " ...\n",
      " [0.357   nan 0.613 ... 0.186 0.515   nan]\n",
      " [0.779 0.36  1.    ... 0.485 0.973   nan]\n",
      " [0.495 0.72  0.882 ... 0.345 0.649 1.   ]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 10891\n",
      "Average improvement: 0.5434102548316933\n",
      "Standard deviation: 0.07981431501405584\n",
      "========= 4 missing\n",
      "----ground truth----\n",
      "prediction score:  [[0.357 0.69  0.2   0.214 0.05  0.053   nan   nan 0.25  0.486 0.8   0.25\n",
      "  0.757   nan]\n",
      " [0.571   nan 0.367 0.286 0.1   0.316 0.5     nan 0.25  0.286   nan 0.25\n",
      "  0.349 0.7  ]\n",
      " [0.429   nan 1.    0.214 0.2   0.716 0.59    nan   nan 0.514 1.    0.4\n",
      "  0.606 0.713]\n",
      " [0.429   nan 0.667 0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455 0.767]\n",
      " [0.357   nan 0.4   0.    0.    0.684   nan   nan 0.25  0.25  0.8   0.25\n",
      "  0.424 0.733]\n",
      " [0.    0.14  0.    0.375 0.142 0.085   nan 0.05    nan 0.423 0.72    nan\n",
      "  0.    0.   ]\n",
      " [0.571 0.85  0.867 0.343 0.23  0.158   nan   nan 0.7   0.693 1.    0.393\n",
      "  0.667   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.2   0.25  0.8   0.\n",
      "  0.273 0.   ]\n",
      " [0.929   nan   nan 1.    0.35  0.821 1.      nan 0.6   1.    1.    0.536\n",
      "  1.    1.   ]\n",
      " [0.429   nan 0.4   0.214 0.05  0.      nan   nan 0.2   0.25  1.    0.25\n",
      "  0.273 0.733]\n",
      " [0.386 0.567 0.6   0.271 0.05  0.495 0.67    nan 0.5   0.207 0.88    nan\n",
      "  0.54    nan]\n",
      " [0.357   nan 1.    0.243 0.07  0.631   nan 0.317 0.25  0.4   0.8   0.407\n",
      "  0.606   nan]\n",
      " [0.571   nan 0.453 0.286 0.2   0.632 0.5   0.125 0.25  0.268   nan 0.429\n",
      "  0.57    nan]\n",
      " [0.7   0.3   1.    0.585 0.31  0.611   nan 0.517 0.24  0.657   nan 0.229\n",
      "  0.582   nan]\n",
      " [0.643 0.66  0.813 0.643 0.39  0.736 0.48    nan 0.53  0.622   nan 0.264\n",
      "  0.63    nan]\n",
      " [0.643   nan 1.    0.214 0.    0.705   nan   nan 0.2   0.643 1.    0.429\n",
      "  0.54  1.   ]\n",
      " [0.894 1.      nan 0.738 0.28    nan   nan 0.588 0.21  0.923 1.    0.493\n",
      "  0.745 0.973]\n",
      " [0.386   nan 0.853 0.228 0.08  0.242 0.2     nan 0.21  0.471 0.92  0.293\n",
      "  0.588   nan]\n",
      " [0.4     nan 0.4   0.272 0.12  0.253 0.2     nan   nan 0.543 1.    0.243\n",
      "  0.424 0.787]\n",
      " [0.429   nan 0.733 0.357 0.1   0.895   nan 0.75  0.5   0.714 1.    0.393\n",
      "    nan 0.7  ]\n",
      " [1.    1.    1.    1.    1.      nan   nan   nan 1.    0.993 1.    0.743\n",
      "  0.933 0.967]\n",
      " [0.357   nan 1.    0.329 0.23  0.674 0.54    nan 0.35  0.522 0.72  0.436\n",
      "  0.551   nan]\n",
      " [1.      nan 0.854 0.6   0.37  0.4     nan 0.783 0.47  0.364   nan 0.286\n",
      "  0.57  0.853]\n",
      " [1.    0.97  1.    1.    0.85  0.316   nan   nan 1.    1.    0.867 1.\n",
      "  1.      nan]\n",
      " [0.357   nan   nan 0.414 0.21  0.568 0.73  0.    0.68  0.536 0.8   0.5\n",
      "  0.697   nan]\n",
      " [0.4     nan 0.813 0.2   0.04  0.211   nan   nan 0.28  0.493 0.92  0.286\n",
      "  0.406 0.167]\n",
      " [0.429   nan 0.4   0.286 0.1   0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424 0.767]\n",
      " [0.357 0.5   0.733 0.25  0.09  0.053   nan   nan 0.57  0.636 0.8   0.286\n",
      "  0.546   nan]\n",
      " [0.457 0.15    nan 0.171 0.09  0.947 0.87  0.833   nan 0.557 0.92    nan\n",
      "  0.055 0.653]\n",
      " [0.371   nan   nan 0.214 0.05  0.2   0.12  0.85  0.05  0.386 1.      nan\n",
      "  0.212 0.18 ]\n",
      " [0.286   nan 0.813 0.143 0.    0.232 0.12  0.      nan 0.078   nan 0.3\n",
      "  0.497 0.86 ]\n",
      " [0.629   nan 1.    0.529 0.29  0.8     nan 0.667 0.48  0.807 0.7   0.464\n",
      "  0.758   nan]\n",
      " [0.514 0.075   nan 0.171 0.01  0.589 0.25  0.733   nan 0.779 1.      nan\n",
      "  0.697 0.807]\n",
      " [0.357   nan 0.667 0.286 0.1   0.684   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.455 0.767]\n",
      " [0.505   nan 0.859 0.438 0.194 0.133   nan 0.941 0.283 0.772   nan 0.364\n",
      "  0.757 0.433]\n",
      " [0.143 0.35  0.6   0.114   nan 0.053 0.44    nan 0.1   0.114 0.8   0.09\n",
      "  0.321 0.667]\n",
      " [0.357   nan 0.453 0.228 0.06  0.684   nan 0.083   nan 0.536 0.8   0.214\n",
      "  0.43  0.667]\n",
      " [0.929 0.15  1.    0.143 0.    0.2     nan 0.5   0.1   0.136   nan 0.343\n",
      "  0.612   nan]\n",
      " [0.214 0.26    nan 0.114 0.01  0.695 0.57    nan 0.12  0.293 0.4   0.321\n",
      "  0.467   nan]\n",
      " [0.429   nan 0.4   0.214 0.05  0.779   nan 0.283 0.85  0.657 1.    0.214\n",
      "  0.424 0.667]\n",
      " [0.571 0.388 0.68  0.625 0.374   nan   nan 0.549 0.37  0.665 1.    0.243\n",
      "  0.43    nan]\n",
      " [0.442   nan 0.941 0.663 0.258 0.667   nan 0.647 0.44  0.354 0.2   0.261\n",
      "  0.671   nan]\n",
      " [  nan 0.4   0.    0.024 0.    0.632 0.15  0.    0.075 0.205   nan   nan\n",
      "  0.061 0.667]\n",
      " [0.728   nan 0.8   0.315 0.21  0.674 0.5     nan   nan 0.679 1.    0.407\n",
      "  0.794 0.98 ]\n",
      " [0.429   nan 0.4   0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424 0.733]]\n",
      "current score:  [[0.357 0.69  0.2   0.214 0.05    nan   nan   nan 0.25  0.536 0.8   0.25\n",
      "  0.757   nan]\n",
      " [  nan   nan 0.367 0.286 0.1   0.316 0.5     nan 0.25  0.286   nan 0.25\n",
      "  0.212 0.7  ]\n",
      " [  nan   nan 1.    0.214 0.2   0.716 0.59    nan   nan 0.5   0.6   0.4\n",
      "  0.606 0.713]\n",
      " [0.429   nan 0.667 0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.    0.    0.684   nan   nan 0.25  0.25  0.8   0.25\n",
      "  0.424   nan]\n",
      " [0.    0.14  0.    0.375 0.142 0.085   nan 0.05    nan 0.423 0.72    nan\n",
      "    nan 0.   ]\n",
      " [0.571   nan 0.867 0.343 0.23  0.158   nan   nan 0.7   0.693 1.    0.393\n",
      "  0.667   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.2   0.25  0.8   0.\n",
      "  0.273   nan]\n",
      " [0.929   nan   nan 1.    0.35  0.821 1.      nan   nan 1.    1.    0.536\n",
      "  1.    1.   ]\n",
      " [0.429   nan 0.4   0.214 0.05  0.      nan   nan 0.2   0.25  1.    0.25\n",
      "  0.273   nan]\n",
      " [0.386 0.567 0.6   0.271 0.05  0.495 0.67    nan   nan 0.207 0.88    nan\n",
      "  0.54    nan]\n",
      " [0.357   nan 1.    0.243 0.07  0.631   nan 0.317   nan 0.4   0.8   0.407\n",
      "  0.606   nan]\n",
      " [0.571   nan 0.453 0.286 0.2   0.632 0.5   0.125   nan 0.268   nan 0.429\n",
      "  0.57    nan]\n",
      " [0.7     nan 1.    0.585 0.31  0.611   nan 0.517 0.24  0.657   nan 0.229\n",
      "  0.582   nan]\n",
      " [0.643 0.66  0.813 0.643 0.39  0.736 0.48    nan 0.53  0.622   nan   nan\n",
      "  0.63    nan]\n",
      " [0.643   nan 1.    0.214 0.    0.705   nan   nan   nan 0.643 1.    0.429\n",
      "  0.618 1.   ]\n",
      " [0.894 1.      nan 0.738 0.28    nan   nan   nan 0.21  0.923 1.    0.493\n",
      "  0.745 0.973]\n",
      " [0.386   nan 0.853 0.228 0.08  0.232   nan   nan 0.21  0.471 0.92  0.293\n",
      "  0.588   nan]\n",
      " [0.4     nan 0.4   0.272 0.12  0.221   nan   nan   nan 0.543 1.    0.243\n",
      "  0.424 0.787]\n",
      " [0.429   nan 0.733 0.357 0.1   0.895   nan 0.75    nan 0.714 1.    0.393\n",
      "    nan 0.7  ]\n",
      " [1.    1.    1.    1.    1.      nan   nan   nan 1.    0.993 1.    0.743\n",
      "  0.933   nan]\n",
      " [0.357   nan 1.    0.329 0.23  0.674 0.54    nan   nan 0.522 0.72  0.436\n",
      "  0.551   nan]\n",
      " [  nan   nan 0.854 0.6   0.37  0.4     nan 0.783 0.47  0.364   nan 0.286\n",
      "  0.57  0.853]\n",
      " [1.    0.97  1.    1.    0.85  0.316   nan   nan 1.    1.      nan 1.\n",
      "  1.      nan]\n",
      " [0.357   nan   nan 0.414 0.21  0.568   nan 0.    0.68  0.536 0.8   0.5\n",
      "  0.697   nan]\n",
      " [0.4     nan 0.813 0.2   0.04  0.211   nan   nan 0.28  0.493 0.92  0.286\n",
      "  0.406   nan]\n",
      " [0.429   nan 0.4   0.286 0.1   0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.357   nan 0.733 0.25  0.09  0.053   nan   nan 0.57  0.636 0.8   0.286\n",
      "  0.546   nan]\n",
      " [0.457 0.15    nan 0.171 0.09  0.947 0.87  0.833   nan 0.557 0.92    nan\n",
      "    nan 0.653]\n",
      " [0.371   nan   nan 0.214 0.05  0.2   0.12  0.85    nan 0.386 1.      nan\n",
      "  0.212 0.18 ]\n",
      " [0.286   nan 0.813 0.143 0.    0.232 0.12    nan   nan 0.078   nan 0.3\n",
      "  0.497 0.86 ]\n",
      " [0.629   nan 1.    0.529 0.29  0.768   nan   nan 0.48  0.807 0.7   0.464\n",
      "  0.758   nan]\n",
      " [0.5   0.075   nan 0.171 0.01  0.589 0.25  0.733   nan 0.779 1.      nan\n",
      "    nan 0.807]\n",
      " [0.357   nan 0.667 0.286 0.1   0.684   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.455   nan]\n",
      " [0.505   nan 0.859 0.438 0.194   nan   nan 0.941 0.283 0.772   nan 0.364\n",
      "  0.757 0.433]\n",
      " [  nan 0.35  0.6   0.114   nan 0.053 0.44    nan 0.1   0.057   nan 0.09\n",
      "  0.321 0.667]\n",
      " [0.357   nan 0.453 0.228 0.06  0.684   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.43  0.667]\n",
      " [  nan 0.15  1.    0.143 0.    0.2     nan 0.5   0.1   0.136   nan 0.343\n",
      "  0.612   nan]\n",
      " [0.214 0.26    nan 0.114 0.01    nan 0.59    nan 0.12  0.293 0.4   0.321\n",
      "  0.467   nan]\n",
      " [0.429   nan 0.4     nan   nan 0.779   nan 0.283 0.85  0.657 1.    0.214\n",
      "  0.424 0.667]\n",
      " [0.571 0.388 0.68  0.625 0.374   nan   nan   nan 0.37  0.665 1.    0.243\n",
      "  0.43    nan]\n",
      " [0.442   nan 0.941 0.663 0.258 0.667   nan 0.647 0.44  0.338   nan 0.261\n",
      "  0.671   nan]\n",
      " [  nan 0.4   0.    0.024 0.    0.724   nan 0.    0.075 0.205   nan   nan\n",
      "  0.061 0.667]\n",
      " [0.728   nan 0.8   0.315 0.21  0.684   nan   nan   nan 0.679 1.    0.407\n",
      "  0.794 0.98 ]\n",
      " [0.429   nan 0.4   0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Number of predicted domains: 58\n",
      "Average improvement: 0.36574137931034484\n",
      "Standard deviation: 0.3221646936532006\n",
      "prediction score:  [[0.357 0.69  0.2   0.214 0.05  0.053   nan   nan 0.25  0.486 0.8   0.25\n",
      "  0.757   nan]\n",
      " [0.571   nan 0.367 0.286 0.1   0.316 0.5     nan 0.25  0.286   nan 0.25\n",
      "  0.349 0.7  ]\n",
      " [0.429   nan 1.    0.214 0.2   0.716 0.59    nan   nan 0.514 1.    0.4\n",
      "  0.606 0.713]\n",
      " [0.429   nan 0.667 0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455 0.767]\n",
      " [0.357   nan 0.4   0.    0.    0.684   nan   nan 0.25  0.25  0.8   0.25\n",
      "  0.424 0.733]\n",
      " [0.    0.14  0.    0.375 0.142 0.085   nan 0.05    nan 0.423 0.72    nan\n",
      "  0.    0.   ]\n",
      " [0.571 0.85  0.867 0.343 0.23  0.158   nan   nan 0.7   0.693 1.    0.393\n",
      "  0.667   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.2   0.25  0.8   0.\n",
      "  0.273 0.   ]\n",
      " [0.929   nan   nan 1.    0.35  0.821 1.      nan 0.6   1.    1.    0.536\n",
      "  1.    1.   ]\n",
      " [0.429   nan 0.4   0.214 0.05  0.      nan   nan 0.2   0.25  1.    0.25\n",
      "  0.273 0.733]\n",
      " [0.386 0.567 0.6   0.271 0.05  0.495 0.67    nan 0.5   0.207 0.88    nan\n",
      "  0.54    nan]\n",
      " [0.357   nan 1.    0.243 0.07  0.631   nan 0.317 0.25  0.4   0.8   0.407\n",
      "  0.606   nan]\n",
      " [0.571   nan 0.453 0.286 0.2   0.632 0.5   0.125 0.25  0.268   nan 0.429\n",
      "  0.57    nan]\n",
      " [0.7   0.3   1.    0.585 0.31  0.611   nan 0.517 0.24  0.657   nan 0.229\n",
      "  0.582   nan]\n",
      " [0.643 0.66  0.813 0.643 0.39  0.736 0.48    nan 0.53  0.622   nan 0.264\n",
      "  0.63    nan]\n",
      " [0.643   nan 1.    0.214 0.    0.705   nan   nan 0.2   0.643 1.    0.429\n",
      "  0.54  1.   ]\n",
      " [0.894 1.      nan 0.738 0.28    nan   nan 0.588 0.21  0.923 1.    0.493\n",
      "  0.745 0.973]\n",
      " [0.386   nan 0.853 0.228 0.08  0.242 0.2     nan 0.21  0.471 0.92  0.293\n",
      "  0.588   nan]\n",
      " [0.4     nan 0.4   0.272 0.12  0.253 0.2     nan   nan 0.543 1.    0.243\n",
      "  0.424 0.787]\n",
      " [0.429   nan 0.733 0.357 0.1   0.895   nan 0.75  0.5   0.714 1.    0.393\n",
      "    nan 0.7  ]\n",
      " [1.    1.    1.    1.    1.      nan   nan   nan 1.    0.993 1.    0.743\n",
      "  0.933 0.967]\n",
      " [0.357   nan 1.    0.329 0.23  0.674 0.54    nan 0.35  0.522 0.72  0.436\n",
      "  0.551   nan]\n",
      " [1.      nan 0.854 0.6   0.37  0.4     nan 0.783 0.47  0.364   nan 0.286\n",
      "  0.57  0.853]\n",
      " [1.    0.97  1.    1.    0.85  0.316   nan   nan 1.    1.    0.867 1.\n",
      "  1.      nan]\n",
      " [0.357   nan   nan 0.414 0.21  0.568 0.73  0.    0.68  0.536 0.8   0.5\n",
      "  0.697   nan]\n",
      " [0.4     nan 0.813 0.2   0.04  0.211   nan   nan 0.28  0.493 0.92  0.286\n",
      "  0.406 0.167]\n",
      " [0.429   nan 0.4   0.286 0.1   0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424 0.767]\n",
      " [0.357 0.5   0.733 0.25  0.09  0.053   nan   nan 0.57  0.636 0.8   0.286\n",
      "  0.546   nan]\n",
      " [0.457 0.15    nan 0.171 0.09  0.947 0.87  0.833   nan 0.557 0.92    nan\n",
      "  0.055 0.653]\n",
      " [0.371   nan   nan 0.214 0.05  0.2   0.12  0.85  0.05  0.386 1.      nan\n",
      "  0.212 0.18 ]\n",
      " [0.286   nan 0.813 0.143 0.    0.232 0.12  0.      nan 0.078   nan 0.3\n",
      "  0.497 0.86 ]\n",
      " [0.629   nan 1.    0.529 0.29  0.8     nan 0.667 0.48  0.807 0.7   0.464\n",
      "  0.758   nan]\n",
      " [0.514 0.075   nan 0.171 0.01  0.589 0.25  0.733   nan 0.779 1.      nan\n",
      "  0.697 0.807]\n",
      " [0.357   nan 0.667 0.286 0.1   0.684   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.455 0.767]\n",
      " [0.505   nan 0.859 0.438 0.194 0.133   nan 0.941 0.283 0.772   nan 0.364\n",
      "  0.757 0.433]\n",
      " [0.143 0.35  0.6   0.114   nan 0.053 0.44    nan 0.1   0.114 0.8   0.09\n",
      "  0.321 0.667]\n",
      " [0.357   nan 0.453 0.228 0.06  0.684   nan 0.083   nan 0.536 0.8   0.214\n",
      "  0.43  0.667]\n",
      " [0.929 0.15  1.    0.143 0.    0.2     nan 0.5   0.1   0.136   nan 0.343\n",
      "  0.612   nan]\n",
      " [0.214 0.26    nan 0.114 0.01  0.695 0.57    nan 0.12  0.293 0.4   0.321\n",
      "  0.467   nan]\n",
      " [0.429   nan 0.4   0.214 0.05  0.779   nan 0.283 0.85  0.657 1.    0.214\n",
      "  0.424 0.667]\n",
      " [0.571 0.388 0.68  0.625 0.374   nan   nan 0.549 0.37  0.665 1.    0.243\n",
      "  0.43    nan]\n",
      " [0.442   nan 0.941 0.663 0.258 0.667   nan 0.647 0.44  0.354 0.2   0.261\n",
      "  0.671   nan]\n",
      " [  nan 0.4   0.    0.024 0.    0.632 0.15  0.    0.075 0.205   nan   nan\n",
      "  0.061 0.667]\n",
      " [0.728   nan 0.8   0.315 0.21  0.674 0.5     nan   nan 0.679 1.    0.407\n",
      "  0.794 0.98 ]\n",
      " [0.429   nan 0.4   0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424 0.733]]\n",
      "current score:  [[0.357 0.69  0.2   0.214 0.05    nan   nan   nan 0.25  0.536 0.8   0.25\n",
      "  0.757   nan]\n",
      " [  nan   nan 0.367 0.286 0.1   0.316 0.5     nan 0.25  0.286   nan 0.25\n",
      "  0.212 0.7  ]\n",
      " [  nan   nan 1.    0.214 0.2   0.716 0.59    nan   nan 0.5   0.6   0.4\n",
      "  0.606 0.713]\n",
      " [0.429   nan 0.667 0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.    0.    0.684   nan   nan 0.25  0.25  0.8   0.25\n",
      "  0.424   nan]\n",
      " [0.    0.14  0.    0.375 0.142 0.085   nan 0.05    nan 0.423 0.72    nan\n",
      "    nan 0.   ]\n",
      " [0.571   nan 0.867 0.343 0.23  0.158   nan   nan 0.7   0.693 1.    0.393\n",
      "  0.667   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.2   0.25  0.8   0.\n",
      "  0.273   nan]\n",
      " [0.929   nan   nan 1.    0.35  0.821 1.      nan   nan 1.    1.    0.536\n",
      "  1.    1.   ]\n",
      " [0.429   nan 0.4   0.214 0.05  0.      nan   nan 0.2   0.25  1.    0.25\n",
      "  0.273   nan]\n",
      " [0.386 0.567 0.6   0.271 0.05  0.495 0.67    nan   nan 0.207 0.88    nan\n",
      "  0.54    nan]\n",
      " [0.357   nan 1.    0.243 0.07  0.631   nan 0.317   nan 0.4   0.8   0.407\n",
      "  0.606   nan]\n",
      " [0.571   nan 0.453 0.286 0.2   0.632 0.5   0.125   nan 0.268   nan 0.429\n",
      "  0.57    nan]\n",
      " [0.7     nan 1.    0.585 0.31  0.611   nan 0.517 0.24  0.657   nan 0.229\n",
      "  0.582   nan]\n",
      " [0.643 0.66  0.813 0.643 0.39  0.736 0.48    nan 0.53  0.622   nan   nan\n",
      "  0.63    nan]\n",
      " [0.643   nan 1.    0.214 0.    0.705   nan   nan   nan 0.643 1.    0.429\n",
      "  0.618 1.   ]\n",
      " [0.894 1.      nan 0.738 0.28    nan   nan   nan 0.21  0.923 1.    0.493\n",
      "  0.745 0.973]\n",
      " [0.386   nan 0.853 0.228 0.08  0.232   nan   nan 0.21  0.471 0.92  0.293\n",
      "  0.588   nan]\n",
      " [0.4     nan 0.4   0.272 0.12  0.221   nan   nan   nan 0.543 1.    0.243\n",
      "  0.424 0.787]\n",
      " [0.429   nan 0.733 0.357 0.1   0.895   nan 0.75    nan 0.714 1.    0.393\n",
      "    nan 0.7  ]\n",
      " [1.    1.    1.    1.    1.      nan   nan   nan 1.    0.993 1.    0.743\n",
      "  0.933   nan]\n",
      " [0.357   nan 1.    0.329 0.23  0.674 0.54    nan   nan 0.522 0.72  0.436\n",
      "  0.551   nan]\n",
      " [  nan   nan 0.854 0.6   0.37  0.4     nan 0.783 0.47  0.364   nan 0.286\n",
      "  0.57  0.853]\n",
      " [1.    0.97  1.    1.    0.85  0.316   nan   nan 1.    1.      nan 1.\n",
      "  1.      nan]\n",
      " [0.357   nan   nan 0.414 0.21  0.568   nan 0.    0.68  0.536 0.8   0.5\n",
      "  0.697   nan]\n",
      " [0.4     nan 0.813 0.2   0.04  0.211   nan   nan 0.28  0.493 0.92  0.286\n",
      "  0.406   nan]\n",
      " [0.429   nan 0.4   0.286 0.1   0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.357   nan 0.733 0.25  0.09  0.053   nan   nan 0.57  0.636 0.8   0.286\n",
      "  0.546   nan]\n",
      " [0.457 0.15    nan 0.171 0.09  0.947 0.87  0.833   nan 0.557 0.92    nan\n",
      "    nan 0.653]\n",
      " [0.371   nan   nan 0.214 0.05  0.2   0.12  0.85    nan 0.386 1.      nan\n",
      "  0.212 0.18 ]\n",
      " [0.286   nan 0.813 0.143 0.    0.232 0.12    nan   nan 0.078   nan 0.3\n",
      "  0.497 0.86 ]\n",
      " [0.629   nan 1.    0.529 0.29  0.768   nan   nan 0.48  0.807 0.7   0.464\n",
      "  0.758   nan]\n",
      " [0.5   0.075   nan 0.171 0.01  0.589 0.25  0.733   nan 0.779 1.      nan\n",
      "    nan 0.807]\n",
      " [0.357   nan 0.667 0.286 0.1   0.684   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.455   nan]\n",
      " [0.505   nan 0.859 0.438 0.194   nan   nan 0.941 0.283 0.772   nan 0.364\n",
      "  0.757 0.433]\n",
      " [  nan 0.35  0.6   0.114   nan 0.053 0.44    nan 0.1   0.057   nan 0.09\n",
      "  0.321 0.667]\n",
      " [0.357   nan 0.453 0.228 0.06  0.684   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.43  0.667]\n",
      " [  nan 0.15  1.    0.143 0.    0.2     nan 0.5   0.1   0.136   nan 0.343\n",
      "  0.612   nan]\n",
      " [0.214 0.26    nan 0.114 0.01    nan 0.59    nan 0.12  0.293 0.4   0.321\n",
      "  0.467   nan]\n",
      " [0.429   nan 0.4     nan   nan 0.779   nan 0.283 0.85  0.657 1.    0.214\n",
      "  0.424 0.667]\n",
      " [0.571 0.388 0.68  0.625 0.374   nan   nan   nan 0.37  0.665 1.    0.243\n",
      "  0.43    nan]\n",
      " [0.442   nan 0.941 0.663 0.258 0.667   nan 0.647 0.44  0.338   nan 0.261\n",
      "  0.671   nan]\n",
      " [  nan 0.4   0.    0.024 0.    0.724   nan 0.    0.075 0.205   nan   nan\n",
      "  0.061 0.667]\n",
      " [0.728   nan 0.8   0.315 0.21  0.684   nan   nan   nan 0.679 1.    0.407\n",
      "  0.794 0.98 ]\n",
      " [0.429   nan 0.4   0.286 0.1   0.737   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Number of predicted domains: 58\n",
      "Average improvement: 0.36574137931034484\n",
      "Standard deviation: 0.3221646936532006\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 4.8770756e-04  1.1957735e-02  7.1925102e-03 ...  2.9481947e-04\n",
      "  -1.3284013e-04  4.3233776e-01]\n",
      " [-8.7586045e-04  5.7283044e-03 -1.6081147e-04 ...  4.9066991e-03\n",
      "   5.1352950e-03 -1.2542892e-02]\n",
      " [ 4.4570044e-03  5.5684721e-01  4.1289255e-04 ... -5.4186136e-03\n",
      "   1.0228665e-02 -1.0243207e-03]\n",
      " ...\n",
      " [ 1.2745261e-02 -1.2150764e-02 -1.0907551e-02 ... -1.5696295e-02\n",
      "   8.1448834e-03 -2.0341912e-02]\n",
      " [-2.7646646e-03  4.2162091e-04 -5.9392713e-03 ... -7.8583360e-03\n",
      "  -9.5029757e-04  4.4420448e-01]\n",
      " [-3.3677742e-03  2.7134418e-03  1.1957761e-02 ... -9.3543008e-03\n",
      "  -1.3033673e-03 -2.1019378e-03]]\n",
      "current score:  [[0.614   nan 1.    ... 0.364 0.691   nan]\n",
      " [0.653 0.38  0.37  ... 0.242 0.378   nan]\n",
      " [0.429   nan 1.    ... 0.232 0.594 0.827]\n",
      " ...\n",
      " [0.989   nan 1.    ... 0.782 0.995 0.917]\n",
      " [0.472 0.4   0.867 ... 0.207 0.661   nan]\n",
      " [0.884 1.    1.    ... 0.667 0.908   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 8722\n",
      "Average improvement: 0.48356601758694545\n",
      "Standard deviation: 0.08375634769392637\n",
      "prediction score:  [[ 4.8770756e-04  1.1957735e-02  7.1925102e-03 ...  2.9481947e-04\n",
      "  -1.3284013e-04  4.3233776e-01]\n",
      " [-8.7586045e-04  5.7283044e-03 -1.6081147e-04 ...  4.9066991e-03\n",
      "   5.1352950e-03 -1.2542892e-02]\n",
      " [ 4.4570044e-03  5.5684721e-01  4.1289255e-04 ... -5.4186136e-03\n",
      "   1.0228665e-02 -1.0243207e-03]\n",
      " ...\n",
      " [ 1.2745261e-02 -1.2150764e-02 -1.0907551e-02 ... -1.5696295e-02\n",
      "   8.1448834e-03 -2.0341912e-02]\n",
      " [-2.7646646e-03  4.2162091e-04 -5.9392713e-03 ... -7.8583360e-03\n",
      "  -9.5029757e-04  4.4420448e-01]\n",
      " [-3.3677742e-03  2.7134418e-03  1.1957761e-02 ... -9.3543008e-03\n",
      "  -1.3033673e-03 -2.1019378e-03]]\n",
      "current score:  [[0.614   nan 1.    ... 0.364 0.691   nan]\n",
      " [0.653 0.38  0.37  ... 0.242 0.378   nan]\n",
      " [0.429   nan 1.    ... 0.232 0.594 0.827]\n",
      " ...\n",
      " [0.989   nan 1.    ... 0.782 0.995 0.917]\n",
      " [0.472 0.4   0.867 ... 0.207 0.661   nan]\n",
      " [0.884 1.    1.    ... 0.667 0.908   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 8722\n",
      "Average improvement: 0.48356601758694545\n",
      "Standard deviation: 0.08375634769392637\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.52737588 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.55684721 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.59415692 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[0.614   nan 1.    ... 0.364 0.691   nan]\n",
      " [0.653 0.38  0.37  ... 0.242 0.378   nan]\n",
      " [0.429   nan 1.    ... 0.232 0.594 0.827]\n",
      " ...\n",
      " [0.989   nan 1.    ... 0.782 0.995 0.917]\n",
      " [0.472 0.4   0.867 ... 0.207 0.661   nan]\n",
      " [0.884 1.    1.    ... 0.667 0.908   nan]]\n",
      "encoding:  [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 8722\n",
      "Average improvement: 0.5604695416021664\n",
      "Standard deviation: 0.08138278510665126\n",
      "prediction score:  [[0.         0.52737588 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.55684721 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.59415692 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[0.614   nan 1.    ... 0.364 0.691   nan]\n",
      " [0.653 0.38  0.37  ... 0.242 0.378   nan]\n",
      " [0.429   nan 1.    ... 0.232 0.594 0.827]\n",
      " ...\n",
      " [0.989   nan 1.    ... 0.782 0.995 0.917]\n",
      " [0.472 0.4   0.867 ... 0.207 0.661   nan]\n",
      " [0.884 1.    1.    ... 0.667 0.908   nan]]\n",
      "encoding:  [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 8722\n",
      "Average improvement: 0.5604695416021664\n",
      "Standard deviation: 0.08138278510665126\n",
      "========= 5 missing\n",
      "----ground truth----\n",
      "prediction score:  [[0.393   nan   nan 0.214 0.05  0.642 0.18  0.583   nan 0.729 1.      nan\n",
      "  0.227 0.817]\n",
      " [0.929   nan 1.    0.272 0.17  0.831   nan   nan 0.7   0.95  1.    0.693\n",
      "  0.915   nan]\n",
      " [0.506   nan 0.504 0.438 0.194 0.    0.278   nan   nan 0.223 1.    0.212\n",
      "  0.367   nan]\n",
      " [0.357   nan 0.556 0.286 0.1   0.737   nan   nan   nan 0.536 0.8   0.25\n",
      "  0.455 0.7  ]\n",
      " [0.357   nan 0.64  0.286 0.1   0.105   nan   nan 0.3   0.536 0.8   0.264\n",
      "  0.4     nan]\n",
      " [  nan   nan 0.52  0.286 0.16  0.811   nan 0.383 0.31  0.357 0.      nan\n",
      "  0.449 0.827]\n",
      " [0.085   nan 0.773 0.114 0.    0.063 0.07    nan 0.09  0.157   nan 0.143\n",
      "  0.315   nan]\n",
      " [0.357   nan   nan 0.386 0.05  1.    0.56  1.      nan 0.543 0.8     nan\n",
      "  0.788 0.9  ]\n",
      " [0.357   nan 0.783 0.179 0.025 0.281 0.5     nan   nan 0.322 0.8   0.309\n",
      "  0.576   nan]\n",
      " [0.671   nan 1.    0.686 0.51  0.842   nan 0.667   nan 0.857 1.    0.429\n",
      "  0.745   nan]\n",
      " [0.607   nan 0.8   0.429 0.3   0.737 0.6     nan   nan 0.643 1.    0.286\n",
      "  0.5     nan]\n",
      " [0.4     nan 1.    0.329 0.21  0.821   nan 0.583   nan 0.371 1.    0.307\n",
      "  0.588   nan]\n",
      " [0.429   nan 0.854 0.314 0.22  0.684   nan   nan 0.34  0.543 1.    0.3\n",
      "  0.515   nan]\n",
      " [0.286 0.19    nan 0.357 0.26  0.305 0.63    nan 0.27  0.343 0.44    nan\n",
      "  0.291   nan]\n",
      " [0.386   nan   nan 0.2   0.05  0.789   nan 0.    0.213 0.657 0.84    nan\n",
      "  0.281 0.667]\n",
      " [  nan   nan 0.866 0.214 0.05  0.358 0.29  0.      nan 0.257 0.2   0.386\n",
      "  0.528   nan]\n",
      " [0.453   nan 0.817   nan   nan 0.711 0.588   nan 0.75  0.607 1.    0.277\n",
      "  0.475 0.722]\n",
      " [1.      nan 0.556 0.525 0.368 1.      nan 1.      nan 0.539 1.    0.212\n",
      "    nan 0.713]\n",
      " [  nan 0.07  0.28    nan   nan   nan 0.72  0.1   0.    0.322 0.4   0.086\n",
      "  0.133 0.227]\n",
      " [0.086 0.    0.453 0.071   nan 0.526 0.      nan   nan 0.157 0.56  0.214\n",
      "  0.249   nan]\n",
      " [0.611 0.    0.392 0.375 0.181 0.52    nan   nan   nan 0.538 0.84  0.212\n",
      "  0.297   nan]\n",
      " [0.214   nan 1.    0.143 0.    0.421 0.46    nan   nan 0.336   nan 0.393\n",
      "  0.606 0.453]\n",
      " [  nan 0.15  0.653 0.    0.15  0.    0.1     nan   nan 0.    0.    0.393\n",
      "  0.655   nan]\n",
      " [0.447   nan 0.489 0.357 0.167 0.776   nan 0.583   nan 0.571 1.    0.214\n",
      "  0.434   nan]\n",
      " [0.143 0.    0.467   nan   nan 0.      nan   nan 0.    0.25  0.    0.\n",
      "  0.    0.   ]\n",
      " [  nan 0.35  0.52  0.314 0.18  0.347   nan 0.028 0.18  0.328   nan   nan\n",
      "  0.309 0.747]\n",
      " [  nan   nan 0.815 0.488 0.168   nan   nan 0.    0.089 0.377 0.267 0.273\n",
      "  0.568 0.52 ]\n",
      " [0.514   nan 1.    0.214 0.05    nan   nan   nan 0.25  0.764 0.8   0.079\n",
      "  0.26  0.1  ]\n",
      " [  nan   nan 0.427 0.214 0.05  0.537 0.5   0.167 0.2   0.264   nan   nan\n",
      "  0.273 0.675]\n",
      " [0.314 0.2   0.506 0.571 0.3     nan   nan   nan 0.21  0.536 0.8   0.293\n",
      "  0.333   nan]\n",
      " [  nan   nan 0.76  0.272 0.11  0.526 0.5   1.      nan 0.143   nan 0.271\n",
      "  0.545 0.493]\n",
      " [0.071   nan 0.6   0.314 0.21  1.    0.4   1.      nan 0.471   nan   nan\n",
      "  0.515 0.514]\n",
      " [  nan 0.125   nan 0.143 0.    0.369 0.42  0.817   nan 0.307 0.2     nan\n",
      "  0.227 0.347]\n",
      " [0.7     nan 1.    0.415 0.23  0.684   nan   nan 0.25  0.772 1.    0.414\n",
      "  0.751   nan]\n",
      " [0.371   nan 0.787 0.386 0.25  0.053   nan   nan   nan 0.493 1.    0.279\n",
      "  0.509 0.667]\n",
      " [0.486   nan   nan 1.    1.    1.      nan 1.      nan 0.607 1.    0.5\n",
      "  0.594 0.92 ]\n",
      " [0.429 0.05  0.68  0.214 0.05  0.088   nan   nan   nan 0.457 1.    0.221\n",
      "    nan 0.6  ]\n",
      " [0.543 0.6   0.747 0.643 0.45    nan   nan   nan 0.84  0.671 1.    0.778\n",
      "  0.751   nan]\n",
      " [0.943   nan 1.    0.5   0.25  1.      nan 1.      nan 0.772 1.    0.55\n",
      "  0.891 0.947]\n",
      " [0.371   nan 0.733 0.257 0.1     nan 0.6     nan 0.2   0.686 0.88  0.25\n",
      "  0.406   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.25  0.    0.8     nan\n",
      "  0.455 0.733]\n",
      " [  nan   nan 0.226 0.143 0.01  0.726 0.55  0.583   nan 0.1     nan 0.072\n",
      "  0.049 0.059]\n",
      " [0.429   nan 0.68  0.271 0.1   0.326 0.5     nan   nan 0.357 1.    0.25\n",
      "  0.461   nan]\n",
      " [0.568   nan 0.911 0.938 0.419   nan   nan   nan 1.    0.661 0.92  0.576\n",
      "  0.881 0.7  ]\n",
      " [0.815   nan 0.867 0.286 0.2   0.39  0.41  0.5   0.71  0.521   nan 0.036\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733 0.214 0.05  0.684   nan   nan 0.3   0.25  1.    0.304\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.48  0.286 0.125 0.726 0.2   0.35  0.25  0.312   nan   nan\n",
      "  0.431 0.675]\n",
      " [1.    0.83  1.    0.786 0.6     nan 0.95    nan 0.95  0.971   nan 0.571\n",
      "  0.897   nan]\n",
      " [0.429   nan 0.787 0.268 0.113 0.724   nan 0.375   nan 0.58  1.    0.259\n",
      "  0.576   nan]\n",
      " [0.579   nan   nan 0.913 0.297 0.693   nan 0.792 0.133 0.446 0.56    nan\n",
      "  0.568 0.567]\n",
      " [  nan 0.25  0.467 0.25  0.075 0.711   nan 0.209 0.25  0.286   nan   nan\n",
      "  0.41  0.667]]\n",
      "current score:  [[0.393   nan   nan 0.214 0.05  0.611 0.18    nan   nan 0.729 1.      nan\n",
      "  0.227 0.817]\n",
      " [0.929   nan 1.    0.272 0.17    nan   nan   nan 0.7   0.957 1.    0.693\n",
      "  0.915   nan]\n",
      " [0.506   nan 0.504 0.438 0.194 0.      nan   nan   nan 0.223 1.    0.212\n",
      "  0.367   nan]\n",
      " [0.357   nan 0.467 0.286 0.1   0.737   nan   nan   nan 0.536 0.8     nan\n",
      "  0.455 0.7  ]\n",
      " [0.357   nan 0.64  0.286 0.1     nan   nan   nan 0.3   0.536 0.8   0.264\n",
      "  0.4     nan]\n",
      " [  nan   nan 0.52  0.286 0.16  0.811   nan 0.383 0.31  0.329   nan   nan\n",
      "  0.449 0.827]\n",
      " [0.085   nan 0.773 0.114 0.    0.063 0.07    nan 0.09  0.157   nan 0.143\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.429   nan 1.    0.56  1.      nan 0.543 0.8     nan\n",
      "  0.788 0.9  ]\n",
      " [0.357   nan 0.755 0.179 0.025 0.281 0.5     nan   nan 0.322 0.8   0.309\n",
      "    nan   nan]\n",
      " [0.671   nan 1.    0.686 0.51  0.821   nan   nan   nan 0.857 1.    0.429\n",
      "  0.745   nan]\n",
      " [0.607   nan 0.8   0.429 0.3   0.737   nan   nan   nan 0.643 1.    0.286\n",
      "  0.5     nan]\n",
      " [0.4     nan 1.    0.329 0.21  0.81    nan   nan   nan 0.371 1.    0.307\n",
      "  0.588   nan]\n",
      " [  nan   nan 0.854 0.314 0.22  0.684   nan   nan 0.34  0.536 0.8   0.3\n",
      "  0.515   nan]\n",
      " [0.286 0.19    nan 0.357 0.26  0.305 0.63    nan   nan 0.343 0.44    nan\n",
      "  0.291   nan]\n",
      " [0.386   nan   nan 0.2   0.05  0.768   nan   nan 0.213 0.657 0.84    nan\n",
      "  0.281 0.667]\n",
      " [  nan   nan 0.866 0.214 0.05  0.358 0.29  0.      nan 0.186   nan 0.386\n",
      "  0.528   nan]\n",
      " [0.453   nan 0.817   nan   nan 0.711 0.588   nan   nan 0.607 1.    0.277\n",
      "  0.475 0.722]\n",
      " [1.      nan   nan 0.525 0.368 1.      nan 1.      nan 0.539 1.    0.212\n",
      "    nan 0.713]\n",
      " [  nan 0.07  0.28    nan   nan   nan 0.72    nan 0.    0.322 0.4   0.086\n",
      "  0.133 0.227]\n",
      " [0.086 0.    0.507 0.071   nan 0.526 0.      nan   nan 0.157 0.56    nan\n",
      "  0.249   nan]\n",
      " [0.611   nan 0.392 0.375 0.181 0.52    nan   nan   nan 0.538 0.84  0.212\n",
      "  0.297   nan]\n",
      " [  nan   nan 1.    0.143 0.    0.421 0.46    nan   nan 0.336   nan 0.393\n",
      "  0.606 0.453]\n",
      " [  nan 0.15  0.653 0.      nan 0.    0.1     nan   nan 0.    0.    0.393\n",
      "  0.655   nan]\n",
      " [0.447   nan 0.489 0.357 0.167 0.754   nan   nan   nan 0.571 1.    0.214\n",
      "  0.434   nan]\n",
      " [0.143   nan 0.467   nan   nan 0.      nan   nan 0.    0.25  0.    0.\n",
      "  0.    0.   ]\n",
      " [  nan   nan 0.52  0.314 0.18  0.347   nan 0.028 0.18  0.328   nan   nan\n",
      "  0.309 0.747]\n",
      " [  nan   nan 0.815 0.488 0.168   nan   nan   nan 0.089 0.377 0.267 0.273\n",
      "  0.568 0.52 ]\n",
      " [0.514   nan 1.    0.214 0.05    nan   nan   nan   nan 0.764 0.8   0.079\n",
      "  0.242 0.1  ]\n",
      " [  nan   nan 0.427 0.214 0.05  0.513   nan 0.167 0.2   0.264   nan   nan\n",
      "  0.273 0.675]\n",
      " [0.314 0.2   0.506 0.429   nan   nan   nan   nan 0.21  0.536 0.8   0.293\n",
      "  0.333   nan]\n",
      " [  nan   nan 0.76  0.272 0.11  0.526   nan 1.      nan 0.143   nan 0.271\n",
      "  0.545 0.493]\n",
      " [  nan   nan 0.6   0.314 0.21  1.    0.4   1.      nan 0.471   nan   nan\n",
      "  0.515 0.514]\n",
      " [  nan 0.125   nan 0.143 0.    0.369 0.42  0.817   nan 0.257   nan   nan\n",
      "  0.227 0.347]\n",
      " [0.7     nan 1.    0.415 0.23  0.684   nan   nan   nan 0.772 1.    0.414\n",
      "  0.758   nan]\n",
      " [0.371   nan 0.787 0.386 0.25    nan   nan   nan   nan 0.543 1.    0.279\n",
      "  0.509 0.667]\n",
      " [0.486   nan   nan 1.    1.    1.      nan 1.      nan 0.607 1.      nan\n",
      "  0.564 0.92 ]\n",
      " [0.429   nan 0.68  0.214 0.05  0.088   nan   nan   nan 0.457 1.    0.221\n",
      "    nan 0.6  ]\n",
      " [0.543   nan 0.747 0.643 0.45    nan   nan   nan 0.84  0.671 1.    0.778\n",
      "  0.751   nan]\n",
      " [0.943   nan 1.      nan   nan 1.      nan 1.      nan 0.772 1.    0.55\n",
      "  0.891 0.947]\n",
      " [0.371   nan 0.733 0.257 0.1     nan   nan   nan 0.2   0.686 0.88  0.25\n",
      "  0.406   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.25  0.    0.8     nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.226 0.143 0.01  0.726   nan 0.583   nan 0.1     nan 0.072\n",
      "  0.049 0.059]\n",
      " [0.429   nan 0.68  0.271 0.1   0.326   nan   nan   nan 0.357 1.    0.25\n",
      "  0.461   nan]\n",
      " [0.568   nan 0.911 0.938 0.419   nan   nan   nan 1.    0.661 0.92  0.576\n",
      "  0.881   nan]\n",
      " [0.815   nan 0.867 0.286 0.2   0.39  0.41  0.5     nan 0.521   nan 0.036\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733 0.214 0.05  0.684   nan   nan   nan 0.25  1.    0.304\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.48  0.286 0.125 0.726   nan 0.35  0.25  0.312   nan   nan\n",
      "  0.431 0.675]\n",
      " [1.    0.83  1.    0.786 0.6     nan   nan   nan 0.95  0.971   nan 0.571\n",
      "  0.897   nan]\n",
      " [0.429   nan 0.75  0.268 0.113 0.724   nan 0.375   nan 0.58  1.    0.259\n",
      "    nan   nan]\n",
      " [0.579   nan   nan 0.913 0.297 0.693   nan 0.792 0.267 0.446 0.56    nan\n",
      "    nan 0.567]\n",
      " [  nan   nan 0.467 0.25  0.075 0.711   nan 0.209 0.25  0.286   nan   nan\n",
      "  0.41  0.667]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 70\n",
      "Average improvement: 0.28357142857142853\n",
      "Standard deviation: 0.26580534293212194\n",
      "prediction score:  [[0.393   nan   nan 0.214 0.05  0.642 0.18  0.583   nan 0.729 1.      nan\n",
      "  0.227 0.817]\n",
      " [0.929   nan 1.    0.272 0.17  0.831   nan   nan 0.7   0.95  1.    0.693\n",
      "  0.915   nan]\n",
      " [0.506   nan 0.504 0.438 0.194 0.    0.278   nan   nan 0.223 1.    0.212\n",
      "  0.367   nan]\n",
      " [0.357   nan 0.556 0.286 0.1   0.737   nan   nan   nan 0.536 0.8   0.25\n",
      "  0.455 0.7  ]\n",
      " [0.357   nan 0.64  0.286 0.1   0.105   nan   nan 0.3   0.536 0.8   0.264\n",
      "  0.4     nan]\n",
      " [  nan   nan 0.52  0.286 0.16  0.811   nan 0.383 0.31  0.357 0.      nan\n",
      "  0.449 0.827]\n",
      " [0.085   nan 0.773 0.114 0.    0.063 0.07    nan 0.09  0.157   nan 0.143\n",
      "  0.315   nan]\n",
      " [0.357   nan   nan 0.386 0.05  1.    0.56  1.      nan 0.543 0.8     nan\n",
      "  0.788 0.9  ]\n",
      " [0.357   nan 0.783 0.179 0.025 0.281 0.5     nan   nan 0.322 0.8   0.309\n",
      "  0.576   nan]\n",
      " [0.671   nan 1.    0.686 0.51  0.842   nan 0.667   nan 0.857 1.    0.429\n",
      "  0.745   nan]\n",
      " [0.607   nan 0.8   0.429 0.3   0.737 0.6     nan   nan 0.643 1.    0.286\n",
      "  0.5     nan]\n",
      " [0.4     nan 1.    0.329 0.21  0.821   nan 0.583   nan 0.371 1.    0.307\n",
      "  0.588   nan]\n",
      " [0.429   nan 0.854 0.314 0.22  0.684   nan   nan 0.34  0.543 1.    0.3\n",
      "  0.515   nan]\n",
      " [0.286 0.19    nan 0.357 0.26  0.305 0.63    nan 0.27  0.343 0.44    nan\n",
      "  0.291   nan]\n",
      " [0.386   nan   nan 0.2   0.05  0.789   nan 0.    0.213 0.657 0.84    nan\n",
      "  0.281 0.667]\n",
      " [  nan   nan 0.866 0.214 0.05  0.358 0.29  0.      nan 0.257 0.2   0.386\n",
      "  0.528   nan]\n",
      " [0.453   nan 0.817   nan   nan 0.711 0.588   nan 0.75  0.607 1.    0.277\n",
      "  0.475 0.722]\n",
      " [1.      nan 0.556 0.525 0.368 1.      nan 1.      nan 0.539 1.    0.212\n",
      "    nan 0.713]\n",
      " [  nan 0.07  0.28    nan   nan   nan 0.72  0.1   0.    0.322 0.4   0.086\n",
      "  0.133 0.227]\n",
      " [0.086 0.    0.453 0.071   nan 0.526 0.      nan   nan 0.157 0.56  0.214\n",
      "  0.249   nan]\n",
      " [0.611 0.    0.392 0.375 0.181 0.52    nan   nan   nan 0.538 0.84  0.212\n",
      "  0.297   nan]\n",
      " [0.214   nan 1.    0.143 0.    0.421 0.46    nan   nan 0.336   nan 0.393\n",
      "  0.606 0.453]\n",
      " [  nan 0.15  0.653 0.    0.15  0.    0.1     nan   nan 0.    0.    0.393\n",
      "  0.655   nan]\n",
      " [0.447   nan 0.489 0.357 0.167 0.776   nan 0.583   nan 0.571 1.    0.214\n",
      "  0.434   nan]\n",
      " [0.143 0.    0.467   nan   nan 0.      nan   nan 0.    0.25  0.    0.\n",
      "  0.    0.   ]\n",
      " [  nan 0.35  0.52  0.314 0.18  0.347   nan 0.028 0.18  0.328   nan   nan\n",
      "  0.309 0.747]\n",
      " [  nan   nan 0.815 0.488 0.168   nan   nan 0.    0.089 0.377 0.267 0.273\n",
      "  0.568 0.52 ]\n",
      " [0.514   nan 1.    0.214 0.05    nan   nan   nan 0.25  0.764 0.8   0.079\n",
      "  0.26  0.1  ]\n",
      " [  nan   nan 0.427 0.214 0.05  0.537 0.5   0.167 0.2   0.264   nan   nan\n",
      "  0.273 0.675]\n",
      " [0.314 0.2   0.506 0.571 0.3     nan   nan   nan 0.21  0.536 0.8   0.293\n",
      "  0.333   nan]\n",
      " [  nan   nan 0.76  0.272 0.11  0.526 0.5   1.      nan 0.143   nan 0.271\n",
      "  0.545 0.493]\n",
      " [0.071   nan 0.6   0.314 0.21  1.    0.4   1.      nan 0.471   nan   nan\n",
      "  0.515 0.514]\n",
      " [  nan 0.125   nan 0.143 0.    0.369 0.42  0.817   nan 0.307 0.2     nan\n",
      "  0.227 0.347]\n",
      " [0.7     nan 1.    0.415 0.23  0.684   nan   nan 0.25  0.772 1.    0.414\n",
      "  0.751   nan]\n",
      " [0.371   nan 0.787 0.386 0.25  0.053   nan   nan   nan 0.493 1.    0.279\n",
      "  0.509 0.667]\n",
      " [0.486   nan   nan 1.    1.    1.      nan 1.      nan 0.607 1.    0.5\n",
      "  0.594 0.92 ]\n",
      " [0.429 0.05  0.68  0.214 0.05  0.088   nan   nan   nan 0.457 1.    0.221\n",
      "    nan 0.6  ]\n",
      " [0.543 0.6   0.747 0.643 0.45    nan   nan   nan 0.84  0.671 1.    0.778\n",
      "  0.751   nan]\n",
      " [0.943   nan 1.    0.5   0.25  1.      nan 1.      nan 0.772 1.    0.55\n",
      "  0.891 0.947]\n",
      " [0.371   nan 0.733 0.257 0.1     nan 0.6     nan 0.2   0.686 0.88  0.25\n",
      "  0.406   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.25  0.    0.8     nan\n",
      "  0.455 0.733]\n",
      " [  nan   nan 0.226 0.143 0.01  0.726 0.55  0.583   nan 0.1     nan 0.072\n",
      "  0.049 0.059]\n",
      " [0.429   nan 0.68  0.271 0.1   0.326 0.5     nan   nan 0.357 1.    0.25\n",
      "  0.461   nan]\n",
      " [0.568   nan 0.911 0.938 0.419   nan   nan   nan 1.    0.661 0.92  0.576\n",
      "  0.881 0.7  ]\n",
      " [0.815   nan 0.867 0.286 0.2   0.39  0.41  0.5   0.71  0.521   nan 0.036\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733 0.214 0.05  0.684   nan   nan 0.3   0.25  1.    0.304\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.48  0.286 0.125 0.726 0.2   0.35  0.25  0.312   nan   nan\n",
      "  0.431 0.675]\n",
      " [1.    0.83  1.    0.786 0.6     nan 0.95    nan 0.95  0.971   nan 0.571\n",
      "  0.897   nan]\n",
      " [0.429   nan 0.787 0.268 0.113 0.724   nan 0.375   nan 0.58  1.    0.259\n",
      "  0.576   nan]\n",
      " [0.579   nan   nan 0.913 0.297 0.693   nan 0.792 0.133 0.446 0.56    nan\n",
      "  0.568 0.567]\n",
      " [  nan 0.25  0.467 0.25  0.075 0.711   nan 0.209 0.25  0.286   nan   nan\n",
      "  0.41  0.667]]\n",
      "current score:  [[0.393   nan   nan 0.214 0.05  0.611 0.18    nan   nan 0.729 1.      nan\n",
      "  0.227 0.817]\n",
      " [0.929   nan 1.    0.272 0.17    nan   nan   nan 0.7   0.957 1.    0.693\n",
      "  0.915   nan]\n",
      " [0.506   nan 0.504 0.438 0.194 0.      nan   nan   nan 0.223 1.    0.212\n",
      "  0.367   nan]\n",
      " [0.357   nan 0.467 0.286 0.1   0.737   nan   nan   nan 0.536 0.8     nan\n",
      "  0.455 0.7  ]\n",
      " [0.357   nan 0.64  0.286 0.1     nan   nan   nan 0.3   0.536 0.8   0.264\n",
      "  0.4     nan]\n",
      " [  nan   nan 0.52  0.286 0.16  0.811   nan 0.383 0.31  0.329   nan   nan\n",
      "  0.449 0.827]\n",
      " [0.085   nan 0.773 0.114 0.    0.063 0.07    nan 0.09  0.157   nan 0.143\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.429   nan 1.    0.56  1.      nan 0.543 0.8     nan\n",
      "  0.788 0.9  ]\n",
      " [0.357   nan 0.755 0.179 0.025 0.281 0.5     nan   nan 0.322 0.8   0.309\n",
      "    nan   nan]\n",
      " [0.671   nan 1.    0.686 0.51  0.821   nan   nan   nan 0.857 1.    0.429\n",
      "  0.745   nan]\n",
      " [0.607   nan 0.8   0.429 0.3   0.737   nan   nan   nan 0.643 1.    0.286\n",
      "  0.5     nan]\n",
      " [0.4     nan 1.    0.329 0.21  0.81    nan   nan   nan 0.371 1.    0.307\n",
      "  0.588   nan]\n",
      " [  nan   nan 0.854 0.314 0.22  0.684   nan   nan 0.34  0.536 0.8   0.3\n",
      "  0.515   nan]\n",
      " [0.286 0.19    nan 0.357 0.26  0.305 0.63    nan   nan 0.343 0.44    nan\n",
      "  0.291   nan]\n",
      " [0.386   nan   nan 0.2   0.05  0.768   nan   nan 0.213 0.657 0.84    nan\n",
      "  0.281 0.667]\n",
      " [  nan   nan 0.866 0.214 0.05  0.358 0.29  0.      nan 0.186   nan 0.386\n",
      "  0.528   nan]\n",
      " [0.453   nan 0.817   nan   nan 0.711 0.588   nan   nan 0.607 1.    0.277\n",
      "  0.475 0.722]\n",
      " [1.      nan   nan 0.525 0.368 1.      nan 1.      nan 0.539 1.    0.212\n",
      "    nan 0.713]\n",
      " [  nan 0.07  0.28    nan   nan   nan 0.72    nan 0.    0.322 0.4   0.086\n",
      "  0.133 0.227]\n",
      " [0.086 0.    0.507 0.071   nan 0.526 0.      nan   nan 0.157 0.56    nan\n",
      "  0.249   nan]\n",
      " [0.611   nan 0.392 0.375 0.181 0.52    nan   nan   nan 0.538 0.84  0.212\n",
      "  0.297   nan]\n",
      " [  nan   nan 1.    0.143 0.    0.421 0.46    nan   nan 0.336   nan 0.393\n",
      "  0.606 0.453]\n",
      " [  nan 0.15  0.653 0.      nan 0.    0.1     nan   nan 0.    0.    0.393\n",
      "  0.655   nan]\n",
      " [0.447   nan 0.489 0.357 0.167 0.754   nan   nan   nan 0.571 1.    0.214\n",
      "  0.434   nan]\n",
      " [0.143   nan 0.467   nan   nan 0.      nan   nan 0.    0.25  0.    0.\n",
      "  0.    0.   ]\n",
      " [  nan   nan 0.52  0.314 0.18  0.347   nan 0.028 0.18  0.328   nan   nan\n",
      "  0.309 0.747]\n",
      " [  nan   nan 0.815 0.488 0.168   nan   nan   nan 0.089 0.377 0.267 0.273\n",
      "  0.568 0.52 ]\n",
      " [0.514   nan 1.    0.214 0.05    nan   nan   nan   nan 0.764 0.8   0.079\n",
      "  0.242 0.1  ]\n",
      " [  nan   nan 0.427 0.214 0.05  0.513   nan 0.167 0.2   0.264   nan   nan\n",
      "  0.273 0.675]\n",
      " [0.314 0.2   0.506 0.429   nan   nan   nan   nan 0.21  0.536 0.8   0.293\n",
      "  0.333   nan]\n",
      " [  nan   nan 0.76  0.272 0.11  0.526   nan 1.      nan 0.143   nan 0.271\n",
      "  0.545 0.493]\n",
      " [  nan   nan 0.6   0.314 0.21  1.    0.4   1.      nan 0.471   nan   nan\n",
      "  0.515 0.514]\n",
      " [  nan 0.125   nan 0.143 0.    0.369 0.42  0.817   nan 0.257   nan   nan\n",
      "  0.227 0.347]\n",
      " [0.7     nan 1.    0.415 0.23  0.684   nan   nan   nan 0.772 1.    0.414\n",
      "  0.758   nan]\n",
      " [0.371   nan 0.787 0.386 0.25    nan   nan   nan   nan 0.543 1.    0.279\n",
      "  0.509 0.667]\n",
      " [0.486   nan   nan 1.    1.    1.      nan 1.      nan 0.607 1.      nan\n",
      "  0.564 0.92 ]\n",
      " [0.429   nan 0.68  0.214 0.05  0.088   nan   nan   nan 0.457 1.    0.221\n",
      "    nan 0.6  ]\n",
      " [0.543   nan 0.747 0.643 0.45    nan   nan   nan 0.84  0.671 1.    0.778\n",
      "  0.751   nan]\n",
      " [0.943   nan 1.      nan   nan 1.      nan 1.      nan 0.772 1.    0.55\n",
      "  0.891 0.947]\n",
      " [0.371   nan 0.733 0.257 0.1     nan   nan   nan 0.2   0.686 0.88  0.25\n",
      "  0.406   nan]\n",
      " [0.357   nan 0.467 0.    0.    0.684   nan   nan 0.25  0.    0.8     nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.226 0.143 0.01  0.726   nan 0.583   nan 0.1     nan 0.072\n",
      "  0.049 0.059]\n",
      " [0.429   nan 0.68  0.271 0.1   0.326   nan   nan   nan 0.357 1.    0.25\n",
      "  0.461   nan]\n",
      " [0.568   nan 0.911 0.938 0.419   nan   nan   nan 1.    0.661 0.92  0.576\n",
      "  0.881   nan]\n",
      " [0.815   nan 0.867 0.286 0.2   0.39  0.41  0.5     nan 0.521   nan 0.036\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733 0.214 0.05  0.684   nan   nan   nan 0.25  1.    0.304\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.48  0.286 0.125 0.726   nan 0.35  0.25  0.312   nan   nan\n",
      "  0.431 0.675]\n",
      " [1.    0.83  1.    0.786 0.6     nan   nan   nan 0.95  0.971   nan 0.571\n",
      "  0.897   nan]\n",
      " [0.429   nan 0.75  0.268 0.113 0.724   nan 0.375   nan 0.58  1.    0.259\n",
      "    nan   nan]\n",
      " [0.579   nan   nan 0.913 0.297 0.693   nan 0.792 0.267 0.446 0.56    nan\n",
      "    nan 0.567]\n",
      " [  nan   nan 0.467 0.25  0.075 0.711   nan 0.209 0.25  0.286   nan   nan\n",
      "  0.41  0.667]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 70\n",
      "Average improvement: 0.28357142857142853\n",
      "Standard deviation: 0.26580534293212194\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[-5.9483945e-04 -3.5453811e-03  6.8316422e-03 ...  9.5573291e-03\n",
      "   7.6046698e-03 -9.9566355e-03]\n",
      " [ 3.0258998e-02 -1.0616824e-02 -2.1498967e-03 ...  5.7460070e-03\n",
      "   6.7131943e-01 -1.1373839e-02]\n",
      " [-7.8389123e-03 -4.0429235e-03  1.3526165e-02 ... -4.5969188e-03\n",
      "  -7.3201191e-03 -4.4572344e-03]\n",
      " ...\n",
      " [-1.9914284e-03  3.7539899e-03  3.6565232e-01 ... -2.2827834e-02\n",
      "  -1.6193926e-02  6.2600169e-03]\n",
      " [ 1.9388139e-02  3.6263466e-03  1.2946570e-02 ...  7.0988685e-03\n",
      "  -7.9616648e-04 -7.6403525e-03]\n",
      " [ 5.9923902e-03 -1.2218133e-02 -1.3414793e-02 ...  8.9632124e-03\n",
      "  -7.2328942e-03  8.4261652e-03]]\n",
      "current score:  [[  nan 0.86  0.666 ... 0.386 0.546 0.9  ]\n",
      " [1.      nan   nan ... 0.34    nan 0.867]\n",
      " [0.357 0.57  1.    ... 0.429 0.667   nan]\n",
      " ...\n",
      " [0.728   nan   nan ...   nan 0.794   nan]\n",
      " [0.632 1.      nan ... 0.473   nan   nan]\n",
      " [  nan 0.13  0.787 ... 0.307 0.509   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 6264\n",
      "Average improvement: 0.48252729725420934\n",
      "Standard deviation: 0.09316647667933507\n",
      "prediction score:  [[-5.9483945e-04 -3.5453811e-03  6.8316422e-03 ...  9.5573291e-03\n",
      "   7.6046698e-03 -9.9566355e-03]\n",
      " [ 3.0258998e-02 -1.0616824e-02 -2.1498967e-03 ...  5.7460070e-03\n",
      "   6.7131943e-01 -1.1373839e-02]\n",
      " [-7.8389123e-03 -4.0429235e-03  1.3526165e-02 ... -4.5969188e-03\n",
      "  -7.3201191e-03 -4.4572344e-03]\n",
      " ...\n",
      " [-1.9914284e-03  3.7539899e-03  3.6565232e-01 ... -2.2827834e-02\n",
      "  -1.6193926e-02  6.2600169e-03]\n",
      " [ 1.9388139e-02  3.6263466e-03  1.2946570e-02 ...  7.0988685e-03\n",
      "  -7.9616648e-04 -7.6403525e-03]\n",
      " [ 5.9923902e-03 -1.2218133e-02 -1.3414793e-02 ...  8.9632124e-03\n",
      "  -7.2328942e-03  8.4261652e-03]]\n",
      "current score:  [[  nan 0.86  0.666 ... 0.386 0.546 0.9  ]\n",
      " [1.      nan   nan ... 0.34    nan 0.867]\n",
      " [0.357 0.57  1.    ... 0.429 0.667   nan]\n",
      " ...\n",
      " [0.728   nan   nan ...   nan 0.794   nan]\n",
      " [0.632 1.      nan ... 0.473   nan   nan]\n",
      " [  nan 0.13  0.787 ... 0.307 0.509   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 6264\n",
      "Average improvement: 0.48252729725420934\n",
      "Standard deviation: 0.09316647667933507\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.67131943 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.67364055 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan 0.86  0.666 ... 0.386 0.546 0.9  ]\n",
      " [1.      nan   nan ... 0.34    nan 0.867]\n",
      " [0.357 0.57  1.    ... 0.429 0.667   nan]\n",
      " ...\n",
      " [0.728   nan   nan ...   nan 0.794   nan]\n",
      " [0.632 1.      nan ... 0.473   nan   nan]\n",
      " [  nan 0.13  0.787 ... 0.307 0.509   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 6264\n",
      "Average improvement: 0.5824251591084028\n",
      "Standard deviation: 0.09348886294898878\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.67131943 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.67364055 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan 0.86  0.666 ... 0.386 0.546 0.9  ]\n",
      " [1.      nan   nan ... 0.34    nan 0.867]\n",
      " [0.357 0.57  1.    ... 0.429 0.667   nan]\n",
      " ...\n",
      " [0.728   nan   nan ...   nan 0.794   nan]\n",
      " [0.632 1.      nan ... 0.473   nan   nan]\n",
      " [  nan 0.13  0.787 ... 0.307 0.509   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 6264\n",
      "Average improvement: 0.5824251591084028\n",
      "Standard deviation: 0.09348886294898878\n",
      "========= 6 missing\n",
      "----ground truth----\n",
      "prediction score:  [[  nan   nan 0.467 0.214 0.05  0.684   nan 0.    0.25  0.286   nan   nan\n",
      "  0.455 0.7  ]\n",
      " [0.579   nan 0.556 0.438 0.194 0.      nan   nan 0.133 0.5   0.8   0.182\n",
      "  0.568   nan]\n",
      " [0.357   nan 0.    0.143 0.    0.316 0.36    nan   nan 0.314 0.8     nan\n",
      "  0.    0.667]\n",
      " [  nan   nan 0.4   0.286 0.1   0.737   nan 0.167 0.25  0.286   nan   nan\n",
      "  0.424 0.7  ]\n",
      " [0.429   nan 0.733 0.286 0.1   0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.571 0.85    nan   nan   nan 0.6   0.53  0.1   0.31  0.386   nan   nan\n",
      "  0.697 0.86 ]\n",
      " [0.557 0.62  1.    0.357 0.32  0.242 0.13    nan 0.75    nan   nan   nan\n",
      "  0.77    nan]\n",
      " [0.429   nan 0.4   0.286 0.2     nan   nan   nan 0.6   0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.214   nan   nan 0.143 0.    0.221 0.1   0.117   nan 0.457 0.64    nan\n",
      "    nan 0.267]\n",
      " [0.057   nan 0.    0.119   nan 0.589 0.33  0.917   nan 0.414 0.56    nan\n",
      "  0.    0.46 ]\n",
      " [0.028 0.    0.414 0.129 0.    0.295 0.21    nan   nan 0.407   nan   nan\n",
      "  0.364   nan]\n",
      " [0.429   nan 0.667 0.214 0.05  0.684   nan   nan 0.    0.571 1.    0.214\n",
      "  0.      nan]\n",
      " [0.579   nan 0.333 0.5   0.226 0.067   nan   nan 0.133 0.5   0.8   0.152\n",
      "  0.243   nan]\n",
      " [0.357   nan 0.4   0.214 0.05  0.684   nan   nan 0.2   0.536 0.8   0.214\n",
      "  0.273   nan]\n",
      " [0.386   nan 1.    0.357   nan 0.684   nan   nan 0.7   0.55  1.    0.286\n",
      "  0.467   nan]\n",
      " [0.571   nan 0.667 0.214 0.05    nan   nan   nan 0.2   0.679 1.    0.214\n",
      "  0.273   nan]\n",
      " [0.947   nan 1.      nan 0.903   nan   nan   nan 0.973 0.923 1.    0.776\n",
      "  0.984 0.82 ]\n",
      " [0.393   nan 0.689   nan   nan 0.763   nan 0.667   nan 0.554 1.    0.232\n",
      "  0.455 0.7  ]\n",
      " [0.429   nan 0.733 0.286 0.1   0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.214 0.05  0.      nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.822 0.286 0.2   0.684   nan   nan   nan 0.571 1.    0.357\n",
      "  0.576   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.424 0.667]\n",
      " [0.619   nan 0.866 0.286 0.2   0.158   nan   nan 0.3   0.607 1.    0.286\n",
      "  0.677   nan]\n",
      " [0.585 0.59  0.906 0.629 0.37    nan   nan   nan 0.51  0.943   nan 0.457\n",
      "  0.733   nan]\n",
      " [0.393   nan 0.567   nan   nan 0.316 0.5     nan   nan 0.554 1.    0.25\n",
      "  0.455 0.   ]\n",
      " [0.3     nan   nan 0.243 0.11  0.947 0.58  0.917 0.17  0.314 0.72    nan\n",
      "  0.164   nan]\n",
      " [0.371   nan   nan 0.214 0.05  0.326 0.5   0.884   nan 0.336 0.84    nan\n",
      "    nan 0.72 ]\n",
      " [0.357   nan 0.    0.214 0.05  0.      nan   nan 0.2   0.536 0.8   0.\n",
      "  0.273   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.2   0.286   nan   nan\n",
      "  0.273 0.7  ]\n",
      " [0.429   nan 0.467   nan   nan 0.316 0.5   0.167   nan 0.571 1.      nan\n",
      "  0.455 0.667]\n",
      " [0.429   nan 0.667 0.214 0.05  0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429 0.05    nan 0.072 0.    0.368 0.25  0.334   nan 0.42  1.      nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.894 0.543 0.3   0.421 0.3     nan 0.65  0.814   nan 0.286\n",
      "  0.854   nan]\n",
      " [0.371   nan   nan 0.186 0.03  0.358 0.39  0.583   nan 0.414 0.84    nan\n",
      "    nan 0.674]\n",
      " [  nan   nan 1.    0.429 0.    0.284 0.31    nan 0.    0.279   nan 0.393\n",
      "  0.485   nan]\n",
      " [0.429   nan 0.4   0.214 0.05  0.684   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.737   nan 0.167 0.2   0.25    nan   nan\n",
      "  0.364 0.7  ]\n",
      " [0.357   nan 0.244 0.214 0.05  0.684   nan   nan   nan 0.536 0.8   0.125\n",
      "  0.      nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.25  0.286   nan   nan\n",
      "  0.455 0.7  ]\n",
      " [0.357   nan 0.4   0.286 0.1     nan   nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.386 0.21    nan 0.2   0.04  0.452   nan   nan 0.08  0.443   nan   nan\n",
      "  0.273 0.667]\n",
      " [0.571 0.      nan 0.143 0.      nan   nan   nan 0.31  0.722   nan 0.714\n",
      "  0.273 0.467]\n",
      " [0.529   nan 0.48  0.557 0.29    nan   nan 0.25    nan 0.643 1.    0.321\n",
      "  0.461   nan]\n",
      " [0.357   nan 0.4   0.214 0.05  0.      nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.667 0.214 0.05  0.737   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan   nan 0.157 0.    0.863 0.2   1.      nan 0.536 0.8     nan\n",
      "    nan 0.42 ]\n",
      " [0.929 0.07  0.76  0.643 0.5     nan   nan   nan   nan 0.793   nan 0.286\n",
      "  0.533 0.307]\n",
      " [0.429   nan 0.467 0.286 0.1   0.737   nan   nan 0.25  0.411 1.      nan\n",
      "  0.455 0.767]\n",
      " [0.071 0.27  0.907 0.157 0.03  0.61    nan 0.483   nan   nan   nan 0.\n",
      "  0.333   nan]\n",
      " [0.357   nan 0.    0.    0.      nan   nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.152   nan]\n",
      " [  nan   nan 0.52  0.    0.    0.013 0.317 0.      nan 0.661   nan 0.243\n",
      "    nan 0.267]\n",
      " [  nan   nan 1.    0.371 0.1   0.8     nan 0.389   nan 0.35    nan 0.357\n",
      "  0.588 0.8  ]\n",
      " [0.357   nan 0.534 0.071 0.01  0.453 0.5     nan   nan 0.436 0.8   0.171\n",
      "    nan   nan]\n",
      " [0.357   nan 0.133 0.243 0.06  0.263   nan   nan   nan 0.193 0.8   0.114\n",
      "  0.394   nan]\n",
      " [0.474   nan 0.956 0.763 0.522 0.52    nan   nan   nan 0.723 0.92    nan\n",
      "  0.919 1.   ]\n",
      " [0.4   0.43  0.733 0.214 0.08    nan   nan   nan 0.22  0.536   nan 0.2\n",
      "  0.291   nan]\n",
      " [  nan   nan 0.667 0.179 0.025 0.737   nan   nan 0.    0.125   nan 0.214\n",
      "  0.    0.133]\n",
      " [0.579   nan 0.519 0.238 0.026   nan   nan   nan   nan 0.254 0.8   0.14\n",
      "  0.746 0.2  ]\n",
      " [0.716 0.23    nan 0.5   0.129 0.2     nan   nan 0.333 0.631   nan 0.212\n",
      "  0.919   nan]]\n",
      "current score:  [[  nan   nan 0.467 0.214 0.05  0.684   nan 0.    0.25  0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.579   nan 0.556   nan   nan 0.      nan   nan 0.133 0.5   0.8   0.182\n",
      "  0.568   nan]\n",
      " [0.357   nan   nan 0.143 0.    0.316 0.36    nan   nan 0.314 0.8     nan\n",
      "    nan 0.667]\n",
      " [  nan   nan 0.4   0.286 0.1   0.737   nan 0.167 0.25  0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.571   nan   nan   nan   nan 0.6   0.53  0.1   0.31  0.386   nan   nan\n",
      "  0.697 0.86 ]\n",
      " [0.557 0.62  1.    0.357 0.32  0.242 0.13    nan   nan   nan   nan   nan\n",
      "  0.77    nan]\n",
      " [0.429   nan 0.4   0.286 0.2     nan   nan   nan   nan 0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.214   nan   nan 0.143 0.    0.221 0.1     nan   nan 0.457 0.64    nan\n",
      "    nan 0.267]\n",
      " [0.057   nan   nan 0.119   nan 0.589 0.33  0.917   nan 0.414 0.56    nan\n",
      "    nan 0.46 ]\n",
      " [0.028 0.    0.414 0.129 0.    0.284   nan   nan   nan 0.407   nan   nan\n",
      "  0.364   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.684   nan   nan 0.    0.571 1.    0.214\n",
      "  0.      nan]\n",
      " [0.579   nan 0.333   nan   nan 0.067   nan   nan 0.133 0.5   0.8   0.152\n",
      "  0.243   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.684   nan   nan 0.2   0.536 0.8   0.214\n",
      "  0.273   nan]\n",
      " [0.386   nan 1.      nan   nan 0.684   nan   nan 0.7   0.55  1.    0.286\n",
      "  0.467   nan]\n",
      " [0.571   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.679 1.    0.214\n",
      "  0.697   nan]\n",
      " [0.947   nan 1.      nan 0.903   nan   nan   nan 0.973 0.923   nan 0.776\n",
      "  0.984 0.82 ]\n",
      " [0.393   nan 0.689   nan   nan 0.719   nan   nan   nan 0.554 1.    0.232\n",
      "  0.455 0.7  ]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.      nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.8   0.286 0.2   0.684   nan   nan   nan 0.571 1.    0.357\n",
      "    nan   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.424   nan]\n",
      " [0.619   nan 0.866   nan   nan 0.158   nan   nan 0.3   0.607 1.    0.286\n",
      "  0.677   nan]\n",
      " [0.585 0.59    nan 0.629 0.37    nan   nan   nan 0.51  0.943   nan 0.457\n",
      "  0.733   nan]\n",
      " [0.393   nan 0.567   nan   nan 0.342   nan   nan   nan 0.554 1.    0.25\n",
      "  0.455 0.   ]\n",
      " [0.3     nan   nan 0.243 0.11    nan 0.58    nan 0.17  0.314 0.72    nan\n",
      "  0.164   nan]\n",
      " [0.371   nan   nan 0.214 0.05  0.326   nan 0.884   nan 0.336 0.84    nan\n",
      "    nan 0.72 ]\n",
      " [0.357   nan 0.      nan   nan 0.      nan   nan 0.2   0.536 0.8   0.\n",
      "  0.273   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.2   0.286   nan   nan\n",
      "  0.273   nan]\n",
      " [0.429   nan 0.467   nan   nan 0.106   nan 0.167   nan 0.571 1.      nan\n",
      "  0.455 0.667]\n",
      " [0.429   nan 0.667   nan   nan 0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan 0.072 0.    0.368 0.25  0.334   nan 0.42  1.      nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.894 0.543 0.3   0.421 0.3     nan 0.65  0.814   nan 0.286\n",
      "    nan   nan]\n",
      " [0.371   nan   nan 0.186 0.03  0.358 0.39    nan   nan 0.414 0.84    nan\n",
      "    nan 0.674]\n",
      " [  nan   nan 1.    0.429 0.    0.284 0.31    nan   nan 0.279   nan 0.393\n",
      "  0.606   nan]\n",
      " [0.429   nan 0.4     nan   nan 0.684   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.737   nan 0.167 0.2   0.25    nan   nan\n",
      "  0.364   nan]\n",
      " [0.357   nan 0.    0.214 0.05  0.684   nan   nan   nan 0.536 0.8     nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.25  0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.386 0.21    nan 0.2   0.04  0.452   nan   nan 0.08  0.443   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan 0.      nan 0.143 0.      nan   nan   nan 0.31  0.722   nan 0.714\n",
      "  0.273 0.467]\n",
      " [0.529   nan 0.48  0.557 0.29    nan   nan   nan   nan 0.643 1.    0.321\n",
      "  0.461   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.      nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.737   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan   nan 0.157 0.    1.      nan 1.      nan 0.536 0.8     nan\n",
      "    nan 0.42 ]\n",
      " [0.929 0.07    nan 0.643 0.5     nan   nan   nan   nan 0.793   nan 0.286\n",
      "  0.479 0.307]\n",
      " [  nan   nan 0.467 0.286 0.1   0.737   nan   nan 0.25  0.25    nan   nan\n",
      "  0.455 0.767]\n",
      " [0.071   nan 0.907 0.157 0.03  0.61    nan 0.483   nan   nan   nan 0.\n",
      "  0.333   nan]\n",
      " [0.357   nan 0.    0.    0.      nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.52  0.    0.    0.013 0.317   nan   nan 0.661   nan 0.243\n",
      "    nan 0.267]\n",
      " [  nan   nan 1.    0.375   nan 0.8     nan 0.389   nan 0.35    nan 0.357\n",
      "  0.588 0.8  ]\n",
      " [0.357   nan 0.534 0.071 0.01  0.453   nan   nan   nan 0.436 0.8   0.171\n",
      "    nan   nan]\n",
      " [0.357   nan 0.133 0.243 0.06    nan   nan   nan   nan 0.193 0.8   0.114\n",
      "  0.394   nan]\n",
      " [0.474   nan 0.956 0.763 0.522 0.52    nan   nan   nan 0.723 0.92    nan\n",
      "    nan 1.   ]\n",
      " [0.4   0.43  0.733 0.214 0.08    nan   nan   nan 0.22    nan   nan 0.2\n",
      "  0.291   nan]\n",
      " [  nan   nan 0.667 0.179 0.025 0.737   nan   nan 0.    0.125   nan 0.214\n",
      "  0.      nan]\n",
      " [0.579   nan   nan 0.238 0.026   nan   nan   nan   nan 0.254 0.8   0.14\n",
      "  0.746 0.2  ]\n",
      " [0.716 0.23    nan 0.5   0.129 0.2     nan   nan 0.333 0.631   nan   nan\n",
      "  0.919   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Number of predicted domains: 83\n",
      "Average improvement: 0.33878313253012043\n",
      "Standard deviation: 0.3050732038577279\n",
      "prediction score:  [[  nan   nan 0.467 0.214 0.05  0.684   nan 0.    0.25  0.286   nan   nan\n",
      "  0.455 0.7  ]\n",
      " [0.579   nan 0.556 0.438 0.194 0.      nan   nan 0.133 0.5   0.8   0.182\n",
      "  0.568   nan]\n",
      " [0.357   nan 0.    0.143 0.    0.316 0.36    nan   nan 0.314 0.8     nan\n",
      "  0.    0.667]\n",
      " [  nan   nan 0.4   0.286 0.1   0.737   nan 0.167 0.25  0.286   nan   nan\n",
      "  0.424 0.7  ]\n",
      " [0.429   nan 0.733 0.286 0.1   0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.571 0.85    nan   nan   nan 0.6   0.53  0.1   0.31  0.386   nan   nan\n",
      "  0.697 0.86 ]\n",
      " [0.557 0.62  1.    0.357 0.32  0.242 0.13    nan 0.75    nan   nan   nan\n",
      "  0.77    nan]\n",
      " [0.429   nan 0.4   0.286 0.2     nan   nan   nan 0.6   0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.214   nan   nan 0.143 0.    0.221 0.1   0.117   nan 0.457 0.64    nan\n",
      "    nan 0.267]\n",
      " [0.057   nan 0.    0.119   nan 0.589 0.33  0.917   nan 0.414 0.56    nan\n",
      "  0.    0.46 ]\n",
      " [0.028 0.    0.414 0.129 0.    0.295 0.21    nan   nan 0.407   nan   nan\n",
      "  0.364   nan]\n",
      " [0.429   nan 0.667 0.214 0.05  0.684   nan   nan 0.    0.571 1.    0.214\n",
      "  0.      nan]\n",
      " [0.579   nan 0.333 0.5   0.226 0.067   nan   nan 0.133 0.5   0.8   0.152\n",
      "  0.243   nan]\n",
      " [0.357   nan 0.4   0.214 0.05  0.684   nan   nan 0.2   0.536 0.8   0.214\n",
      "  0.273   nan]\n",
      " [0.386   nan 1.    0.357   nan 0.684   nan   nan 0.7   0.55  1.    0.286\n",
      "  0.467   nan]\n",
      " [0.571   nan 0.667 0.214 0.05    nan   nan   nan 0.2   0.679 1.    0.214\n",
      "  0.273   nan]\n",
      " [0.947   nan 1.      nan 0.903   nan   nan   nan 0.973 0.923 1.    0.776\n",
      "  0.984 0.82 ]\n",
      " [0.393   nan 0.689   nan   nan 0.763   nan 0.667   nan 0.554 1.    0.232\n",
      "  0.455 0.7  ]\n",
      " [0.429   nan 0.733 0.286 0.1   0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.214 0.05  0.      nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.822 0.286 0.2   0.684   nan   nan   nan 0.571 1.    0.357\n",
      "  0.576   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.424 0.667]\n",
      " [0.619   nan 0.866 0.286 0.2   0.158   nan   nan 0.3   0.607 1.    0.286\n",
      "  0.677   nan]\n",
      " [0.585 0.59  0.906 0.629 0.37    nan   nan   nan 0.51  0.943   nan 0.457\n",
      "  0.733   nan]\n",
      " [0.393   nan 0.567   nan   nan 0.316 0.5     nan   nan 0.554 1.    0.25\n",
      "  0.455 0.   ]\n",
      " [0.3     nan   nan 0.243 0.11  0.947 0.58  0.917 0.17  0.314 0.72    nan\n",
      "  0.164   nan]\n",
      " [0.371   nan   nan 0.214 0.05  0.326 0.5   0.884   nan 0.336 0.84    nan\n",
      "    nan 0.72 ]\n",
      " [0.357   nan 0.    0.214 0.05  0.      nan   nan 0.2   0.536 0.8   0.\n",
      "  0.273   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.2   0.286   nan   nan\n",
      "  0.273 0.7  ]\n",
      " [0.429   nan 0.467   nan   nan 0.316 0.5   0.167   nan 0.571 1.      nan\n",
      "  0.455 0.667]\n",
      " [0.429   nan 0.667 0.214 0.05  0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429 0.05    nan 0.072 0.    0.368 0.25  0.334   nan 0.42  1.      nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.894 0.543 0.3   0.421 0.3     nan 0.65  0.814   nan 0.286\n",
      "  0.854   nan]\n",
      " [0.371   nan   nan 0.186 0.03  0.358 0.39  0.583   nan 0.414 0.84    nan\n",
      "    nan 0.674]\n",
      " [  nan   nan 1.    0.429 0.    0.284 0.31    nan 0.    0.279   nan 0.393\n",
      "  0.485   nan]\n",
      " [0.429   nan 0.4   0.214 0.05  0.684   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.737   nan 0.167 0.2   0.25    nan   nan\n",
      "  0.364 0.7  ]\n",
      " [0.357   nan 0.244 0.214 0.05  0.684   nan   nan   nan 0.536 0.8   0.125\n",
      "  0.      nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.25  0.286   nan   nan\n",
      "  0.455 0.7  ]\n",
      " [0.357   nan 0.4   0.286 0.1     nan   nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.386 0.21    nan 0.2   0.04  0.452   nan   nan 0.08  0.443   nan   nan\n",
      "  0.273 0.667]\n",
      " [0.571 0.      nan 0.143 0.      nan   nan   nan 0.31  0.722   nan 0.714\n",
      "  0.273 0.467]\n",
      " [0.529   nan 0.48  0.557 0.29    nan   nan 0.25    nan 0.643 1.    0.321\n",
      "  0.461   nan]\n",
      " [0.357   nan 0.4   0.214 0.05  0.      nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.667 0.214 0.05  0.737   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan   nan 0.157 0.    0.863 0.2   1.      nan 0.536 0.8     nan\n",
      "    nan 0.42 ]\n",
      " [0.929 0.07  0.76  0.643 0.5     nan   nan   nan   nan 0.793   nan 0.286\n",
      "  0.533 0.307]\n",
      " [0.429   nan 0.467 0.286 0.1   0.737   nan   nan 0.25  0.411 1.      nan\n",
      "  0.455 0.767]\n",
      " [0.071 0.27  0.907 0.157 0.03  0.61    nan 0.483   nan   nan   nan 0.\n",
      "  0.333   nan]\n",
      " [0.357   nan 0.    0.    0.      nan   nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.152   nan]\n",
      " [  nan   nan 0.52  0.    0.    0.013 0.317 0.      nan 0.661   nan 0.243\n",
      "    nan 0.267]\n",
      " [  nan   nan 1.    0.371 0.1   0.8     nan 0.389   nan 0.35    nan 0.357\n",
      "  0.588 0.8  ]\n",
      " [0.357   nan 0.534 0.071 0.01  0.453 0.5     nan   nan 0.436 0.8   0.171\n",
      "    nan   nan]\n",
      " [0.357   nan 0.133 0.243 0.06  0.263   nan   nan   nan 0.193 0.8   0.114\n",
      "  0.394   nan]\n",
      " [0.474   nan 0.956 0.763 0.522 0.52    nan   nan   nan 0.723 0.92    nan\n",
      "  0.919 1.   ]\n",
      " [0.4   0.43  0.733 0.214 0.08    nan   nan   nan 0.22  0.536   nan 0.2\n",
      "  0.291   nan]\n",
      " [  nan   nan 0.667 0.179 0.025 0.737   nan   nan 0.    0.125   nan 0.214\n",
      "  0.    0.133]\n",
      " [0.579   nan 0.519 0.238 0.026   nan   nan   nan   nan 0.254 0.8   0.14\n",
      "  0.746 0.2  ]\n",
      " [0.716 0.23    nan 0.5   0.129 0.2     nan   nan 0.333 0.631   nan 0.212\n",
      "  0.919   nan]]\n",
      "current score:  [[  nan   nan 0.467 0.214 0.05  0.684   nan 0.    0.25  0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.579   nan 0.556   nan   nan 0.      nan   nan 0.133 0.5   0.8   0.182\n",
      "  0.568   nan]\n",
      " [0.357   nan   nan 0.143 0.    0.316 0.36    nan   nan 0.314 0.8     nan\n",
      "    nan 0.667]\n",
      " [  nan   nan 0.4   0.286 0.1   0.737   nan 0.167 0.25  0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.571   nan   nan   nan   nan 0.6   0.53  0.1   0.31  0.386   nan   nan\n",
      "  0.697 0.86 ]\n",
      " [0.557 0.62  1.    0.357 0.32  0.242 0.13    nan   nan   nan   nan   nan\n",
      "  0.77    nan]\n",
      " [0.429   nan 0.4   0.286 0.2     nan   nan   nan   nan 0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.214   nan   nan 0.143 0.    0.221 0.1     nan   nan 0.457 0.64    nan\n",
      "    nan 0.267]\n",
      " [0.057   nan   nan 0.119   nan 0.589 0.33  0.917   nan 0.414 0.56    nan\n",
      "    nan 0.46 ]\n",
      " [0.028 0.    0.414 0.129 0.    0.284   nan   nan   nan 0.407   nan   nan\n",
      "  0.364   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.684   nan   nan 0.    0.571 1.    0.214\n",
      "  0.      nan]\n",
      " [0.579   nan 0.333   nan   nan 0.067   nan   nan 0.133 0.5   0.8   0.152\n",
      "  0.243   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.684   nan   nan 0.2   0.536 0.8   0.214\n",
      "  0.273   nan]\n",
      " [0.386   nan 1.      nan   nan 0.684   nan   nan 0.7   0.55  1.    0.286\n",
      "  0.467   nan]\n",
      " [0.571   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.679 1.    0.214\n",
      "  0.697   nan]\n",
      " [0.947   nan 1.      nan 0.903   nan   nan   nan 0.973 0.923   nan 0.776\n",
      "  0.984 0.82 ]\n",
      " [0.393   nan 0.689   nan   nan 0.719   nan   nan   nan 0.554 1.    0.232\n",
      "  0.455 0.7  ]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan 0.25  0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.      nan   nan 0.25  0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.8   0.286 0.2   0.684   nan   nan   nan 0.571 1.    0.357\n",
      "    nan   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.424   nan]\n",
      " [0.619   nan 0.866   nan   nan 0.158   nan   nan 0.3   0.607 1.    0.286\n",
      "  0.677   nan]\n",
      " [0.585 0.59    nan 0.629 0.37    nan   nan   nan 0.51  0.943   nan 0.457\n",
      "  0.733   nan]\n",
      " [0.393   nan 0.567   nan   nan 0.342   nan   nan   nan 0.554 1.    0.25\n",
      "  0.455 0.   ]\n",
      " [0.3     nan   nan 0.243 0.11    nan 0.58    nan 0.17  0.314 0.72    nan\n",
      "  0.164   nan]\n",
      " [0.371   nan   nan 0.214 0.05  0.326   nan 0.884   nan 0.336 0.84    nan\n",
      "    nan 0.72 ]\n",
      " [0.357   nan 0.      nan   nan 0.      nan   nan 0.2   0.536 0.8   0.\n",
      "  0.273   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.2   0.286   nan   nan\n",
      "  0.273   nan]\n",
      " [0.429   nan 0.467   nan   nan 0.106   nan 0.167   nan 0.571 1.      nan\n",
      "  0.455 0.667]\n",
      " [0.429   nan 0.667   nan   nan 0.684   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan 0.072 0.    0.368 0.25  0.334   nan 0.42  1.      nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.894 0.543 0.3   0.421 0.3     nan 0.65  0.814   nan 0.286\n",
      "    nan   nan]\n",
      " [0.371   nan   nan 0.186 0.03  0.358 0.39    nan   nan 0.414 0.84    nan\n",
      "    nan 0.674]\n",
      " [  nan   nan 1.    0.429 0.    0.284 0.31    nan   nan 0.279   nan 0.393\n",
      "  0.606   nan]\n",
      " [0.429   nan 0.4     nan   nan 0.684   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.737   nan 0.167 0.2   0.25    nan   nan\n",
      "  0.364   nan]\n",
      " [0.357   nan 0.    0.214 0.05  0.684   nan   nan   nan 0.536 0.8     nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.25  0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.386 0.21    nan 0.2   0.04  0.452   nan   nan 0.08  0.443   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan 0.      nan 0.143 0.      nan   nan   nan 0.31  0.722   nan 0.714\n",
      "  0.273 0.467]\n",
      " [0.529   nan 0.48  0.557 0.29    nan   nan   nan   nan 0.643 1.    0.321\n",
      "  0.461   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.      nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.737   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan   nan 0.157 0.    1.      nan 1.      nan 0.536 0.8     nan\n",
      "    nan 0.42 ]\n",
      " [0.929 0.07    nan 0.643 0.5     nan   nan   nan   nan 0.793   nan 0.286\n",
      "  0.479 0.307]\n",
      " [  nan   nan 0.467 0.286 0.1   0.737   nan   nan 0.25  0.25    nan   nan\n",
      "  0.455 0.767]\n",
      " [0.071   nan 0.907 0.157 0.03  0.61    nan 0.483   nan   nan   nan 0.\n",
      "  0.333   nan]\n",
      " [0.357   nan 0.    0.    0.      nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.52  0.    0.    0.013 0.317   nan   nan 0.661   nan 0.243\n",
      "    nan 0.267]\n",
      " [  nan   nan 1.    0.375   nan 0.8     nan 0.389   nan 0.35    nan 0.357\n",
      "  0.588 0.8  ]\n",
      " [0.357   nan 0.534 0.071 0.01  0.453   nan   nan   nan 0.436 0.8   0.171\n",
      "    nan   nan]\n",
      " [0.357   nan 0.133 0.243 0.06    nan   nan   nan   nan 0.193 0.8   0.114\n",
      "  0.394   nan]\n",
      " [0.474   nan 0.956 0.763 0.522 0.52    nan   nan   nan 0.723 0.92    nan\n",
      "    nan 1.   ]\n",
      " [0.4   0.43  0.733 0.214 0.08    nan   nan   nan 0.22    nan   nan 0.2\n",
      "  0.291   nan]\n",
      " [  nan   nan 0.667 0.179 0.025 0.737   nan   nan 0.    0.125   nan 0.214\n",
      "  0.      nan]\n",
      " [0.579   nan   nan 0.238 0.026   nan   nan   nan   nan 0.254 0.8   0.14\n",
      "  0.746 0.2  ]\n",
      " [0.716 0.23    nan 0.5   0.129 0.2     nan   nan 0.333 0.631   nan   nan\n",
      "  0.919   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Number of predicted domains: 83\n",
      "Average improvement: 0.33878313253012043\n",
      "Standard deviation: 0.3050732038577279\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[-2.2450015e-03 -2.5306717e-03  7.4874765e-01 ... -2.5074035e-03\n",
      "  -1.8370040e-02  7.0686843e-03]\n",
      " [ 1.2659878e-02 -1.9660965e-03 -3.2218285e-03 ... -4.0822700e-03\n",
      "  -4.2918278e-03 -5.6195632e-03]\n",
      " [-6.7106336e-03 -1.7345876e-02 -1.4329612e-02 ...  8.0039650e-03\n",
      "  -6.8303170e-03  9.0200342e-03]\n",
      " ...\n",
      " [-2.6483834e-04  5.5082679e-01  1.0655278e-02 ... -9.1126338e-03\n",
      "  -4.5099584e-03 -2.1138964e-03]\n",
      " [ 6.4253211e-03 -2.8580278e-03  7.6041324e-03 ...  4.4417918e-01\n",
      "  -2.8010737e-04 -5.0098458e-03]\n",
      " [-2.0774715e-02 -1.0265790e-02 -9.3091223e-03 ...  9.3781874e-03\n",
      "  -9.8939668e-03 -2.8013778e-03]]\n",
      "current score:  [[0.768   nan   nan ...   nan   nan 0.913]\n",
      " [0.357   nan 0.689 ... 0.777 0.568   nan]\n",
      " [0.105 0.15    nan ... 0.091 0.432   nan]\n",
      " ...\n",
      " [0.579   nan 1.    ... 0.545   nan 0.413]\n",
      " [0.472   nan   nan ...   nan   nan 0.567]\n",
      " [0.214   nan   nan ...   nan   nan 0.533]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 3995\n",
      "Average improvement: 0.4816328121290935\n",
      "Standard deviation: 0.10656779631879615\n",
      "prediction score:  [[-2.2450015e-03 -2.5306717e-03  7.4874765e-01 ... -2.5074035e-03\n",
      "  -1.8370040e-02  7.0686843e-03]\n",
      " [ 1.2659878e-02 -1.9660965e-03 -3.2218285e-03 ... -4.0822700e-03\n",
      "  -4.2918278e-03 -5.6195632e-03]\n",
      " [-6.7106336e-03 -1.7345876e-02 -1.4329612e-02 ...  8.0039650e-03\n",
      "  -6.8303170e-03  9.0200342e-03]\n",
      " ...\n",
      " [-2.6483834e-04  5.5082679e-01  1.0655278e-02 ... -9.1126338e-03\n",
      "  -4.5099584e-03 -2.1138964e-03]\n",
      " [ 6.4253211e-03 -2.8580278e-03  7.6041324e-03 ...  4.4417918e-01\n",
      "  -2.8010737e-04 -5.0098458e-03]\n",
      " [-2.0774715e-02 -1.0265790e-02 -9.3091223e-03 ...  9.3781874e-03\n",
      "  -9.8939668e-03 -2.8013778e-03]]\n",
      "current score:  [[0.768   nan   nan ...   nan   nan 0.913]\n",
      " [0.357   nan 0.689 ... 0.777 0.568   nan]\n",
      " [0.105 0.15    nan ... 0.091 0.432   nan]\n",
      " ...\n",
      " [0.579   nan 1.    ... 0.545   nan 0.413]\n",
      " [0.472   nan   nan ...   nan   nan 0.567]\n",
      " [0.214   nan   nan ...   nan   nan 0.533]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 3995\n",
      "Average improvement: 0.4816328121290935\n",
      "Standard deviation: 0.10656779631879615\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.74874765 ... 0.         0.         0.        ]\n",
      " [0.         0.52293181 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.68806738 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.6494683  0.        ]\n",
      " [0.         0.         0.74815661 ... 0.         0.         0.        ]]\n",
      "current score:  [[0.768   nan   nan ...   nan   nan 0.913]\n",
      " [0.357   nan 0.689 ... 0.777 0.568   nan]\n",
      " [0.105 0.15    nan ... 0.091 0.432   nan]\n",
      " ...\n",
      " [0.579   nan 1.    ... 0.545   nan 0.413]\n",
      " [0.472   nan   nan ...   nan   nan 0.567]\n",
      " [0.214   nan   nan ...   nan   nan 0.533]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "Number of predicted domains: 3995\n",
      "Average improvement: 0.6084079505952636\n",
      "Standard deviation: 0.10480166358895837\n",
      "prediction score:  [[0.         0.         0.74874765 ... 0.         0.         0.        ]\n",
      " [0.         0.52293181 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.68806738 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.6494683  0.        ]\n",
      " [0.         0.         0.74815661 ... 0.         0.         0.        ]]\n",
      "current score:  [[0.768   nan   nan ...   nan   nan 0.913]\n",
      " [0.357   nan 0.689 ... 0.777 0.568   nan]\n",
      " [0.105 0.15    nan ... 0.091 0.432   nan]\n",
      " ...\n",
      " [0.579   nan 1.    ... 0.545   nan 0.413]\n",
      " [0.472   nan   nan ...   nan   nan 0.567]\n",
      " [0.214   nan   nan ...   nan   nan 0.533]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "Number of predicted domains: 3995\n",
      "Average improvement: 0.6084079505952636\n",
      "Standard deviation: 0.10480166358895837\n",
      "========= 7 missing\n",
      "----ground truth----\n",
      "prediction score:  [[0.357   nan 0.507 0.214 0.05    nan   nan   nan   nan 0.372 0.8   0.2\n",
      "  0.394   nan]\n",
      " [0.505 0.617 0.985 0.771 0.69    nan   nan   nan 0.34    nan   nan 0.571\n",
      "  0.848   nan]\n",
      " [  nan   nan 0.6   0.143 0.      nan   nan 0.    0.8   0.25    nan   nan\n",
      "  0.515 0.667]\n",
      " [0.357   nan   nan 0.214 0.05  0.684   nan 0.583   nan 0.25  0.8     nan\n",
      "    nan 0.7  ]\n",
      " [0.514   nan   nan   nan   nan 0.621 0.49  0.517   nan 0.7   1.      nan\n",
      "  0.    0.667]\n",
      " [0.211 0.15    nan   nan   nan 0.293   nan 1.    0.867 0.439 0.72    nan\n",
      "    nan 0.667]\n",
      " [  nan 0.175 0.854 0.179 0.025 0.869   nan 0.625 0.13    nan   nan 0.286\n",
      "  0.763   nan]\n",
      " [0.5     nan   nan 0.443 0.25  0.579 0.55    nan   nan 0.614 1.      nan\n",
      "    nan 0.687]\n",
      " [  nan   nan 0.689 0.214 0.05  0.711   nan   nan   nan 0.429 0.2   0.25\n",
      "    nan 0.567]\n",
      " [0.514 0.567 0.6   0.471 0.22    nan   nan   nan 0.16    nan   nan 0.179\n",
      "  0.521   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.509 0.5     nan   nan 0.214   nan 0.339\n",
      "    nan 0.233]\n",
      " [0.657   nan   nan 0.5   0.46  0.505 0.3   0.917   nan 0.529 1.      nan\n",
      "    nan   nan]\n",
      " [0.514 0.15  0.787 0.286 0.2     nan   nan   nan   nan 0.807   nan 0.307\n",
      "  0.442   nan]\n",
      " [  nan 0.97    nan 0.443 0.25    nan   nan   nan 0.3   0.743   nan 0.571\n",
      "  0.727 0.467]\n",
      " [  nan   nan 0.733 0.25  0.075 0.816   nan 0.667 0.85  0.25    nan 0.321\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.    0.25  0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.257 0.1   0.653 0.513 0.583   nan 0.393 0.      nan\n",
      "    nan 0.113]\n",
      " [0.357   nan 0.4     nan   nan 0.684   nan 0.583   nan 0.536 0.8   0.197\n",
      "  0.424   nan]\n",
      " [0.429   nan   nan 0.214 0.05  0.079 0.55    nan   nan 0.25  1.      nan\n",
      "    nan 0.667]\n",
      " [0.6   0.34  0.2   0.286   nan   nan   nan   nan 0.38    nan   nan 0.464\n",
      "  0.637 0.893]\n",
      " [0.357   nan   nan 0.143 0.    0.684 0.55    nan   nan 0.25  0.      nan\n",
      "    nan 0.   ]\n",
      " [0.429   nan 0.4   0.429   nan 0.408   nan   nan   nan 0.455 1.    0.268\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.167 0.25  0.25    nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan 0.25  0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan 0.263   nan   nan   nan 0.125 1.    0.25\n",
      "  0.424 0.7  ]\n",
      " [0.      nan 0.733 0.938 0.613   nan   nan   nan 0.25  0.25  0.    0.182\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.667   nan   nan 0.684   nan   nan 0.    0.536 0.8   0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.167 0.2   0.286   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan 0.2   0.933 0.228 0.09  0.642 0.51    nan 0.15    nan   nan   nan\n",
      "  0.358   nan]\n",
      " [0.5     nan 0.813 0.2   0.04  0.105 0.53    nan   nan 0.321   nan 0.272\n",
      "    nan   nan]\n",
      " [0.014   nan 0.4   0.143 0.    0.379 0.26  0.684   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [0.857   nan 0.867 0.329 0.21  0.137   nan   nan   nan 0.443   nan 0.122\n",
      "  0.685   nan]\n",
      " [  nan   nan 0.413 0.171 0.02  0.337 0.2     nan   nan 0.307   nan 0.\n",
      "  0.443   nan]\n",
      " [0.357   nan   nan 0.157 0.01    nan 0.65  1.      nan 0.536 0.8     nan\n",
      "    nan 0.24 ]\n",
      " [0.071   nan 0.    0.1     nan 0.589   nan 0.183   nan 0.229 0.04    nan\n",
      "  0.      nan]\n",
      " [0.579   nan 0.123 0.    0.      nan   nan   nan   nan 0.135 0.8     nan\n",
      "  0.351 0.4  ]\n",
      " [0.857   nan   nan   nan   nan 0.326 0.    1.      nan 0.593 1.      nan\n",
      "  0.279 0.74 ]\n",
      " [0.429   nan 0.667   nan   nan 0.684   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [  nan 0.05    nan 0.143 0.    0.421 0.29  0.233   nan 0.407   nan   nan\n",
      "    nan 0.7  ]\n",
      " [1.      nan   nan 0.371 0.15  0.389   nan 1.      nan 0.321   nan   nan\n",
      "  0.509 0.787]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.2   0.286   nan   nan\n",
      "  0.273   nan]\n",
      " [0.514 0.28    nan 0.143 0.    0.263   nan 0.35    nan 0.278   nan   nan\n",
      "  0.485   nan]\n",
      " [0.632   nan   nan 0.438 0.194 0.      nan   nan 0.133 0.154 1.      nan\n",
      "  0.568 0.6  ]\n",
      " [0.429   nan   nan 0.125 0.05  0.592   nan 0.125   nan 0.429 1.      nan\n",
      "    nan 0.756]\n",
      " [0.579   nan 0.      nan   nan 0.      nan   nan 0.2   0.5   0.8   0.152\n",
      "  0.      nan]\n",
      " [0.215   nan 0.667   nan   nan 0.684   nan   nan 0.2   0.381 1.      nan\n",
      "  0.344 0.733]\n",
      " [0.357 0.2   0.4     nan   nan 0.747 0.89    nan 0.11  0.615   nan 0.036\n",
      "    nan   nan]\n",
      " [0.      nan 0.4   0.    0.      nan   nan   nan 0.2   0.25  0.    0.09\n",
      "  0.349   nan]\n",
      " [0.786 0.9   1.    0.5   0.25    nan   nan   nan 0.73  1.      nan 0.636\n",
      "  0.945   nan]\n",
      " [0.771   nan 0.92  0.386   nan   nan 0.91    nan 0.42  1.      nan 0.421\n",
      "  0.369   nan]\n",
      " [  nan 0.55  0.467 0.286 0.1   0.737   nan 0.167   nan   nan   nan 0.\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan 0.25  0.25  1.      nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.114 0.02  0.442 0.55    nan   nan 0.295   nan 0.171\n",
      "  0.424   nan]]\n",
      "current score:  [[0.357   nan 0.627 0.214 0.05    nan   nan   nan   nan 0.372 0.8   0.2\n",
      "    nan   nan]\n",
      " [  nan 0.617 1.    0.771 0.69    nan   nan   nan 0.34    nan   nan 0.571\n",
      "  0.848   nan]\n",
      " [  nan   nan 0.6   0.143 0.      nan   nan 0.    0.8   0.25    nan   nan\n",
      "  0.515   nan]\n",
      " [0.357   nan   nan 0.214 0.05  0.684   nan   nan   nan 0.25  0.8     nan\n",
      "    nan 0.7  ]\n",
      " [0.486   nan   nan   nan   nan 0.621 0.49  0.517   nan 0.7   1.      nan\n",
      "    nan 0.667]\n",
      " [0.211 0.15    nan   nan   nan 0.293   nan 1.      nan 0.439 0.72    nan\n",
      "    nan 0.667]\n",
      " [  nan 0.175 0.854   nan   nan 0.869   nan 0.625 0.13    nan   nan 0.286\n",
      "  0.763   nan]\n",
      " [0.5     nan   nan 0.443 0.25  0.579   nan   nan   nan 0.614 1.      nan\n",
      "    nan 0.687]\n",
      " [  nan   nan 0.689 0.214 0.05  0.711   nan   nan   nan 0.357   nan 0.25\n",
      "    nan 0.567]\n",
      " [0.514 0.567 0.6   0.471 0.22    nan   nan   nan   nan   nan   nan 0.179\n",
      "  0.521   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.509   nan   nan   nan 0.214   nan 0.339\n",
      "    nan 0.233]\n",
      " [0.657   nan   nan 0.5   0.46  0.505 0.3     nan   nan 0.529 1.      nan\n",
      "    nan   nan]\n",
      " [0.514 0.15  0.787 0.286 0.2     nan   nan   nan   nan 0.807   nan 0.307\n",
      "    nan   nan]\n",
      " [  nan 0.97    nan 0.443 0.25    nan   nan   nan 0.3   0.743   nan 0.571\n",
      "  0.727   nan]\n",
      " [  nan   nan 0.733 0.25  0.075 0.737   nan   nan 0.85  0.25    nan 0.321\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.      nan 0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.257 0.1   0.653 0.513 0.583   nan 0.393   nan   nan\n",
      "    nan 0.113]\n",
      " [0.357   nan 0.4     nan   nan 0.684   nan   nan   nan 0.536 0.8   0.197\n",
      "  0.424   nan]\n",
      " [0.429   nan   nan 0.214 0.05  0.079   nan   nan   nan 0.25  1.      nan\n",
      "    nan 0.667]\n",
      " [0.6   0.34  0.2   0.286   nan   nan   nan   nan   nan   nan   nan 0.464\n",
      "  0.637 0.893]\n",
      " [0.357   nan   nan 0.143 0.    0.684   nan   nan   nan 0.25  0.      nan\n",
      "    nan 0.   ]\n",
      " [0.429   nan 0.4     nan   nan 0.408   nan   nan   nan 0.455 1.    0.268\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.167   nan 0.25    nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.    1.    0.25\n",
      "  0.424 0.7  ]\n",
      " [0.      nan 0.733   nan   nan   nan   nan   nan 0.25  0.25  0.    0.182\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan 0.    0.536 0.8   0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.167   nan 0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.2   0.933 0.228 0.09  0.642 0.51    nan   nan   nan   nan   nan\n",
      "  0.358   nan]\n",
      " [0.5     nan 0.813 0.2   0.04  0.105   nan   nan   nan 0.321   nan 0.272\n",
      "    nan   nan]\n",
      " [0.014   nan 0.4   0.143 0.    0.379 0.26    nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [0.857   nan   nan 0.329 0.21  0.137   nan   nan   nan 0.443   nan 0.122\n",
      "  0.685   nan]\n",
      " [  nan   nan 0.413 0.171 0.02  0.337 0.2     nan   nan 0.307   nan   nan\n",
      "  0.43    nan]\n",
      " [0.357   nan   nan 0.157 0.01    nan   nan 1.      nan 0.536 0.8     nan\n",
      "    nan 0.24 ]\n",
      " [0.071   nan 0.    0.1     nan 0.589   nan 0.183   nan 0.229   nan   nan\n",
      "  0.      nan]\n",
      " [0.579   nan 0.185 0.    0.      nan   nan   nan   nan 0.135 0.8     nan\n",
      "    nan 0.4  ]\n",
      " [0.857   nan   nan   nan   nan 0.326   nan 1.      nan 0.593 1.      nan\n",
      "  0.279 0.74 ]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.421 0.29  0.233   nan 0.407   nan   nan\n",
      "    nan 0.7  ]\n",
      " [  nan   nan   nan 0.371 0.15  0.389   nan 1.      nan 0.321   nan   nan\n",
      "  0.509 0.787]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083   nan 0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.514 0.28    nan 0.143 0.    0.126   nan   nan   nan 0.278   nan   nan\n",
      "  0.485   nan]\n",
      " [0.632   nan   nan 0.438 0.194 0.      nan   nan   nan 0.154 1.      nan\n",
      "    nan 0.6  ]\n",
      " [  nan   nan   nan 0.125 0.05  0.592   nan 0.125   nan 0.411 0.333   nan\n",
      "    nan 0.756]\n",
      " [0.579   nan 0.      nan   nan   nan   nan   nan 0.2   0.5   0.8   0.152\n",
      "  0.      nan]\n",
      " [0.215   nan 0.667   nan   nan 0.684   nan   nan 0.2   0.381 1.      nan\n",
      "  0.344   nan]\n",
      " [0.357 0.2   0.4     nan   nan 0.747 0.89    nan 0.11    nan   nan 0.036\n",
      "    nan   nan]\n",
      " [0.      nan 0.4     nan   nan   nan   nan   nan 0.2   0.25  0.    0.09\n",
      "  0.349   nan]\n",
      " [0.786 0.9   1.      nan   nan   nan   nan   nan 0.73  1.      nan 0.636\n",
      "  0.945   nan]\n",
      " [0.771   nan 0.92  0.386   nan   nan 0.91    nan 0.42    nan   nan 0.421\n",
      "  0.369   nan]\n",
      " [  nan 0.55  0.    0.286 0.1   0.737   nan 0.167   nan   nan   nan 0.\n",
      "    nan   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.25  1.      nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.114 0.02  0.442   nan   nan   nan 0.295   nan 0.171\n",
      "  0.424   nan]]\n",
      "encoding:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 65\n",
      "Average improvement: 0.38735384615384616\n",
      "Standard deviation: 0.29710480215159507\n",
      "prediction score:  [[0.357   nan 0.507 0.214 0.05    nan   nan   nan   nan 0.372 0.8   0.2\n",
      "  0.394   nan]\n",
      " [0.505 0.617 0.985 0.771 0.69    nan   nan   nan 0.34    nan   nan 0.571\n",
      "  0.848   nan]\n",
      " [  nan   nan 0.6   0.143 0.      nan   nan 0.    0.8   0.25    nan   nan\n",
      "  0.515 0.667]\n",
      " [0.357   nan   nan 0.214 0.05  0.684   nan 0.583   nan 0.25  0.8     nan\n",
      "    nan 0.7  ]\n",
      " [0.514   nan   nan   nan   nan 0.621 0.49  0.517   nan 0.7   1.      nan\n",
      "  0.    0.667]\n",
      " [0.211 0.15    nan   nan   nan 0.293   nan 1.    0.867 0.439 0.72    nan\n",
      "    nan 0.667]\n",
      " [  nan 0.175 0.854 0.179 0.025 0.869   nan 0.625 0.13    nan   nan 0.286\n",
      "  0.763   nan]\n",
      " [0.5     nan   nan 0.443 0.25  0.579 0.55    nan   nan 0.614 1.      nan\n",
      "    nan 0.687]\n",
      " [  nan   nan 0.689 0.214 0.05  0.711   nan   nan   nan 0.429 0.2   0.25\n",
      "    nan 0.567]\n",
      " [0.514 0.567 0.6   0.471 0.22    nan   nan   nan 0.16    nan   nan 0.179\n",
      "  0.521   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.509 0.5     nan   nan 0.214   nan 0.339\n",
      "    nan 0.233]\n",
      " [0.657   nan   nan 0.5   0.46  0.505 0.3   0.917   nan 0.529 1.      nan\n",
      "    nan   nan]\n",
      " [0.514 0.15  0.787 0.286 0.2     nan   nan   nan   nan 0.807   nan 0.307\n",
      "  0.442   nan]\n",
      " [  nan 0.97    nan 0.443 0.25    nan   nan   nan 0.3   0.743   nan 0.571\n",
      "  0.727 0.467]\n",
      " [  nan   nan 0.733 0.25  0.075 0.816   nan 0.667 0.85  0.25    nan 0.321\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.    0.25  0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.257 0.1   0.653 0.513 0.583   nan 0.393 0.      nan\n",
      "    nan 0.113]\n",
      " [0.357   nan 0.4     nan   nan 0.684   nan 0.583   nan 0.536 0.8   0.197\n",
      "  0.424   nan]\n",
      " [0.429   nan   nan 0.214 0.05  0.079 0.55    nan   nan 0.25  1.      nan\n",
      "    nan 0.667]\n",
      " [0.6   0.34  0.2   0.286   nan   nan   nan   nan 0.38    nan   nan 0.464\n",
      "  0.637 0.893]\n",
      " [0.357   nan   nan 0.143 0.    0.684 0.55    nan   nan 0.25  0.      nan\n",
      "    nan 0.   ]\n",
      " [0.429   nan 0.4   0.429   nan 0.408   nan   nan   nan 0.455 1.    0.268\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.167 0.25  0.25    nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan 0.25  0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan 0.263   nan   nan   nan 0.125 1.    0.25\n",
      "  0.424 0.7  ]\n",
      " [0.      nan 0.733 0.938 0.613   nan   nan   nan 0.25  0.25  0.    0.182\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.667   nan   nan 0.684   nan   nan 0.    0.536 0.8   0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.167 0.2   0.286   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan 0.2   0.933 0.228 0.09  0.642 0.51    nan 0.15    nan   nan   nan\n",
      "  0.358   nan]\n",
      " [0.5     nan 0.813 0.2   0.04  0.105 0.53    nan   nan 0.321   nan 0.272\n",
      "    nan   nan]\n",
      " [0.014   nan 0.4   0.143 0.    0.379 0.26  0.684   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [0.857   nan 0.867 0.329 0.21  0.137   nan   nan   nan 0.443   nan 0.122\n",
      "  0.685   nan]\n",
      " [  nan   nan 0.413 0.171 0.02  0.337 0.2     nan   nan 0.307   nan 0.\n",
      "  0.443   nan]\n",
      " [0.357   nan   nan 0.157 0.01    nan 0.65  1.      nan 0.536 0.8     nan\n",
      "    nan 0.24 ]\n",
      " [0.071   nan 0.    0.1     nan 0.589   nan 0.183   nan 0.229 0.04    nan\n",
      "  0.      nan]\n",
      " [0.579   nan 0.123 0.    0.      nan   nan   nan   nan 0.135 0.8     nan\n",
      "  0.351 0.4  ]\n",
      " [0.857   nan   nan   nan   nan 0.326 0.    1.      nan 0.593 1.      nan\n",
      "  0.279 0.74 ]\n",
      " [0.429   nan 0.667   nan   nan 0.684   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [  nan 0.05    nan 0.143 0.    0.421 0.29  0.233   nan 0.407   nan   nan\n",
      "    nan 0.7  ]\n",
      " [1.      nan   nan 0.371 0.15  0.389   nan 1.      nan 0.321   nan   nan\n",
      "  0.509 0.787]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083 0.2   0.286   nan   nan\n",
      "  0.273   nan]\n",
      " [0.514 0.28    nan 0.143 0.    0.263   nan 0.35    nan 0.278   nan   nan\n",
      "  0.485   nan]\n",
      " [0.632   nan   nan 0.438 0.194 0.      nan   nan 0.133 0.154 1.      nan\n",
      "  0.568 0.6  ]\n",
      " [0.429   nan   nan 0.125 0.05  0.592   nan 0.125   nan 0.429 1.      nan\n",
      "    nan 0.756]\n",
      " [0.579   nan 0.      nan   nan 0.      nan   nan 0.2   0.5   0.8   0.152\n",
      "  0.      nan]\n",
      " [0.215   nan 0.667   nan   nan 0.684   nan   nan 0.2   0.381 1.      nan\n",
      "  0.344 0.733]\n",
      " [0.357 0.2   0.4     nan   nan 0.747 0.89    nan 0.11  0.615   nan 0.036\n",
      "    nan   nan]\n",
      " [0.      nan 0.4   0.    0.      nan   nan   nan 0.2   0.25  0.    0.09\n",
      "  0.349   nan]\n",
      " [0.786 0.9   1.    0.5   0.25    nan   nan   nan 0.73  1.      nan 0.636\n",
      "  0.945   nan]\n",
      " [0.771   nan 0.92  0.386   nan   nan 0.91    nan 0.42  1.      nan 0.421\n",
      "  0.369   nan]\n",
      " [  nan 0.55  0.467 0.286 0.1   0.737   nan 0.167   nan   nan   nan 0.\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan 0.25  0.25  1.      nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.114 0.02  0.442 0.55    nan   nan 0.295   nan 0.171\n",
      "  0.424   nan]]\n",
      "current score:  [[0.357   nan 0.627 0.214 0.05    nan   nan   nan   nan 0.372 0.8   0.2\n",
      "    nan   nan]\n",
      " [  nan 0.617 1.    0.771 0.69    nan   nan   nan 0.34    nan   nan 0.571\n",
      "  0.848   nan]\n",
      " [  nan   nan 0.6   0.143 0.      nan   nan 0.    0.8   0.25    nan   nan\n",
      "  0.515   nan]\n",
      " [0.357   nan   nan 0.214 0.05  0.684   nan   nan   nan 0.25  0.8     nan\n",
      "    nan 0.7  ]\n",
      " [0.486   nan   nan   nan   nan 0.621 0.49  0.517   nan 0.7   1.      nan\n",
      "    nan 0.667]\n",
      " [0.211 0.15    nan   nan   nan 0.293   nan 1.      nan 0.439 0.72    nan\n",
      "    nan 0.667]\n",
      " [  nan 0.175 0.854   nan   nan 0.869   nan 0.625 0.13    nan   nan 0.286\n",
      "  0.763   nan]\n",
      " [0.5     nan   nan 0.443 0.25  0.579   nan   nan   nan 0.614 1.      nan\n",
      "    nan 0.687]\n",
      " [  nan   nan 0.689 0.214 0.05  0.711   nan   nan   nan 0.357   nan 0.25\n",
      "    nan 0.567]\n",
      " [0.514 0.567 0.6   0.471 0.22    nan   nan   nan   nan   nan   nan 0.179\n",
      "  0.521   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.509   nan   nan   nan 0.214   nan 0.339\n",
      "    nan 0.233]\n",
      " [0.657   nan   nan 0.5   0.46  0.505 0.3     nan   nan 0.529 1.      nan\n",
      "    nan   nan]\n",
      " [0.514 0.15  0.787 0.286 0.2     nan   nan   nan   nan 0.807   nan 0.307\n",
      "    nan   nan]\n",
      " [  nan 0.97    nan 0.443 0.25    nan   nan   nan 0.3   0.743   nan 0.571\n",
      "  0.727   nan]\n",
      " [  nan   nan 0.733 0.25  0.075 0.737   nan   nan 0.85  0.25    nan 0.321\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.      nan 0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.257 0.1   0.653 0.513 0.583   nan 0.393   nan   nan\n",
      "    nan 0.113]\n",
      " [0.357   nan 0.4     nan   nan 0.684   nan   nan   nan 0.536 0.8   0.197\n",
      "  0.424   nan]\n",
      " [0.429   nan   nan 0.214 0.05  0.079   nan   nan   nan 0.25  1.      nan\n",
      "    nan 0.667]\n",
      " [0.6   0.34  0.2   0.286   nan   nan   nan   nan   nan   nan   nan 0.464\n",
      "  0.637 0.893]\n",
      " [0.357   nan   nan 0.143 0.    0.684   nan   nan   nan 0.25  0.      nan\n",
      "    nan 0.   ]\n",
      " [0.429   nan 0.4     nan   nan 0.408   nan   nan   nan 0.455 1.    0.268\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.167   nan 0.25    nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.737   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.    1.    0.25\n",
      "  0.424 0.7  ]\n",
      " [0.      nan 0.733   nan   nan   nan   nan   nan 0.25  0.25  0.    0.182\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan 0.    0.536 0.8   0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.167   nan 0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.2   0.933 0.228 0.09  0.642 0.51    nan   nan   nan   nan   nan\n",
      "  0.358   nan]\n",
      " [0.5     nan 0.813 0.2   0.04  0.105   nan   nan   nan 0.321   nan 0.272\n",
      "    nan   nan]\n",
      " [0.014   nan 0.4   0.143 0.    0.379 0.26    nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [0.857   nan   nan 0.329 0.21  0.137   nan   nan   nan 0.443   nan 0.122\n",
      "  0.685   nan]\n",
      " [  nan   nan 0.413 0.171 0.02  0.337 0.2     nan   nan 0.307   nan   nan\n",
      "  0.43    nan]\n",
      " [0.357   nan   nan 0.157 0.01    nan   nan 1.      nan 0.536 0.8     nan\n",
      "    nan 0.24 ]\n",
      " [0.071   nan 0.    0.1     nan 0.589   nan 0.183   nan 0.229   nan   nan\n",
      "  0.      nan]\n",
      " [0.579   nan 0.185 0.    0.      nan   nan   nan   nan 0.135 0.8     nan\n",
      "    nan 0.4  ]\n",
      " [0.857   nan   nan   nan   nan 0.326   nan 1.      nan 0.593 1.      nan\n",
      "  0.279 0.74 ]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.421 0.29  0.233   nan 0.407   nan   nan\n",
      "    nan 0.7  ]\n",
      " [  nan   nan   nan 0.371 0.15  0.389   nan 1.      nan 0.321   nan   nan\n",
      "  0.509 0.787]\n",
      " [  nan   nan 0.467 0.286 0.1   0.684   nan 0.083   nan 0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.514 0.28    nan 0.143 0.    0.126   nan   nan   nan 0.278   nan   nan\n",
      "  0.485   nan]\n",
      " [0.632   nan   nan 0.438 0.194 0.      nan   nan   nan 0.154 1.      nan\n",
      "    nan 0.6  ]\n",
      " [  nan   nan   nan 0.125 0.05  0.592   nan 0.125   nan 0.411 0.333   nan\n",
      "    nan 0.756]\n",
      " [0.579   nan 0.      nan   nan   nan   nan   nan 0.2   0.5   0.8   0.152\n",
      "  0.      nan]\n",
      " [0.215   nan 0.667   nan   nan 0.684   nan   nan 0.2   0.381 1.      nan\n",
      "  0.344   nan]\n",
      " [0.357 0.2   0.4     nan   nan 0.747 0.89    nan 0.11    nan   nan 0.036\n",
      "    nan   nan]\n",
      " [0.      nan 0.4     nan   nan   nan   nan   nan 0.2   0.25  0.    0.09\n",
      "  0.349   nan]\n",
      " [0.786 0.9   1.      nan   nan   nan   nan   nan 0.73  1.      nan 0.636\n",
      "  0.945   nan]\n",
      " [0.771   nan 0.92  0.386   nan   nan 0.91    nan 0.42    nan   nan 0.421\n",
      "  0.369   nan]\n",
      " [  nan 0.55  0.    0.286 0.1   0.737   nan 0.167   nan   nan   nan 0.\n",
      "    nan   nan]\n",
      " [0.429   nan 0.4   0.286 0.1     nan   nan   nan   nan 0.25  1.      nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.114 0.02  0.442   nan   nan   nan 0.295   nan 0.171\n",
      "  0.424   nan]]\n",
      "encoding:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 65\n",
      "Average improvement: 0.38735384615384616\n",
      "Standard deviation: 0.29710480215159507\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 8.49226862e-03 -1.13867223e-03 -6.24711625e-03 ... -7.02798367e-04\n",
      "   1.00310743e-02 -9.02229454e-03]\n",
      " [ 1.75139531e-02  3.31690907e-03 -4.62171249e-03 ...  1.56762451e-03\n",
      "  -3.50014307e-04 -1.38185686e-02]\n",
      " [ 1.08263567e-02 -1.40182450e-02 -7.50968792e-03 ...  2.65564024e-03\n",
      "  -3.91682191e-03  1.04062185e-02]\n",
      " ...\n",
      " [ 4.51031327e-03 -6.32757694e-03 -6.63426332e-03 ...  2.08880007e-03\n",
      "  -2.48776935e-03  1.61283370e-03]\n",
      " [-2.94628739e-03 -1.80634111e-03 -6.10144064e-03 ... -5.41269034e-03\n",
      "  -3.25100496e-04 -8.65506008e-05]\n",
      " [-2.97147781e-03 -4.84336168e-03  9.76117048e-03 ... -5.61922044e-03\n",
      "  -6.15192484e-03  5.83359659e-01]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.667]\n",
      " [0.4     nan   nan ...   nan   nan 0.1  ]\n",
      " [  nan   nan 0.726 ... 0.285 0.757   nan]\n",
      " ...\n",
      " [0.621   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ... 0.171 0.424   nan]\n",
      " [  nan 0.617 1.    ... 0.571 0.794   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 2515\n",
      "Average improvement: 0.474763926194155\n",
      "Standard deviation: 0.10750859158874337\n",
      "prediction score:  [[ 8.49226862e-03 -1.13867223e-03 -6.24711625e-03 ... -7.02798367e-04\n",
      "   1.00310743e-02 -9.02229454e-03]\n",
      " [ 1.75139531e-02  3.31690907e-03 -4.62171249e-03 ...  1.56762451e-03\n",
      "  -3.50014307e-04 -1.38185686e-02]\n",
      " [ 1.08263567e-02 -1.40182450e-02 -7.50968792e-03 ...  2.65564024e-03\n",
      "  -3.91682191e-03  1.04062185e-02]\n",
      " ...\n",
      " [ 4.51031327e-03 -6.32757694e-03 -6.63426332e-03 ...  2.08880007e-03\n",
      "  -2.48776935e-03  1.61283370e-03]\n",
      " [-2.94628739e-03 -1.80634111e-03 -6.10144064e-03 ... -5.41269034e-03\n",
      "  -3.25100496e-04 -8.65506008e-05]\n",
      " [-2.97147781e-03 -4.84336168e-03  9.76117048e-03 ... -5.61922044e-03\n",
      "  -6.15192484e-03  5.83359659e-01]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.667]\n",
      " [0.4     nan   nan ...   nan   nan 0.1  ]\n",
      " [  nan   nan 0.726 ... 0.285 0.757   nan]\n",
      " ...\n",
      " [0.621   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ... 0.171 0.424   nan]\n",
      " [  nan 0.617 1.    ... 0.571 0.794   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 2515\n",
      "Average improvement: 0.474763926194155\n",
      "Standard deviation: 0.10750859158874337\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.47285599 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.54452336]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.69023961 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.667]\n",
      " [0.4     nan   nan ...   nan   nan 0.1  ]\n",
      " [  nan   nan 0.726 ... 0.285 0.757   nan]\n",
      " ...\n",
      " [0.621   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ... 0.171 0.424   nan]\n",
      " [  nan 0.617 1.    ... 0.571 0.794   nan]]\n",
      "encoding:  [[0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 2515\n",
      "Average improvement: 0.610020618066636\n",
      "Standard deviation: 0.11196484487343249\n",
      "prediction score:  [[0.         0.         0.         ... 0.47285599 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.54452336]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.69023961 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.667]\n",
      " [0.4     nan   nan ...   nan   nan 0.1  ]\n",
      " [  nan   nan 0.726 ... 0.285 0.757   nan]\n",
      " ...\n",
      " [0.621   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ... 0.171 0.424   nan]\n",
      " [  nan 0.617 1.    ... 0.571 0.794   nan]]\n",
      "encoding:  [[0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 2515\n",
      "Average improvement: 0.610020618066636\n",
      "Standard deviation: 0.11196484487343249\n",
      "========= 8 missing\n",
      "----ground truth----\n",
      "prediction score:  [[  nan 0.363 0.345 0.413 0.205   nan 0.056   nan   nan 0.185   nan   nan\n",
      "  0.279   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.171 0.18  0.413   nan   nan 0.39    nan   nan   nan 0.278 0.4     nan\n",
      "  0.273 0.74 ]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan 0.25  0.571 1.    0.\n",
      "  0.424   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.737   nan   nan   nan 0.25  0.8   0.\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.267 0.143 0.    0.095 0.15    nan   nan 0.25    nan   nan\n",
      "  0.121 0.287]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan   nan   nan 0.286   nan 0.25\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.733 0.286 0.1   0.737   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.571 0.3     nan   nan   nan   nan 0.25  0.8   0.821\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.286 0.1   0.      nan   nan   nan 0.25    nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.767 0.286 0.15  0.316 0.5     nan   nan   nan   nan 0.357\n",
      "    nan 0.7  ]\n",
      " [  nan 0.05    nan 0.107 0.    0.053   nan 0.583   nan 0.143   nan   nan\n",
      "    nan 0.067]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan 0.25  0.    0.8   0.214\n",
      "  0.303   nan]\n",
      " [0.386   nan   nan 0.141   nan   nan 0.111   nan   nan 0.385 0.2     nan\n",
      "  0.595 0.617]\n",
      " [0.357   nan 0.434   nan   nan   nan   nan   nan 0.25  0.25  0.8   0.\n",
      "  0.44    nan]\n",
      " [0.557   nan   nan   nan   nan 0.621   nan 0.05    nan 0.557 1.      nan\n",
      "  0.727 0.667]\n",
      " [0.      nan 0.    0.    0.      nan   nan   nan   nan 0.    0.    0.214\n",
      "  0.      nan]\n",
      " [0.393   nan   nan   nan   nan 0.474   nan 0.1     nan 0.493 1.      nan\n",
      "  0.333 0.747]\n",
      " [  nan 0.66  0.548 0.575 0.316   nan   nan   nan   nan 0.154   nan 0.254\n",
      "  0.335   nan]\n",
      " [0.343   nan 0.613   nan   nan 0.59  0.46    nan   nan 0.364 0.76  0.179\n",
      "  0.551   nan]\n",
      " [0.197   nan 0.347   nan   nan 0.671 0.283   nan 0.15    nan   nan 0.197\n",
      "  0.176 0.407]\n",
      " [0.381   nan   nan 0.071   nan 0.719   nan 0.195   nan 0.548 1.      nan\n",
      "    nan 0.75 ]\n",
      " [0.357 0.15  0.653 0.071 0.13  0.158   nan   nan   nan   nan   nan 0.336\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.083   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [0.714 0.275 1.    0.414 0.41    nan   nan   nan 0.53    nan   nan   nan\n",
      "  0.727   nan]\n",
      " [0.429   nan 0.4   0.214 0.05  0.684   nan   nan   nan 0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan 0.167   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.146 0.032 0.053 0.    0.235   nan 0.      nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.167   nan 0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan   nan   nan 0.421 0.55  0.167   nan 0.464 1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.429   nan 0.467 0.214   nan   nan   nan 0.209   nan 0.554 1.      nan\n",
      "  0.455 0.734]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.455   nan]\n",
      " [0.571   nan 1.    0.357 0.26    nan   nan   nan   nan 0.907   nan 0.4\n",
      "  0.691   nan]\n",
      " [0.429   nan   nan 0.286 0.1   0.737   nan   nan   nan 0.25  1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.357   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan 0.667]\n",
      " [0.429   nan 1.    0.857 0.6     nan   nan   nan 0.75  0.571 1.    0.507\n",
      "  0.867   nan]\n",
      " [0.572 1.      nan   nan   nan   nan   nan 0.083 0.6     nan   nan 0.779\n",
      "  0.715 0.18 ]\n",
      " [0.429   nan 0.7     nan   nan   nan   nan   nan 0.25  0.571 1.    0.268\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan 0.25  0.25  0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.05  0.132   nan 0.      nan 0.089 0.2     nan\n",
      "    nan 0.1  ]\n",
      " [  nan   nan   nan 0.085 0.01  0.042 0.2   0.75    nan 0.036   nan   nan\n",
      "    nan 0.253]\n",
      " [0.571   nan   nan 0.228 0.05    nan   nan   nan 0.73  0.564 0.96  0.278\n",
      "  0.709   nan]\n",
      " [0.429   nan 0.733   nan   nan   nan   nan   nan 0.2   0.25  1.    0.25\n",
      "  0.273   nan]\n",
      " [0.071 0.05  0.034 0.036 0.075 0.018   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan 0.95    nan 0.538 0.271 0.    0.167   nan   nan 0.769   nan 0.455\n",
      "    nan   nan]\n",
      " [0.465   nan   nan 0.085   nan 1.      nan 1.      nan 0.036 0.24    nan\n",
      "  0.      nan]\n",
      " [0.386 0.27  0.493 0.071   nan   nan   nan   nan   nan 0.271 1.      nan\n",
      "  0.424   nan]\n",
      " [0.643   nan 1.    0.857 0.5     nan   nan   nan 1.      nan   nan 0.464\n",
      "  0.879   nan]\n",
      " [  nan   nan   nan 0.094   nan 0.045   nan 0.    0.067 0.169 0.2     nan\n",
      "    nan 0.492]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.      nan   nan 0.143   nan 0.252 0.14  0.817   nan 0.393 0.28    nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.467 0.214 0.05  0.      nan   nan   nan 0.536 0.8     nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan 0.25  0.    1.    0.25\n",
      "  0.424   nan]\n",
      " [0.      nan   nan 0.071 0.    0.39  0.46  1.      nan 0.036   nan   nan\n",
      "    nan   nan]\n",
      " [0.657   nan 0.467 0.585 0.31    nan   nan   nan 0.74    nan   nan 0.321\n",
      "  0.637   nan]\n",
      " [0.643 0.25  0.467 0.286 0.1     nan   nan   nan 0.75    nan   nan   nan\n",
      "  0.758   nan]\n",
      " [0.071   nan 0.467 0.119 0.017   nan   nan   nan   nan 0.25  0.3   0.072\n",
      "  0.455   nan]\n",
      " [0.357   nan   nan 0.    0.    0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan 0.667]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan 0.25  0.536 0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan 0.      nan 0.286 0.2     nan   nan   nan 0.188 0.75    nan 0.321\n",
      "  0.333   nan]]\n",
      "current score:  [[  nan 0.363 0.345 0.413 0.205   nan 0.056   nan   nan   nan   nan   nan\n",
      "  0.279   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.171 0.18    nan   nan   nan 0.39    nan   nan   nan 0.278 0.4     nan\n",
      "    nan 0.74 ]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.571 1.    0.\n",
      "  0.424   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan   nan 0.25  0.8   0.\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.095 0.15    nan   nan 0.25    nan   nan\n",
      "    nan 0.287]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.737   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4   0.571 0.3     nan   nan   nan   nan 0.25    nan 0.821\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.286 0.1   0.      nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.767 0.286 0.15  0.      nan   nan   nan   nan   nan 0.357\n",
      "    nan 0.7  ]\n",
      " [  nan   nan   nan 0.107 0.    0.053   nan 0.583   nan 0.143   nan   nan\n",
      "    nan 0.067]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan   nan 0.    0.8   0.214\n",
      "  0.121   nan]\n",
      " [0.386   nan   nan 0.141   nan   nan 0.111   nan   nan 0.385 0.2     nan\n",
      "    nan 0.617]\n",
      " [0.357   nan 0.434   nan   nan   nan   nan   nan   nan 0.25  0.8   0.\n",
      "  0.44    nan]\n",
      " [0.543   nan   nan   nan   nan 0.621   nan 0.05    nan 0.557 1.      nan\n",
      "    nan 0.667]\n",
      " [0.      nan 0.      nan   nan   nan   nan   nan   nan 0.    0.    0.214\n",
      "  0.      nan]\n",
      " [0.393   nan   nan   nan   nan 0.474   nan 0.1     nan 0.493 1.      nan\n",
      "    nan 0.747]\n",
      " [  nan 0.66  0.548 0.575 0.316   nan   nan   nan   nan   nan   nan 0.254\n",
      "  0.335   nan]\n",
      " [0.343   nan 0.613   nan   nan   nan   nan   nan   nan 0.364 0.76  0.179\n",
      "  0.551   nan]\n",
      " [0.197   nan 0.347   nan   nan   nan   nan   nan 0.15    nan   nan 0.197\n",
      "  0.176 0.407]\n",
      " [0.381   nan   nan   nan   nan 0.719   nan 0.195   nan 0.548 1.      nan\n",
      "    nan 0.75 ]\n",
      " [0.357 0.15  0.653 0.071   nan 0.158   nan   nan   nan   nan   nan 0.336\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.083   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [0.714 0.275 1.      nan 0.41    nan   nan   nan 0.53    nan   nan   nan\n",
      "  0.727   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan   nan   nan   nan   nan 0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan 0.167   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.146 0.032 0.053 0.      nan   nan 0.      nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan   nan   nan 0.421   nan 0.167   nan 0.464 1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.429   nan   nan 0.214   nan   nan   nan 0.209   nan 0.554 1.      nan\n",
      "    nan 0.734]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan   nan 0.25  0.8   0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 1.    0.357 0.26    nan   nan   nan   nan 0.907   nan 0.4\n",
      "  0.691   nan]\n",
      " [0.429   nan   nan 0.286 0.1   0.737   nan   nan   nan 0.25  1.      nan\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [  nan   nan 1.    0.857 0.6     nan   nan   nan 0.75    nan   nan 0.507\n",
      "  0.867   nan]\n",
      " [0.572 1.      nan   nan   nan   nan   nan 0.083 0.6     nan   nan   nan\n",
      "  0.745 0.18 ]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.571 1.      nan\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan   nan 0.25  0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.05  0.132   nan 0.      nan 0.089 0.2     nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.085 0.01  0.042   nan 0.75    nan 0.036   nan   nan\n",
      "    nan 0.253]\n",
      " [0.629   nan   nan 0.228 0.05    nan   nan   nan 0.73    nan   nan 0.278\n",
      "  0.709   nan]\n",
      " [0.429   nan 0.733   nan   nan   nan   nan   nan   nan 0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.071 0.05  0.034 0.036   nan 0.018   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan 0.95    nan 0.538 0.271 0.      nan   nan   nan 0.769   nan 0.455\n",
      "    nan   nan]\n",
      " [0.929   nan   nan 0.085   nan 1.      nan 1.      nan 0.036 0.24    nan\n",
      "    nan   nan]\n",
      " [0.386 0.27  0.493   nan   nan   nan   nan   nan   nan 0.271 1.      nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 1.    0.857 0.5     nan   nan   nan 1.      nan   nan 0.464\n",
      "  0.879   nan]\n",
      " [  nan   nan   nan 0.094   nan 0.045   nan 0.    0.067 0.115   nan   nan\n",
      "    nan 0.492]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan   nan 0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan   nan 0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.      nan   nan   nan   nan 0.252 0.14  0.817   nan 0.393 0.28    nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.467   nan   nan 0.      nan   nan   nan 0.536 0.8     nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.    1.    0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.071 0.    0.39  0.46  1.      nan 0.036   nan   nan\n",
      "    nan   nan]\n",
      " [0.657   nan   nan 0.585 0.31    nan   nan   nan 0.74    nan   nan 0.321\n",
      "  0.576   nan]\n",
      " [0.643   nan 0.467 0.286 0.1     nan   nan   nan 0.75    nan   nan   nan\n",
      "  0.758   nan]\n",
      " [0.071   nan   nan 0.119 0.017   nan   nan   nan   nan 0.25  0.3   0.072\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.    0.    0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan   nan 0.536 0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan 0.      nan 0.286 0.2     nan   nan   nan 0.188 0.75    nan 0.321\n",
      "    nan   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Number of predicted domains: 83\n",
      "Average improvement: 0.3469518072289156\n",
      "Standard deviation: 0.27077147702644816\n",
      "prediction score:  [[  nan 0.363 0.345 0.413 0.205   nan 0.056   nan   nan 0.185   nan   nan\n",
      "  0.279   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.171 0.18  0.413   nan   nan 0.39    nan   nan   nan 0.278 0.4     nan\n",
      "  0.273 0.74 ]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan 0.25  0.571 1.    0.\n",
      "  0.424   nan]\n",
      " [0.357   nan 0.4     nan   nan 0.737   nan   nan   nan 0.25  0.8   0.\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.267 0.143 0.    0.095 0.15    nan   nan 0.25    nan   nan\n",
      "  0.121 0.287]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan   nan   nan 0.286   nan 0.25\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.733 0.286 0.1   0.737   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.4   0.571 0.3     nan   nan   nan   nan 0.25  0.8   0.821\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.286 0.1   0.      nan   nan   nan 0.25    nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.767 0.286 0.15  0.316 0.5     nan   nan   nan   nan 0.357\n",
      "    nan 0.7  ]\n",
      " [  nan 0.05    nan 0.107 0.    0.053   nan 0.583   nan 0.143   nan   nan\n",
      "    nan 0.067]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan 0.25  0.    0.8   0.214\n",
      "  0.303   nan]\n",
      " [0.386   nan   nan 0.141   nan   nan 0.111   nan   nan 0.385 0.2     nan\n",
      "  0.595 0.617]\n",
      " [0.357   nan 0.434   nan   nan   nan   nan   nan 0.25  0.25  0.8   0.\n",
      "  0.44    nan]\n",
      " [0.557   nan   nan   nan   nan 0.621   nan 0.05    nan 0.557 1.      nan\n",
      "  0.727 0.667]\n",
      " [0.      nan 0.    0.    0.      nan   nan   nan   nan 0.    0.    0.214\n",
      "  0.      nan]\n",
      " [0.393   nan   nan   nan   nan 0.474   nan 0.1     nan 0.493 1.      nan\n",
      "  0.333 0.747]\n",
      " [  nan 0.66  0.548 0.575 0.316   nan   nan   nan   nan 0.154   nan 0.254\n",
      "  0.335   nan]\n",
      " [0.343   nan 0.613   nan   nan 0.59  0.46    nan   nan 0.364 0.76  0.179\n",
      "  0.551   nan]\n",
      " [0.197   nan 0.347   nan   nan 0.671 0.283   nan 0.15    nan   nan 0.197\n",
      "  0.176 0.407]\n",
      " [0.381   nan   nan 0.071   nan 0.719   nan 0.195   nan 0.548 1.      nan\n",
      "    nan 0.75 ]\n",
      " [0.357 0.15  0.653 0.071 0.13  0.158   nan   nan   nan   nan   nan 0.336\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.083   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [0.714 0.275 1.    0.414 0.41    nan   nan   nan 0.53    nan   nan   nan\n",
      "  0.727   nan]\n",
      " [0.429   nan 0.4   0.214 0.05  0.684   nan   nan   nan 0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan 0.167   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.146 0.032 0.053 0.    0.235   nan 0.      nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.167   nan 0.286   nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan   nan   nan 0.421 0.55  0.167   nan 0.464 1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.429   nan 0.467 0.214   nan   nan   nan 0.209   nan 0.554 1.      nan\n",
      "  0.455 0.734]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.455   nan]\n",
      " [0.571   nan 1.    0.357 0.26    nan   nan   nan   nan 0.907   nan 0.4\n",
      "  0.691   nan]\n",
      " [0.429   nan   nan 0.286 0.1   0.737   nan   nan   nan 0.25  1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.357   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan 0.667]\n",
      " [0.429   nan 1.    0.857 0.6     nan   nan   nan 0.75  0.571 1.    0.507\n",
      "  0.867   nan]\n",
      " [0.572 1.      nan   nan   nan   nan   nan 0.083 0.6     nan   nan 0.779\n",
      "  0.715 0.18 ]\n",
      " [0.429   nan 0.7     nan   nan   nan   nan   nan 0.25  0.571 1.    0.268\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan 0.25  0.25  0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.05  0.132   nan 0.      nan 0.089 0.2     nan\n",
      "    nan 0.1  ]\n",
      " [  nan   nan   nan 0.085 0.01  0.042 0.2   0.75    nan 0.036   nan   nan\n",
      "    nan 0.253]\n",
      " [0.571   nan   nan 0.228 0.05    nan   nan   nan 0.73  0.564 0.96  0.278\n",
      "  0.709   nan]\n",
      " [0.429   nan 0.733   nan   nan   nan   nan   nan 0.2   0.25  1.    0.25\n",
      "  0.273   nan]\n",
      " [0.071 0.05  0.034 0.036 0.075 0.018   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan 0.95    nan 0.538 0.271 0.    0.167   nan   nan 0.769   nan 0.455\n",
      "    nan   nan]\n",
      " [0.465   nan   nan 0.085   nan 1.      nan 1.      nan 0.036 0.24    nan\n",
      "  0.      nan]\n",
      " [0.386 0.27  0.493 0.071   nan   nan   nan   nan   nan 0.271 1.      nan\n",
      "  0.424   nan]\n",
      " [0.643   nan 1.    0.857 0.5     nan   nan   nan 1.      nan   nan 0.464\n",
      "  0.879   nan]\n",
      " [  nan   nan   nan 0.094   nan 0.045   nan 0.    0.067 0.169 0.2     nan\n",
      "    nan 0.492]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.      nan   nan 0.143   nan 0.252 0.14  0.817   nan 0.393 0.28    nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.467 0.214 0.05  0.      nan   nan   nan 0.536 0.8     nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan 0.25  0.    1.    0.25\n",
      "  0.424   nan]\n",
      " [0.      nan   nan 0.071 0.    0.39  0.46  1.      nan 0.036   nan   nan\n",
      "    nan   nan]\n",
      " [0.657   nan 0.467 0.585 0.31    nan   nan   nan 0.74    nan   nan 0.321\n",
      "  0.637   nan]\n",
      " [0.643 0.25  0.467 0.286 0.1     nan   nan   nan 0.75    nan   nan   nan\n",
      "  0.758   nan]\n",
      " [0.071   nan 0.467 0.119 0.017   nan   nan   nan   nan 0.25  0.3   0.072\n",
      "  0.455   nan]\n",
      " [0.357   nan   nan 0.    0.    0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan 0.667]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan 0.25  0.536 0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan 0.      nan 0.286 0.2     nan   nan   nan 0.188 0.75    nan 0.321\n",
      "  0.333   nan]]\n",
      "current score:  [[  nan 0.363 0.345 0.413 0.205   nan 0.056   nan   nan   nan   nan   nan\n",
      "  0.279   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.571 1.    0.214\n",
      "  0.424   nan]\n",
      " [0.171 0.18    nan   nan   nan 0.39    nan   nan   nan 0.278 0.4     nan\n",
      "    nan 0.74 ]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.571 1.    0.\n",
      "  0.424   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan   nan 0.25  0.8   0.\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.095 0.15    nan   nan 0.25    nan   nan\n",
      "    nan 0.287]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.737   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4   0.571 0.3     nan   nan   nan   nan 0.25    nan 0.821\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.286 0.1   0.      nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.767 0.286 0.15  0.      nan   nan   nan   nan   nan 0.357\n",
      "    nan 0.7  ]\n",
      " [  nan   nan   nan 0.107 0.    0.053   nan 0.583   nan 0.143   nan   nan\n",
      "    nan 0.067]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan   nan 0.    0.8   0.214\n",
      "  0.121   nan]\n",
      " [0.386   nan   nan 0.141   nan   nan 0.111   nan   nan 0.385 0.2     nan\n",
      "    nan 0.617]\n",
      " [0.357   nan 0.434   nan   nan   nan   nan   nan   nan 0.25  0.8   0.\n",
      "  0.44    nan]\n",
      " [0.543   nan   nan   nan   nan 0.621   nan 0.05    nan 0.557 1.      nan\n",
      "    nan 0.667]\n",
      " [0.      nan 0.      nan   nan   nan   nan   nan   nan 0.    0.    0.214\n",
      "  0.      nan]\n",
      " [0.393   nan   nan   nan   nan 0.474   nan 0.1     nan 0.493 1.      nan\n",
      "    nan 0.747]\n",
      " [  nan 0.66  0.548 0.575 0.316   nan   nan   nan   nan   nan   nan 0.254\n",
      "  0.335   nan]\n",
      " [0.343   nan 0.613   nan   nan   nan   nan   nan   nan 0.364 0.76  0.179\n",
      "  0.551   nan]\n",
      " [0.197   nan 0.347   nan   nan   nan   nan   nan 0.15    nan   nan 0.197\n",
      "  0.176 0.407]\n",
      " [0.381   nan   nan   nan   nan 0.719   nan 0.195   nan 0.548 1.      nan\n",
      "    nan 0.75 ]\n",
      " [0.357 0.15  0.653 0.071   nan 0.158   nan   nan   nan   nan   nan 0.336\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan 0.083   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [0.714 0.275 1.      nan 0.41    nan   nan   nan 0.53    nan   nan   nan\n",
      "  0.727   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.684   nan   nan   nan   nan   nan 0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan 0.167   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.146 0.032 0.053 0.      nan   nan 0.      nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.467 0.214 0.05  0.      nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan   nan   nan 0.421   nan 0.167   nan 0.464 1.      nan\n",
      "    nan 0.7  ]\n",
      " [0.429   nan   nan 0.214   nan   nan   nan 0.209   nan 0.554 1.      nan\n",
      "    nan 0.734]\n",
      " [0.357   nan 0.667   nan   nan   nan   nan   nan   nan 0.25  0.8   0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 1.    0.357 0.26    nan   nan   nan   nan 0.907   nan 0.4\n",
      "  0.691   nan]\n",
      " [0.429   nan   nan 0.286 0.1   0.737   nan   nan   nan 0.25  1.      nan\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [  nan   nan 1.    0.857 0.6     nan   nan   nan 0.75    nan   nan 0.507\n",
      "  0.867   nan]\n",
      " [0.572 1.      nan   nan   nan   nan   nan 0.083 0.6     nan   nan   nan\n",
      "  0.745 0.18 ]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan 0.25  0.571 1.      nan\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan   nan 0.25  0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.05  0.132   nan 0.      nan 0.089 0.2     nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.085 0.01  0.042   nan 0.75    nan 0.036   nan   nan\n",
      "    nan 0.253]\n",
      " [0.629   nan   nan 0.228 0.05    nan   nan   nan 0.73    nan   nan 0.278\n",
      "  0.709   nan]\n",
      " [0.429   nan 0.733   nan   nan   nan   nan   nan   nan 0.25  1.    0.25\n",
      "  0.455   nan]\n",
      " [0.071 0.05  0.034 0.036   nan 0.018   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan 0.95    nan 0.538 0.271 0.      nan   nan   nan 0.769   nan 0.455\n",
      "    nan   nan]\n",
      " [0.929   nan   nan 0.085   nan 1.      nan 1.      nan 0.036 0.24    nan\n",
      "    nan   nan]\n",
      " [0.386 0.27  0.493   nan   nan   nan   nan   nan   nan 0.271 1.      nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 1.    0.857 0.5     nan   nan   nan 1.      nan   nan 0.464\n",
      "  0.879   nan]\n",
      " [  nan   nan   nan 0.094   nan 0.045   nan 0.    0.067 0.115   nan   nan\n",
      "    nan 0.492]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan   nan 0.25  1.    0.214\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.667   nan   nan   nan   nan   nan   nan 0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.      nan   nan   nan   nan 0.252 0.14  0.817   nan 0.393 0.28    nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.467   nan   nan 0.      nan   nan   nan 0.536 0.8     nan\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.    1.    0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.071 0.    0.39  0.46  1.      nan 0.036   nan   nan\n",
      "    nan   nan]\n",
      " [0.657   nan   nan 0.585 0.31    nan   nan   nan 0.74    nan   nan 0.321\n",
      "  0.576   nan]\n",
      " [0.643   nan 0.467 0.286 0.1     nan   nan   nan 0.75    nan   nan   nan\n",
      "  0.758   nan]\n",
      " [0.071   nan   nan 0.119 0.017   nan   nan   nan   nan 0.25  0.3   0.072\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.    0.    0.737   nan   nan   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.733   nan   nan   nan   nan   nan   nan 0.536 0.8   0.25\n",
      "  0.455   nan]\n",
      " [  nan 0.      nan 0.286 0.2     nan   nan   nan 0.188 0.75    nan 0.321\n",
      "    nan   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Number of predicted domains: 83\n",
      "Average improvement: 0.3469518072289156\n",
      "Standard deviation: 0.27077147702644816\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 3.6894456e-03 -2.7345866e-04  6.0432881e-01 ...  1.0856777e-02\n",
      "  -2.8559100e-03 -2.1381840e-02]\n",
      " [ 1.2706354e-02  2.1265894e-03 -1.1059623e-02 ...  3.9550066e-03\n",
      "   4.6513705e-03 -9.1566229e-03]\n",
      " [ 1.4194325e-02 -2.5516227e-03 -1.0147018e-02 ... -1.1478364e-03\n",
      "  -1.0101402e-02  9.3449019e-03]\n",
      " ...\n",
      " [-6.3371658e-04 -3.0510053e-03  2.8517935e-01 ... -1.4260411e-03\n",
      "  -1.7764311e-02  2.7785841e-03]\n",
      " [-7.2533712e-03  5.0857514e-03  1.5213046e-02 ...  3.4819728e-01\n",
      "   6.9186240e-03 -5.8038514e-03]\n",
      " [ 2.6353821e-03  3.6121905e-04  5.7204608e-03 ...  6.1923489e-03\n",
      "   6.8775350e-03 -1.5264989e-02]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.074]\n",
      " [1.    1.      nan ... 0.685 1.      nan]\n",
      " [0.571   nan 0.773 ... 0.278 0.4     nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.711]\n",
      " [0.357   nan   nan ...   nan   nan 0.087]\n",
      " [  nan   nan   nan ...   nan   nan 0.067]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 1424\n",
      "Average improvement: 0.4732576155449065\n",
      "Standard deviation: 0.10759432452317685\n",
      "prediction score:  [[ 3.6894456e-03 -2.7345866e-04  6.0432881e-01 ...  1.0856777e-02\n",
      "  -2.8559100e-03 -2.1381840e-02]\n",
      " [ 1.2706354e-02  2.1265894e-03 -1.1059623e-02 ...  3.9550066e-03\n",
      "   4.6513705e-03 -9.1566229e-03]\n",
      " [ 1.4194325e-02 -2.5516227e-03 -1.0147018e-02 ... -1.1478364e-03\n",
      "  -1.0101402e-02  9.3449019e-03]\n",
      " ...\n",
      " [-6.3371658e-04 -3.0510053e-03  2.8517935e-01 ... -1.4260411e-03\n",
      "  -1.7764311e-02  2.7785841e-03]\n",
      " [-7.2533712e-03  5.0857514e-03  1.5213046e-02 ...  3.4819728e-01\n",
      "   6.9186240e-03 -5.8038514e-03]\n",
      " [ 2.6353821e-03  3.6121905e-04  5.7204608e-03 ...  6.1923489e-03\n",
      "   6.8775350e-03 -1.5264989e-02]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.074]\n",
      " [1.    1.      nan ... 0.685 1.      nan]\n",
      " [0.571   nan 0.773 ... 0.278 0.4     nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.711]\n",
      " [0.357   nan   nan ...   nan   nan 0.087]\n",
      " [  nan   nan   nan ...   nan   nan 0.067]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 1424\n",
      "Average improvement: 0.4732576155449065\n",
      "Standard deviation: 0.10759432452317685\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.60432881 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.60495204 ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.074]\n",
      " [1.    1.      nan ... 0.685 1.      nan]\n",
      " [0.571   nan 0.773 ... 0.278 0.4     nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.711]\n",
      " [0.357   nan   nan ...   nan   nan 0.087]\n",
      " [  nan   nan   nan ...   nan   nan 0.067]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "Number of predicted domains: 1424\n",
      "Average improvement: 0.625639316971215\n",
      "Standard deviation: 0.11434851954746134\n",
      "prediction score:  [[0.         0.         0.60432881 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.60495204 ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.074]\n",
      " [1.    1.      nan ... 0.685 1.      nan]\n",
      " [0.571   nan 0.773 ... 0.278 0.4     nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.711]\n",
      " [0.357   nan   nan ...   nan   nan 0.087]\n",
      " [  nan   nan   nan ...   nan   nan 0.067]]\n",
      "encoding:  [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "Number of predicted domains: 1424\n",
      "Average improvement: 0.625639316971215\n",
      "Standard deviation: 0.11434851954746134\n",
      "========= 9 missing\n",
      "----ground truth----\n",
      "prediction score:  [[  nan   nan 0.667 0.214 0.05  0.684   nan   nan   nan 0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [0.357   nan 0.355 0.214 0.05    nan   nan   nan   nan 0.536 0.8   0.125\n",
      "  0.409   nan]\n",
      " [  nan   nan 0.4   0.214 0.05    nan   nan   nan 0.7     nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.133 0.143 0.    0.053   nan 0.      nan   nan   nan   nan\n",
      "  0.03    nan]\n",
      " [0.357   nan 0.454 0.157 0.01    nan   nan   nan   nan 0.25  0.8     nan\n",
      "  0.382   nan]\n",
      " [0.129   nan 0.173 0.143   nan   nan   nan   nan   nan 0.729   nan   nan\n",
      "  0.703 0.267]\n",
      " [  nan   nan 0.4   0.5   0.25  0.053   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.225 0.065 0.067 0.1   0.424   nan 0.085   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.053   nan   nan   nan 0.114 0.      nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan 0.1   0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.6   0.733 0.214 0.05  0.737   nan   nan   nan   nan   nan 0.25\n",
      "    nan 0.7  ]\n",
      " [  nan   nan 0.889 0.465 0.25    nan   nan   nan 0.75    nan   nan 0.262\n",
      "  0.657   nan]\n",
      " [0.3   0.37    nan   nan 0.34  0.347 0.23    nan 0.013   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.424   nan]\n",
      " [  nan 0.575 0.755 0.214 0.05    nan   nan   nan   nan   nan   nan 0.297\n",
      "  0.545   nan]\n",
      " [  nan   nan 0.8   0.286 0.4     nan   nan   nan 0.7     nan   nan 0.429\n",
      "  0.667   nan]\n",
      " [0.429   nan 0.567 0.286 0.083   nan   nan   nan   nan 0.571 1.    0.232\n",
      "  0.061   nan]\n",
      " [  nan   nan 0.667 0.214 0.05  0.      nan   nan   nan 0.      nan 0.214\n",
      "    nan 0.667]\n",
      " [0.429   nan 0.733 0.286 0.1     nan   nan   nan   nan 0.571 1.    0.357\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733 0.286 0.2     nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.515   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan   nan   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [1.      nan   nan 0.386 0.17    nan   nan   nan 0.79    nan   nan 0.414\n",
      "  0.739   nan]\n",
      " [  nan   nan   nan 0.095 0.033 0.211   nan 0.      nan 0.012   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan 0.093 0.188   nan 0.267   nan   nan   nan 0.077   nan 0.167\n",
      "  0.041   nan]\n",
      " [0.371   nan   nan 0.143 0.    0.537 0.51    nan   nan 0.557 0.84    nan\n",
      "    nan   nan]\n",
      " [0.757   nan   nan 0.714 0.5   0.884   nan 0.717   nan   nan   nan 0.462\n",
      "  0.8     nan]\n",
      " [0.357   nan   nan 0.    0.    0.737   nan 0.083   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.438 0.194 0.      nan 0.059   nan 0.      nan   nan\n",
      "    nan 0.633]\n",
      " [  nan 0.18    nan   nan   nan 0.547   nan 0.766 0.22  0.429   nan   nan\n",
      "  0.291   nan]\n",
      " [  nan 0.55  0.778 0.5   0.15    nan   nan   nan   nan   nan   nan 0.268\n",
      "  0.576   nan]\n",
      " [0.371   nan 0.333   nan   nan   nan   nan   nan   nan 0.629 0.84  0.\n",
      "  0.285   nan]\n",
      " [0.357   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.    0.8   0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 1.      nan   nan 0.211 0.2   0.05    nan   nan   nan   nan\n",
      "  0.222 0.234]\n",
      " [  nan   nan 0.933 0.429 0.15    nan   nan   nan 0.7     nan   nan 0.357\n",
      "  0.667   nan]\n",
      " [0.29    nan 0.      nan   nan   nan   nan   nan   nan 0.25  0.4     nan\n",
      "  0.    0.633]\n",
      " [0.357   nan 0.4   0.214 0.05    nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.143 0.    0.684   nan   nan   nan 0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.      nan 0.      nan   nan   nan 0.429 0.2     nan\n",
      "  0.424 0.533]\n",
      " [  nan   nan 0.    0.214 0.05    nan   nan   nan   nan 0.286   nan 0.214\n",
      "  0.      nan]\n",
      " [0.571   nan 0.444 0.381 0.217   nan   nan   nan   nan 0.774   nan   nan\n",
      "  0.485   nan]\n",
      " [  nan   nan 0.907 0.372 0.24  0.105   nan   nan   nan 0.321   nan 0.3\n",
      "  0.515   nan]\n",
      " [  nan   nan 0.067 0.085   nan 0.053 0.05    nan   nan 0.      nan   nan\n",
      "  0.024   nan]\n",
      " [0.357   nan 0.667 0.286 0.1     nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.667 0.214 0.05  0.684   nan   nan   nan 0.536 0.8   0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.737   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]]\n",
      "current score:  [[  nan   nan 0.667 0.214 0.05  0.684   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.355 0.214 0.05    nan   nan   nan   nan   nan   nan 0.125\n",
      "  0.409   nan]\n",
      " [  nan   nan 0.4   0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.133 0.143 0.      nan   nan 0.      nan   nan   nan   nan\n",
      "  0.03    nan]\n",
      " [0.357   nan 0.454   nan   nan   nan   nan   nan   nan 0.25  0.8     nan\n",
      "  0.382   nan]\n",
      " [0.129   nan   nan 0.143   nan   nan   nan   nan   nan 0.729   nan   nan\n",
      "  0.612 0.267]\n",
      " [  nan   nan 0.4   0.5   0.25  0.053   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.213   nan 0.067 0.1   0.424   nan 0.085   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.053   nan   nan   nan 0.114   nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan   nan 0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.6   0.733   nan   nan 0.737   nan   nan   nan   nan   nan 0.25\n",
      "    nan 0.7  ]\n",
      " [  nan   nan 0.889 0.429   nan   nan   nan   nan 0.75    nan   nan 0.262\n",
      "  0.657   nan]\n",
      " [0.3   0.37    nan   nan 0.34  0.347 0.23    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan   nan 0.25  0.8   0.214\n",
      "    nan   nan]\n",
      " [  nan 0.575 0.755 0.214 0.05    nan   nan   nan   nan   nan   nan 0.297\n",
      "    nan   nan]\n",
      " [  nan   nan 0.8   0.286 0.4     nan   nan   nan   nan   nan   nan 0.429\n",
      "  0.667   nan]\n",
      " [  nan   nan 0.567 0.286 0.083   nan   nan   nan   nan   nan   nan 0.232\n",
      "  0.061   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.      nan   nan   nan 0.      nan 0.214\n",
      "    nan 0.667]\n",
      " [  nan   nan 0.733 0.286 0.1     nan   nan   nan   nan 0.286   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.286 0.2     nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.515   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [1.      nan   nan 0.386 0.17    nan   nan   nan 0.79    nan   nan 0.414\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.095 0.033   nan   nan 0.      nan 0.012   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan 0.093 0.188   nan   nan   nan   nan   nan 0.077   nan 0.167\n",
      "  0.041   nan]\n",
      " [0.371   nan   nan 0.143 0.      nan   nan   nan   nan 0.557 0.84    nan\n",
      "    nan   nan]\n",
      " [0.757   nan   nan 0.714 0.5     nan   nan   nan   nan   nan   nan 0.462\n",
      "  0.8     nan]\n",
      " [0.357   nan   nan   nan   nan 0.737   nan 0.083   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.438 0.194 0.      nan 0.059   nan 0.      nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.18    nan   nan   nan 0.547   nan 0.766 0.22    nan   nan   nan\n",
      "  0.291   nan]\n",
      " [  nan 0.55  0.734 0.5   0.15    nan   nan   nan   nan   nan   nan 0.268\n",
      "    nan   nan]\n",
      " [0.371   nan 0.333   nan   nan   nan   nan   nan   nan 0.629 0.84    nan\n",
      "  0.285   nan]\n",
      " [  nan   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.      nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 1.      nan   nan 0.211 0.2   0.05    nan   nan   nan   nan\n",
      "  0.222   nan]\n",
      " [  nan   nan 0.933 0.429 0.15    nan   nan   nan   nan   nan   nan 0.357\n",
      "  0.667   nan]\n",
      " [0.29    nan 0.      nan   nan   nan   nan   nan   nan 0.25  0.4     nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.4   0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.143 0.    0.684   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.429 0.2     nan\n",
      "  0.424 0.533]\n",
      " [  nan   nan 0.    0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.444 0.381 0.217   nan   nan   nan   nan 0.774   nan   nan\n",
      "  0.485   nan]\n",
      " [  nan   nan 0.907 0.372 0.24    nan   nan   nan   nan   nan   nan 0.3\n",
      "  0.515   nan]\n",
      " [  nan   nan   nan 0.085   nan 0.053 0.05    nan   nan 0.      nan   nan\n",
      "  0.03    nan]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.667 0.214 0.05  0.684   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Number of predicted domains: 69\n",
      "Average improvement: 0.402840579710145\n",
      "Standard deviation: 0.27527006114789326\n",
      "prediction score:  [[  nan   nan 0.667 0.214 0.05  0.684   nan   nan   nan 0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [0.357   nan 0.355 0.214 0.05    nan   nan   nan   nan 0.536 0.8   0.125\n",
      "  0.409   nan]\n",
      " [  nan   nan 0.4   0.214 0.05    nan   nan   nan 0.7     nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.133 0.143 0.    0.053   nan 0.      nan   nan   nan   nan\n",
      "  0.03    nan]\n",
      " [0.357   nan 0.454 0.157 0.01    nan   nan   nan   nan 0.25  0.8     nan\n",
      "  0.382   nan]\n",
      " [0.129   nan 0.173 0.143   nan   nan   nan   nan   nan 0.729   nan   nan\n",
      "  0.703 0.267]\n",
      " [  nan   nan 0.4   0.5   0.25  0.053   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.225 0.065 0.067 0.1   0.424   nan 0.085   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.053   nan   nan   nan 0.114 0.      nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan 0.1   0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.6   0.733 0.214 0.05  0.737   nan   nan   nan   nan   nan 0.25\n",
      "    nan 0.7  ]\n",
      " [  nan   nan 0.889 0.465 0.25    nan   nan   nan 0.75    nan   nan 0.262\n",
      "  0.657   nan]\n",
      " [0.3   0.37    nan   nan 0.34  0.347 0.23    nan 0.013   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan 0.25  0.25  0.8   0.214\n",
      "  0.424   nan]\n",
      " [  nan 0.575 0.755 0.214 0.05    nan   nan   nan   nan   nan   nan 0.297\n",
      "  0.545   nan]\n",
      " [  nan   nan 0.8   0.286 0.4     nan   nan   nan 0.7     nan   nan 0.429\n",
      "  0.667   nan]\n",
      " [0.429   nan 0.567 0.286 0.083   nan   nan   nan   nan 0.571 1.    0.232\n",
      "  0.061   nan]\n",
      " [  nan   nan 0.667 0.214 0.05  0.      nan   nan   nan 0.      nan 0.214\n",
      "    nan 0.667]\n",
      " [0.429   nan 0.733 0.286 0.1     nan   nan   nan   nan 0.571 1.    0.357\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733 0.286 0.2     nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.515   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan   nan   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [1.      nan   nan 0.386 0.17    nan   nan   nan 0.79    nan   nan 0.414\n",
      "  0.739   nan]\n",
      " [  nan   nan   nan 0.095 0.033 0.211   nan 0.      nan 0.012   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan 0.093 0.188   nan 0.267   nan   nan   nan 0.077   nan 0.167\n",
      "  0.041   nan]\n",
      " [0.371   nan   nan 0.143 0.    0.537 0.51    nan   nan 0.557 0.84    nan\n",
      "    nan   nan]\n",
      " [0.757   nan   nan 0.714 0.5   0.884   nan 0.717   nan   nan   nan 0.462\n",
      "  0.8     nan]\n",
      " [0.357   nan   nan 0.    0.    0.737   nan 0.083   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.438 0.194 0.      nan 0.059   nan 0.      nan   nan\n",
      "    nan 0.633]\n",
      " [  nan 0.18    nan   nan   nan 0.547   nan 0.766 0.22  0.429   nan   nan\n",
      "  0.291   nan]\n",
      " [  nan 0.55  0.778 0.5   0.15    nan   nan   nan   nan   nan   nan 0.268\n",
      "  0.576   nan]\n",
      " [0.371   nan 0.333   nan   nan   nan   nan   nan   nan 0.629 0.84  0.\n",
      "  0.285   nan]\n",
      " [0.357   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.    0.8   0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 1.      nan   nan 0.211 0.2   0.05    nan   nan   nan   nan\n",
      "  0.222 0.234]\n",
      " [  nan   nan 0.933 0.429 0.15    nan   nan   nan 0.7     nan   nan 0.357\n",
      "  0.667   nan]\n",
      " [0.29    nan 0.      nan   nan   nan   nan   nan   nan 0.25  0.4     nan\n",
      "  0.    0.633]\n",
      " [0.357   nan 0.4   0.214 0.05    nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.143 0.    0.684   nan   nan   nan 0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.      nan 0.      nan   nan   nan 0.429 0.2     nan\n",
      "  0.424 0.533]\n",
      " [  nan   nan 0.    0.214 0.05    nan   nan   nan   nan 0.286   nan 0.214\n",
      "  0.      nan]\n",
      " [0.571   nan 0.444 0.381 0.217   nan   nan   nan   nan 0.774   nan   nan\n",
      "  0.485   nan]\n",
      " [  nan   nan 0.907 0.372 0.24  0.105   nan   nan   nan 0.321   nan 0.3\n",
      "  0.515   nan]\n",
      " [  nan   nan 0.067 0.085   nan 0.053 0.05    nan   nan 0.      nan   nan\n",
      "  0.024   nan]\n",
      " [0.357   nan 0.667 0.286 0.1     nan   nan   nan   nan 0.536 0.8   0.214\n",
      "  0.455   nan]\n",
      " [0.357   nan 0.667 0.214 0.05  0.684   nan   nan   nan 0.536 0.8   0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.286 0.1   0.737   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]]\n",
      "current score:  [[  nan   nan 0.667 0.214 0.05  0.684   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.355 0.214 0.05    nan   nan   nan   nan   nan   nan 0.125\n",
      "  0.409   nan]\n",
      " [  nan   nan 0.4   0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.133 0.143 0.      nan   nan 0.      nan   nan   nan   nan\n",
      "  0.03    nan]\n",
      " [0.357   nan 0.454   nan   nan   nan   nan   nan   nan 0.25  0.8     nan\n",
      "  0.382   nan]\n",
      " [0.129   nan   nan 0.143   nan   nan   nan   nan   nan 0.729   nan   nan\n",
      "  0.612 0.267]\n",
      " [  nan   nan 0.4   0.5   0.25  0.053   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.213   nan 0.067 0.1   0.424   nan 0.085   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.053   nan   nan   nan 0.114   nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan   nan 0.286   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.6   0.733   nan   nan 0.737   nan   nan   nan   nan   nan 0.25\n",
      "    nan 0.7  ]\n",
      " [  nan   nan 0.889 0.429   nan   nan   nan   nan 0.75    nan   nan 0.262\n",
      "  0.657   nan]\n",
      " [0.3   0.37    nan   nan 0.34  0.347 0.23    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan   nan 0.25  0.8   0.214\n",
      "    nan   nan]\n",
      " [  nan 0.575 0.755 0.214 0.05    nan   nan   nan   nan   nan   nan 0.297\n",
      "    nan   nan]\n",
      " [  nan   nan 0.8   0.286 0.4     nan   nan   nan   nan   nan   nan 0.429\n",
      "  0.667   nan]\n",
      " [  nan   nan 0.567 0.286 0.083   nan   nan   nan   nan   nan   nan 0.232\n",
      "  0.061   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.      nan   nan   nan 0.      nan 0.214\n",
      "    nan 0.667]\n",
      " [  nan   nan 0.733 0.286 0.1     nan   nan   nan   nan 0.286   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.286 0.2     nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.515   nan]\n",
      " [  nan   nan 0.4   0.214 0.05  0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [1.      nan   nan 0.386 0.17    nan   nan   nan 0.79    nan   nan 0.414\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.095 0.033   nan   nan 0.      nan 0.012   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan 0.093 0.188   nan   nan   nan   nan   nan 0.077   nan 0.167\n",
      "  0.041   nan]\n",
      " [0.371   nan   nan 0.143 0.      nan   nan   nan   nan 0.557 0.84    nan\n",
      "    nan   nan]\n",
      " [0.757   nan   nan 0.714 0.5     nan   nan   nan   nan   nan   nan 0.462\n",
      "  0.8     nan]\n",
      " [0.357   nan   nan   nan   nan 0.737   nan 0.083   nan 0.25  0.8     nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.438 0.194 0.      nan 0.059   nan 0.      nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.18    nan   nan   nan 0.547   nan 0.766 0.22    nan   nan   nan\n",
      "  0.291   nan]\n",
      " [  nan 0.55  0.734 0.5   0.15    nan   nan   nan   nan   nan   nan 0.268\n",
      "    nan   nan]\n",
      " [0.371   nan 0.333   nan   nan   nan   nan   nan   nan 0.629 0.84    nan\n",
      "  0.285   nan]\n",
      " [  nan   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.      nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 1.      nan   nan 0.211 0.2   0.05    nan   nan   nan   nan\n",
      "  0.222   nan]\n",
      " [  nan   nan 0.933 0.429 0.15    nan   nan   nan   nan   nan   nan 0.357\n",
      "  0.667   nan]\n",
      " [0.29    nan 0.      nan   nan   nan   nan   nan   nan 0.25  0.4     nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.4   0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.667 0.143 0.    0.684   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.429 0.2     nan\n",
      "  0.424 0.533]\n",
      " [  nan   nan 0.    0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 0.444 0.381 0.217   nan   nan   nan   nan 0.774   nan   nan\n",
      "  0.485   nan]\n",
      " [  nan   nan 0.907 0.372 0.24    nan   nan   nan   nan   nan   nan 0.3\n",
      "  0.515   nan]\n",
      " [  nan   nan   nan 0.085   nan 0.053 0.05    nan   nan 0.      nan   nan\n",
      "  0.03    nan]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.667 0.214 0.05  0.684   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]]\n",
      "encoding:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Number of predicted domains: 69\n",
      "Average improvement: 0.402840579710145\n",
      "Standard deviation: 0.27527006114789326\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 1.48097426e-02  1.09345689e-02  6.35088887e-03 ... -8.21308047e-03\n",
      "   6.80043735e-03  5.18661141e-01]\n",
      " [-1.86218545e-02 -8.48621130e-05 -4.92172316e-04 ... -7.33949989e-03\n",
      "  -3.73254856e-03 -9.92376357e-03]\n",
      " [ 3.29955667e-03  3.57945263e-03 -4.88845631e-03 ...  8.99563730e-03\n",
      "   3.23180169e-01  5.62873017e-03]\n",
      " ...\n",
      " [ 8.63447785e-03  1.46943703e-02 -5.56530431e-03 ... -1.24124438e-03\n",
      "  -6.98959036e-03  9.17155296e-04]\n",
      " [-5.49912453e-03 -1.02118552e-02 -1.12590995e-02 ...  4.41578850e-02\n",
      "  -3.71305272e-03  1.94970742e-02]\n",
      " [ 7.80924410e-03  4.96549070e-01 -5.07304817e-03 ...  6.47070259e-03\n",
      "   7.73030985e-03 -3.63646029e-03]]\n",
      "current score:  [[  nan   nan   nan ... 0.739 0.939   nan]\n",
      " [  nan 0.64  0.787 ... 0.414 0.879   nan]\n",
      " [0.107   nan   nan ...   nan   nan 0.522]\n",
      " ...\n",
      " [  nan   nan 1.    ... 0.322 0.642   nan]\n",
      " [  nan   nan   nan ... 0.751 0.939   nan]\n",
      " [  nan   nan 0.667 ... 0.214   nan   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "Number of predicted domains: 728\n",
      "Average improvement: 0.4791253221804624\n",
      "Standard deviation: 0.11593425318658507\n",
      "prediction score:  [[ 1.48097426e-02  1.09345689e-02  6.35088887e-03 ... -8.21308047e-03\n",
      "   6.80043735e-03  5.18661141e-01]\n",
      " [-1.86218545e-02 -8.48621130e-05 -4.92172316e-04 ... -7.33949989e-03\n",
      "  -3.73254856e-03 -9.92376357e-03]\n",
      " [ 3.29955667e-03  3.57945263e-03 -4.88845631e-03 ...  8.99563730e-03\n",
      "   3.23180169e-01  5.62873017e-03]\n",
      " ...\n",
      " [ 8.63447785e-03  1.46943703e-02 -5.56530431e-03 ... -1.24124438e-03\n",
      "  -6.98959036e-03  9.17155296e-04]\n",
      " [-5.49912453e-03 -1.02118552e-02 -1.12590995e-02 ...  4.41578850e-02\n",
      "  -3.71305272e-03  1.94970742e-02]\n",
      " [ 7.80924410e-03  4.96549070e-01 -5.07304817e-03 ...  6.47070259e-03\n",
      "   7.73030985e-03 -3.63646029e-03]]\n",
      "current score:  [[  nan   nan   nan ... 0.739 0.939   nan]\n",
      " [  nan 0.64  0.787 ... 0.414 0.879   nan]\n",
      " [0.107   nan   nan ...   nan   nan 0.522]\n",
      " ...\n",
      " [  nan   nan 1.    ... 0.322 0.642   nan]\n",
      " [  nan   nan   nan ... 0.751 0.939   nan]\n",
      " [  nan   nan 0.667 ... 0.214   nan   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "Number of predicted domains: 728\n",
      "Average improvement: 0.4791253221804624\n",
      "Standard deviation: 0.11593425318658507\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.51866114]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.61497074 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.50956637]\n",
      " [0.         0.         0.73223019 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ... 0.739 0.939   nan]\n",
      " [  nan 0.64  0.787 ... 0.414 0.879   nan]\n",
      " [0.107   nan   nan ...   nan   nan 0.522]\n",
      " ...\n",
      " [  nan   nan 1.    ... 0.322 0.642   nan]\n",
      " [  nan   nan   nan ... 0.751 0.939   nan]\n",
      " [  nan   nan 0.667 ... 0.214   nan   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 728\n",
      "Average improvement: 0.6499402401457121\n",
      "Standard deviation: 0.1196502097164064\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.51866114]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.61497074 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.50956637]\n",
      " [0.         0.         0.73223019 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ... 0.739 0.939   nan]\n",
      " [  nan 0.64  0.787 ... 0.414 0.879   nan]\n",
      " [0.107   nan   nan ...   nan   nan 0.522]\n",
      " ...\n",
      " [  nan   nan 1.    ... 0.322 0.642   nan]\n",
      " [  nan   nan   nan ... 0.751 0.939   nan]\n",
      " [  nan   nan 0.667 ... 0.214   nan   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 728\n",
      "Average improvement: 0.6499402401457121\n",
      "Standard deviation: 0.1196502097164064\n",
      "========= 10 missing\n",
      "----ground truth----\n",
      "prediction score:  [[  nan 0.6   0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.129 0.    0.463   nan 0.167   nan 0.121   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.    0.8     nan\n",
      "    nan   nan]\n",
      " [  nan 0.    0.      nan 0.15    nan   nan   nan   nan   nan   nan 0.\n",
      "  0.576   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.424   nan]\n",
      " [  nan 0.08  0.6   0.086   nan   nan   nan   nan 0.1   0.279   nan   nan\n",
      "  0.461   nan]\n",
      " [  nan   nan   nan 0.    0.    0.      nan   nan   nan 0.      nan   nan\n",
      "    nan 0.533]\n",
      " [  nan 1.      nan 0.571 0.3     nan   nan   nan   nan   nan   nan 0.507\n",
      "  0.885   nan]\n",
      " [0.771   nan 0.92  0.471 0.27    nan   nan   nan   nan   nan   nan 0.364\n",
      "  0.739   nan]\n",
      " [0.286 0.37    nan 0.229 0.2     nan   nan   nan   nan 0.443   nan   nan\n",
      "  0.394   nan]\n",
      " [0.714   nan   nan   nan   nan   nan   nan   nan 0.94  0.571 1.    0.671\n",
      "  0.606   nan]\n",
      " [0.357   nan 1.      nan   nan 0.684   nan   nan   nan 0.536 0.8   0.857\n",
      "  0.606   nan]\n",
      " [0.429   nan   nan   nan   nan 1.    0.48  0.1     nan 0.643   nan   nan\n",
      "    nan   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.429 1.    0.25\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.684   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan 0.143 0.    0.737   nan   nan   nan 0.571 1.      nan\n",
      "    nan   nan]\n",
      " [  nan   nan 1.    0.657 0.46    nan   nan   nan 0.82    nan   nan   nan\n",
      "  0.836   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.737   nan 0.167   nan 0.571 1.    0.214\n",
      "    nan   nan]\n",
      " [0.429   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.571 1.    0.214\n",
      "    nan   nan]\n",
      " [0.632   nan   nan   nan 0.71    nan   nan   nan   nan 0.577 1.      nan\n",
      "    nan 0.533]\n",
      " [0.571 0.69    nan   nan   nan   nan 0.78    nan   nan   nan   nan 0.321\n",
      "  0.649   nan]\n",
      " [  nan   nan   nan 0.429 0.1   0.684 0.05    nan   nan 0.465   nan   nan\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733   nan   nan   nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [  nan 0.6   0.733 0.357 0.1     nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan 0.867   nan   nan   nan   nan   nan   nan 0.607 0.8   0.286\n",
      "    nan 0.767]\n",
      " [  nan 0.5     nan 0.7   0.49    nan   nan   nan 0.    0.757   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.167 0.067 0.027 0.15    nan   nan 0.098   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan 0.429 0.2   0.036\n",
      "  0.636   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.737   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.684   nan 0.      nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan 0.96    nan 0.438 0.207   nan   nan   nan   nan 0.769   nan 0.497\n",
      "    nan   nan]\n",
      " [  nan   nan 0.933 0.286 0.1     nan   nan   nan   nan   nan   nan 0.893\n",
      "  0.576   nan]\n",
      " [  nan   nan 0.733 0.286 0.1     nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.163 0.065   nan 0.056   nan   nan 0.046   nan 0.121\n",
      "  0.73    nan]\n",
      " [  nan   nan   nan 0.072 0.    0.737 0.35    nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.533 0.357 0.25    nan   nan   nan   nan   nan   nan 0.464\n",
      "  0.697   nan]\n",
      " [0.585   nan   nan 0.643 0.45    nan   nan   nan 0.95    nan   nan   nan\n",
      "  0.703   nan]\n",
      " [0.429   nan 0.467   nan   nan   nan   nan   nan   nan 0.25  1.    0.\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan 0.842   nan 0.583   nan 0.5   0.6     nan\n",
      "  0.182 0.167]\n",
      " [0.357 0.46  0.893 0.286   nan 0.695 1.      nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.684   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan 0.\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.243 0.2   0.695   nan   nan 0.1     nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.232 0.15    nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.    0.667 0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.57    nan 0.214 0.05    nan   nan   nan 0.42  0.743   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.636   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.263   nan   nan   nan 0.25    nan 0.\n",
      "  0.424   nan]\n",
      " [  nan 0.86    nan   nan 0.258   nan   nan   nan 0.587   nan   nan 0.248\n",
      "    nan 0.867]\n",
      " [  nan   nan 0.467 0.143 0.      nan   nan   nan   nan 0.286   nan 0.\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.737   nan   nan   nan 0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.5     nan   nan 0.214 0.05    nan   nan   nan   nan 0.75    nan   nan\n",
      "  0.242   nan]\n",
      " [0.429   nan   nan 0.214 0.05  0.      nan   nan   nan 0.25  1.      nan\n",
      "    nan   nan]\n",
      " [  nan 0.55  0.667   nan   nan 0.      nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]]\n",
      "current score:  [[  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.129   nan 0.463   nan 0.167   nan 0.121   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.      nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.    0.      nan   nan   nan   nan   nan   nan   nan   nan 0.\n",
      "  0.576   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan 0.08  0.6     nan   nan   nan   nan   nan 0.1     nan   nan   nan\n",
      "  0.461   nan]\n",
      " [  nan   nan   nan 0.      nan 0.      nan   nan   nan 0.      nan   nan\n",
      "    nan 0.533]\n",
      " [  nan   nan   nan 0.571 0.3     nan   nan   nan   nan   nan   nan 0.507\n",
      "  0.885   nan]\n",
      " [0.771   nan 0.92    nan   nan   nan   nan   nan   nan   nan   nan 0.364\n",
      "  0.739   nan]\n",
      " [0.286 0.37    nan   nan   nan   nan   nan   nan   nan 0.443   nan   nan\n",
      "  0.394   nan]\n",
      " [0.714   nan   nan   nan   nan   nan   nan   nan 0.94    nan   nan 0.671\n",
      "  0.606   nan]\n",
      " [  nan   nan 1.      nan   nan 0.684   nan   nan   nan   nan   nan 0.857\n",
      "  0.606   nan]\n",
      " [0.429   nan   nan   nan   nan 1.      nan 0.1     nan 0.643   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.733   nan   nan 0.684   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.737   nan   nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 1.    0.657 0.46    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.836   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.737   nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667 0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [0.632   nan   nan   nan 0.71    nan   nan   nan   nan 0.577 1.      nan\n",
      "    nan   nan]\n",
      " [0.571   nan   nan   nan   nan   nan 0.78    nan   nan   nan   nan 0.321\n",
      "  0.649   nan]\n",
      " [  nan   nan   nan 0.429 0.1   0.684   nan   nan   nan 0.465   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733   nan   nan   nan   nan   nan   nan 0.286   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.733 0.357 0.1     nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan 0.867   nan   nan   nan   nan   nan   nan 0.607   nan 0.286\n",
      "    nan 0.767]\n",
      " [  nan 0.5     nan 0.7   0.49    nan   nan   nan 0.      nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.167 0.067 0.027   nan   nan   nan 0.098   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan 0.429 0.2     nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.737   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan 0.96    nan 0.425 0.207   nan   nan   nan   nan   nan   nan 0.497\n",
      "    nan   nan]\n",
      " [  nan   nan 0.933 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.576   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.163 0.065   nan 0.056   nan   nan 0.046   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.072 0.    0.737   nan   nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.533 0.357 0.25    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.485   nan]\n",
      " [0.585   nan   nan 0.643 0.45    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.703   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan 0.25    nan 0.\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan 0.842   nan 0.583   nan   nan   nan   nan\n",
      "  0.182 0.167]\n",
      " [0.357 0.46  0.893   nan   nan   nan 1.      nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.243 0.2   0.695   nan   nan 0.1     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.263 0.15    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667 0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.57    nan 0.214 0.05    nan   nan   nan 0.42    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.263   nan   nan   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.86    nan   nan 0.258   nan   nan   nan 0.587   nan   nan 0.248\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan 0.286   nan 0.\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.737   nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [0.5     nan   nan 0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.242   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.      nan   nan   nan 0.25    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.      nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]]\n",
      "encoding:  [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 87\n",
      "Average improvement: 0.5006666666666667\n",
      "Standard deviation: 0.302673231838096\n",
      "prediction score:  [[  nan 0.6   0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.129 0.    0.463   nan 0.167   nan 0.121   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.    0.8     nan\n",
      "    nan   nan]\n",
      " [  nan 0.    0.      nan 0.15    nan   nan   nan   nan   nan   nan 0.\n",
      "  0.576   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.424   nan]\n",
      " [  nan 0.08  0.6   0.086   nan   nan   nan   nan 0.1   0.279   nan   nan\n",
      "  0.461   nan]\n",
      " [  nan   nan   nan 0.    0.    0.      nan   nan   nan 0.      nan   nan\n",
      "    nan 0.533]\n",
      " [  nan 1.      nan 0.571 0.3     nan   nan   nan   nan   nan   nan 0.507\n",
      "  0.885   nan]\n",
      " [0.771   nan 0.92  0.471 0.27    nan   nan   nan   nan   nan   nan 0.364\n",
      "  0.739   nan]\n",
      " [0.286 0.37    nan 0.229 0.2     nan   nan   nan   nan 0.443   nan   nan\n",
      "  0.394   nan]\n",
      " [0.714   nan   nan   nan   nan   nan   nan   nan 0.94  0.571 1.    0.671\n",
      "  0.606   nan]\n",
      " [0.357   nan 1.      nan   nan 0.684   nan   nan   nan 0.536 0.8   0.857\n",
      "  0.606   nan]\n",
      " [0.429   nan   nan   nan   nan 1.    0.48  0.1     nan 0.643   nan   nan\n",
      "    nan   nan]\n",
      " [0.429   nan 0.4     nan   nan   nan   nan   nan   nan 0.429 1.    0.25\n",
      "  0.424   nan]\n",
      " [0.429   nan 0.733   nan   nan 0.684   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [0.429   nan   nan 0.143 0.    0.737   nan   nan   nan 0.571 1.      nan\n",
      "    nan   nan]\n",
      " [  nan   nan 1.    0.657 0.46    nan   nan   nan 0.82    nan   nan   nan\n",
      "  0.836   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.737   nan 0.167   nan 0.571 1.    0.214\n",
      "    nan   nan]\n",
      " [0.429   nan 0.667 0.214 0.05    nan   nan   nan   nan 0.571 1.    0.214\n",
      "    nan   nan]\n",
      " [0.632   nan   nan   nan 0.71    nan   nan   nan   nan 0.577 1.      nan\n",
      "    nan 0.533]\n",
      " [0.571 0.69    nan   nan   nan   nan 0.78    nan   nan   nan   nan 0.321\n",
      "  0.649   nan]\n",
      " [  nan   nan   nan 0.429 0.1   0.684 0.05    nan   nan 0.465   nan   nan\n",
      "    nan   nan]\n",
      " [0.429   nan 0.733   nan   nan   nan   nan   nan   nan 0.571 1.    0.25\n",
      "  0.455   nan]\n",
      " [  nan 0.6   0.733 0.357 0.1     nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan 0.867   nan   nan   nan   nan   nan   nan 0.607 0.8   0.286\n",
      "    nan 0.767]\n",
      " [  nan 0.5     nan 0.7   0.49    nan   nan   nan 0.    0.757   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.167 0.067 0.027 0.15    nan   nan 0.098   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan 0.429 0.2   0.036\n",
      "  0.636   nan]\n",
      " [  nan   nan 0.467 0.286 0.1   0.737   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.684   nan 0.      nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan 0.96    nan 0.438 0.207   nan   nan   nan   nan 0.769   nan 0.497\n",
      "    nan   nan]\n",
      " [  nan   nan 0.933 0.286 0.1     nan   nan   nan   nan   nan   nan 0.893\n",
      "  0.576   nan]\n",
      " [  nan   nan 0.733 0.286 0.1     nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.163 0.065   nan 0.056   nan   nan 0.046   nan 0.121\n",
      "  0.73    nan]\n",
      " [  nan   nan   nan 0.072 0.    0.737 0.35    nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.533 0.357 0.25    nan   nan   nan   nan   nan   nan 0.464\n",
      "  0.697   nan]\n",
      " [0.585   nan   nan 0.643 0.45    nan   nan   nan 0.95    nan   nan   nan\n",
      "  0.703   nan]\n",
      " [0.429   nan 0.467   nan   nan   nan   nan   nan   nan 0.25  1.    0.\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan 0.842   nan 0.583   nan 0.5   0.6     nan\n",
      "  0.182 0.167]\n",
      " [0.357 0.46  0.893 0.286   nan 0.695 1.      nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05  0.684   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.667 0.286 0.1     nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan 0.\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.243 0.2   0.695   nan   nan 0.1     nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.232 0.15    nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.    0.667 0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.57    nan 0.214 0.05    nan   nan   nan 0.42  0.743   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.636   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.263   nan   nan   nan 0.25    nan 0.\n",
      "  0.424   nan]\n",
      " [  nan 0.86    nan   nan 0.258   nan   nan   nan 0.587   nan   nan 0.248\n",
      "    nan 0.867]\n",
      " [  nan   nan 0.467 0.143 0.      nan   nan   nan   nan 0.286   nan 0.\n",
      "  0.455   nan]\n",
      " [0.429   nan 0.667   nan   nan 0.737   nan   nan   nan 0.571 1.    0.214\n",
      "  0.455   nan]\n",
      " [0.5     nan   nan 0.214 0.05    nan   nan   nan   nan 0.75    nan   nan\n",
      "  0.242   nan]\n",
      " [0.429   nan   nan 0.214 0.05  0.      nan   nan   nan 0.25  1.      nan\n",
      "    nan   nan]\n",
      " [  nan 0.55  0.667   nan   nan 0.      nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]]\n",
      "current score:  [[  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.129   nan 0.463   nan 0.167   nan 0.121   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.737   nan   nan   nan 0.      nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.    0.      nan   nan   nan   nan   nan   nan   nan   nan 0.\n",
      "  0.576   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan 0.08  0.6     nan   nan   nan   nan   nan 0.1     nan   nan   nan\n",
      "  0.461   nan]\n",
      " [  nan   nan   nan 0.      nan 0.      nan   nan   nan 0.      nan   nan\n",
      "    nan 0.533]\n",
      " [  nan   nan   nan 0.571 0.3     nan   nan   nan   nan   nan   nan 0.507\n",
      "  0.885   nan]\n",
      " [0.771   nan 0.92    nan   nan   nan   nan   nan   nan   nan   nan 0.364\n",
      "  0.739   nan]\n",
      " [0.286 0.37    nan   nan   nan   nan   nan   nan   nan 0.443   nan   nan\n",
      "  0.394   nan]\n",
      " [0.714   nan   nan   nan   nan   nan   nan   nan 0.94    nan   nan 0.671\n",
      "  0.606   nan]\n",
      " [  nan   nan 1.      nan   nan 0.684   nan   nan   nan   nan   nan 0.857\n",
      "  0.606   nan]\n",
      " [0.429   nan   nan   nan   nan 1.      nan 0.1     nan 0.643   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.733   nan   nan 0.684   nan   nan   nan   nan   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.737   nan   nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 1.    0.657 0.46    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.836   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.737   nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667 0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [0.632   nan   nan   nan 0.71    nan   nan   nan   nan 0.577 1.      nan\n",
      "    nan   nan]\n",
      " [0.571   nan   nan   nan   nan   nan 0.78    nan   nan   nan   nan 0.321\n",
      "  0.649   nan]\n",
      " [  nan   nan   nan 0.429 0.1   0.684   nan   nan   nan 0.465   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733   nan   nan   nan   nan   nan   nan 0.286   nan 0.25\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.733 0.357 0.1     nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan 0.867   nan   nan   nan   nan   nan   nan 0.607   nan 0.286\n",
      "    nan 0.767]\n",
      " [  nan 0.5     nan 0.7   0.49    nan   nan   nan 0.      nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.167 0.067 0.027   nan   nan   nan 0.098   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan 0.429 0.2     nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.737   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan 0.96    nan 0.425 0.207   nan   nan   nan   nan   nan   nan 0.497\n",
      "    nan   nan]\n",
      " [  nan   nan 0.933 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.576   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.163 0.065   nan 0.056   nan   nan 0.046   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.072 0.    0.737   nan   nan   nan 0.286   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.533 0.357 0.25    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.485   nan]\n",
      " [0.585   nan   nan 0.643 0.45    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.703   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan 0.25    nan 0.\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan 0.842   nan 0.583   nan   nan   nan   nan\n",
      "  0.182 0.167]\n",
      " [0.357 0.46  0.893   nan   nan   nan 1.      nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.243 0.2   0.695   nan   nan 0.1     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.    0.263 0.15    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667 0.214 0.05    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.57    nan 0.214 0.05    nan   nan   nan 0.42    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.263   nan   nan   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.86    nan   nan 0.258   nan   nan   nan 0.587   nan   nan 0.248\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan 0.286   nan 0.\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.737   nan   nan   nan   nan   nan 0.214\n",
      "  0.455   nan]\n",
      " [0.5     nan   nan 0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.242   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.      nan   nan   nan 0.25    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.      nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]]\n",
      "encoding:  [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 87\n",
      "Average improvement: 0.5006666666666667\n",
      "Standard deviation: 0.302673231838096\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 9.3511194e-03 -5.9224889e-03 -6.4196773e-03 ...  4.5822635e-03\n",
      "  -4.1943132e-03  3.8708830e-03]\n",
      " [ 6.8367049e-03  5.2709579e-03  5.8914237e-03 ...  7.5939000e-03\n",
      "   1.3015997e-02 -2.4587964e-03]\n",
      " [-8.9524537e-03 -1.3334982e-02 -2.2344053e-02 ... -8.2071051e-03\n",
      "  -2.1128921e-02  7.7726971e-04]\n",
      " ...\n",
      " [-7.3641911e-03  4.4987351e-03  2.7767587e-03 ... -1.1307612e-02\n",
      "   3.0813092e-01  2.6131216e-03]\n",
      " [-1.4978342e-02 -7.3039532e-03 -3.2930952e-02 ... -2.9855743e-03\n",
      "  -1.8764477e-02 -3.9700605e-03]\n",
      " [-6.1546564e-03 -8.8946968e-03  8.2992017e-05 ... -1.4475092e-02\n",
      "  -1.0730079e-02  4.1097614e-01]]\n",
      "current score:  [[  nan   nan 0.747 ... 0.343 0.818   nan]\n",
      " [  nan   nan 0.453 ...   nan 0.385   nan]\n",
      " [  nan   nan 0.093 ...   nan 0.012   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.12  ...   nan 0.024   nan]\n",
      " [  nan   nan 0.107 ...   nan 0.018   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 480\n",
      "Average improvement: 0.4515646578433613\n",
      "Standard deviation: 0.11401604525419123\n",
      "prediction score:  [[ 9.3511194e-03 -5.9224889e-03 -6.4196773e-03 ...  4.5822635e-03\n",
      "  -4.1943132e-03  3.8708830e-03]\n",
      " [ 6.8367049e-03  5.2709579e-03  5.8914237e-03 ...  7.5939000e-03\n",
      "   1.3015997e-02 -2.4587964e-03]\n",
      " [-8.9524537e-03 -1.3334982e-02 -2.2344053e-02 ... -8.2071051e-03\n",
      "  -2.1128921e-02  7.7726971e-04]\n",
      " ...\n",
      " [-7.3641911e-03  4.4987351e-03  2.7767587e-03 ... -1.1307612e-02\n",
      "   3.0813092e-01  2.6131216e-03]\n",
      " [-1.4978342e-02 -7.3039532e-03 -3.2930952e-02 ... -2.9855743e-03\n",
      "  -1.8764477e-02 -3.9700605e-03]\n",
      " [-6.1546564e-03 -8.8946968e-03  8.2992017e-05 ... -1.4475092e-02\n",
      "  -1.0730079e-02  4.1097614e-01]]\n",
      "current score:  [[  nan   nan 0.747 ... 0.343 0.818   nan]\n",
      " [  nan   nan 0.453 ...   nan 0.385   nan]\n",
      " [  nan   nan 0.093 ...   nan 0.012   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.12  ...   nan 0.024   nan]\n",
      " [  nan   nan 0.107 ...   nan 0.018   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Number of predicted domains: 480\n",
      "Average improvement: 0.4515646578433613\n",
      "Standard deviation: 0.11401604525419123\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.53559613]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.49961519 0.         0.        ]]\n",
      "current score:  [[  nan   nan 0.747 ... 0.343 0.818   nan]\n",
      " [  nan   nan 0.453 ...   nan 0.385   nan]\n",
      " [  nan   nan 0.093 ...   nan 0.012   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.12  ...   nan 0.024   nan]\n",
      " [  nan   nan 0.107 ...   nan 0.018   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "Number of predicted domains: 480\n",
      "Average improvement: 0.6279441150526206\n",
      "Standard deviation: 0.12400396932199571\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.53559613]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.49961519 0.         0.        ]]\n",
      "current score:  [[  nan   nan 0.747 ... 0.343 0.818   nan]\n",
      " [  nan   nan 0.453 ...   nan 0.385   nan]\n",
      " [  nan   nan 0.093 ...   nan 0.012   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.12  ...   nan 0.024   nan]\n",
      " [  nan   nan 0.107 ...   nan 0.018   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "Number of predicted domains: 480\n",
      "Average improvement: 0.6279441150526206\n",
      "Standard deviation: 0.12400396932199571\n",
      "========= 11 missing\n",
      "----ground truth----\n",
      "prediction score:  [[  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " [0.386 0.41    nan ...   nan 0.243   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " ...\n",
      " [  nan   nan 0.587 ... 0.    0.521   nan]\n",
      " [  nan   nan   nan ...   nan   nan 0.033]\n",
      " [  nan   nan 0.4   ... 0.214 0.424   nan]]\n",
      "current score:  [[  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " [0.386   nan   nan ...   nan 0.243   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " ...\n",
      " [  nan   nan 0.587 ... 0.    0.521   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]]\n",
      "encoding:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 0.]]\n",
      "Number of predicted domains: 99\n",
      "Average improvement: 0.34230303030303033\n",
      "Standard deviation: 0.25177842763703295\n",
      "prediction score:  [[  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " [0.386 0.41    nan ...   nan 0.243   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " ...\n",
      " [  nan   nan 0.587 ... 0.    0.521   nan]\n",
      " [  nan   nan   nan ...   nan   nan 0.033]\n",
      " [  nan   nan 0.4   ... 0.214 0.424   nan]]\n",
      "current score:  [[  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " [0.386   nan   nan ...   nan 0.243   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " ...\n",
      " [  nan   nan 0.587 ... 0.    0.521   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]]\n",
      "encoding:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 0.]]\n",
      "Number of predicted domains: 99\n",
      "Average improvement: 0.34230303030303033\n",
      "Standard deviation: 0.25177842763703295\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 0.00151461 -0.00185627 -0.00824675 ...  0.02485264  0.00884831\n",
      "  -0.00060818]\n",
      " [-0.00113498  0.3637746  -0.00187733 ...  0.00998288 -0.00523944\n",
      "  -0.00301611]\n",
      " [ 0.00769144  0.00711662  0.00972193 ... -0.00644641  0.01558448\n",
      "   0.00648564]\n",
      " ...\n",
      " [-0.00866774 -0.00068627  0.00581631 ... -0.00342192 -0.01178371\n",
      "  -0.0121363 ]\n",
      " [ 0.00480923 -0.00073387 -0.0062146  ... -0.00452103 -0.00562139\n",
      "   0.45333505]\n",
      " [ 0.00639103  0.00177903  0.00574798 ...  0.00271422  0.00902753\n",
      "   0.01224798]]\n",
      "current score:  [[  nan   nan   nan ... 0.5   0.867   nan]\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 160\n",
      "Average improvement: 0.46094469213858247\n",
      "Standard deviation: 0.11217109454374574\n",
      "prediction score:  [[ 0.00151461 -0.00185627 -0.00824675 ...  0.02485264  0.00884831\n",
      "  -0.00060818]\n",
      " [-0.00113498  0.3637746  -0.00187733 ...  0.00998288 -0.00523944\n",
      "  -0.00301611]\n",
      " [ 0.00769144  0.00711662  0.00972193 ... -0.00644641  0.01558448\n",
      "   0.00648564]\n",
      " ...\n",
      " [-0.00866774 -0.00068627  0.00581631 ... -0.00342192 -0.01178371\n",
      "  -0.0121363 ]\n",
      " [ 0.00480923 -0.00073387 -0.0062146  ... -0.00452103 -0.00562139\n",
      "   0.45333505]\n",
      " [ 0.00639103  0.00177903  0.00574798 ...  0.00271422  0.00902753\n",
      "   0.01224798]]\n",
      "current score:  [[  nan   nan   nan ... 0.5   0.867   nan]\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 160\n",
      "Average improvement: 0.46094469213858247\n",
      "Standard deviation: 0.11217109454374574\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.74675262 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ... 0.5   0.867   nan]\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 160\n",
      "Average improvement: 0.636813635751605\n",
      "Standard deviation: 0.12257697532280276\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.74675262 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ... 0.5   0.867   nan]\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan 0.267]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 160\n",
      "Average improvement: 0.636813635751605\n",
      "Standard deviation: 0.12257697532280276\n",
      "========= 12 missing\n",
      "----ground truth----\n",
      "prediction score:  [[  nan   nan 0.4     nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [0.357   nan   nan 0.429   nan   nan   nan   nan   nan 0.536 0.8     nan\n",
      "    nan   nan]\n",
      " [0.9     nan   nan   nan   nan 0.4   0.28    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan 0.25    nan   nan\n",
      "  0.      nan]\n",
      " [0.743   nan   nan   nan   nan 0.505 0.57    nan   nan   nan   nan   nan\n",
      "  0.824   nan]\n",
      " [  nan   nan   nan   nan   nan 0.568 0.36  0.8     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.75    nan 0.5     nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [0.357 0.58    nan   nan   nan   nan   nan   nan   nan 0.579   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.827   nan   nan   nan   nan   nan   nan   nan   nan 0.235\n",
      "  0.721   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan 0.      nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.19  0.341   nan 0.142   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.13    nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.293 0.4   0.\n",
      "  0.455   nan]\n",
      " [0.571   nan 0.6     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.557   nan]\n",
      " [0.343 0.43    nan 0.614 0.34    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.2     nan   nan   nan   nan   nan   nan   nan   nan 0.036\n",
      "  0.091   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.684   nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.286 0.1   0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.6     nan   nan   nan   nan   nan   nan 0.767   nan   nan   nan\n",
      "  0.748   nan]\n",
      " [  nan   nan 0.433 0.262 0.083   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.326   nan]\n",
      " [  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [0.571   nan   nan   nan   nan   nan   nan   nan   nan 0.378   nan   nan\n",
      "  0.394   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.      nan]\n",
      " [  nan   nan   nan 0.357 0.1     nan   nan   nan   nan 0.679   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan   nan 0.536 0.8     nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.    0.    0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.071\n",
      "  0.424   nan]\n",
      " [  nan 0.65  0.933   nan   nan   nan   nan   nan   nan   nan   nan 0.064\n",
      "    nan   nan]\n",
      " [0.357 0.2   0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.036\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.      nan 0.286   nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan   nan 0.286 0.15    nan   nan   nan   nan   nan   nan 0.143\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.071   nan 0.053   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.2  ]\n",
      " [  nan   nan   nan 0.6   0.36    nan   nan   nan   nan   nan   nan 0.478\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.333]\n",
      " [0.643 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.339   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424 0.667]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 1.      nan   nan 1.    0.29    nan   nan   nan   nan   nan\n",
      "  0.727   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.571 0.3     nan   nan   nan   nan 0.722   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.286 0.2     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.    0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [0.871 0.57  0.734   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.467   nan]\n",
      " [  nan   nan 0.8     nan   nan   nan   nan   nan 0.8     nan   nan   nan\n",
      "  0.545   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan 0.083   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.694 0.157 0.025   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.667   nan]]\n",
      "current score:  [[  nan   nan   nan   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.429   nan   nan   nan   nan   nan 0.607   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.4   0.28    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [0.743   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.824   nan]\n",
      " [  nan   nan   nan   nan   nan 0.516 0.36    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.75    nan 0.5     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.58    nan   nan   nan   nan   nan   nan   nan 0.579   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.827   nan   nan   nan   nan   nan   nan   nan   nan 0.235\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.19    nan   nan 0.142   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.293 0.4     nan\n",
      "    nan   nan]\n",
      " [0.571   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.582   nan]\n",
      " [0.343 0.43    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.2     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.091   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.767   nan   nan   nan\n",
      "  0.748   nan]\n",
      " [  nan   nan 0.433   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.326   nan]\n",
      " [  nan   nan   nan 0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [1.      nan   nan   nan   nan   nan   nan   nan   nan 0.378   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan   nan 0.357 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.933   nan   nan   nan   nan   nan   nan   nan   nan 0.064\n",
      "    nan   nan]\n",
      " [0.357 0.2     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan   nan   nan 0.15    nan   nan   nan   nan   nan   nan 0.143\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.071   nan 0.053   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.6   0.36    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.643   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.339   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan   nan   nan   nan 1.    0.29    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.571 0.3     nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [0.871 0.57    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.8     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.545   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan 0.083   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.694   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.667   nan]]\n",
      "encoding:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 77\n",
      "Average improvement: 0.38074025974025977\n",
      "Standard deviation: 0.2735834522252956\n",
      "prediction score:  [[  nan   nan 0.4     nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.25    nan   nan\n",
      "  0.424   nan]\n",
      " [0.357   nan   nan 0.429   nan   nan   nan   nan   nan 0.536 0.8     nan\n",
      "    nan   nan]\n",
      " [0.9     nan   nan   nan   nan 0.4   0.28    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan 0.25    nan   nan\n",
      "  0.      nan]\n",
      " [0.743   nan   nan   nan   nan 0.505 0.57    nan   nan   nan   nan   nan\n",
      "  0.824   nan]\n",
      " [  nan   nan   nan   nan   nan 0.568 0.36  0.8     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.75    nan 0.5     nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [0.357 0.58    nan   nan   nan   nan   nan   nan   nan 0.579   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.827   nan   nan   nan   nan   nan   nan   nan   nan 0.235\n",
      "  0.721   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan 0.      nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.19  0.341   nan 0.142   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.13    nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.293 0.4   0.\n",
      "  0.455   nan]\n",
      " [0.571   nan 0.6     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.557   nan]\n",
      " [0.343 0.43    nan 0.614 0.34    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467 0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.2     nan   nan   nan   nan   nan   nan   nan   nan 0.036\n",
      "  0.091   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.684   nan 0.167   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.286 0.1   0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.6     nan   nan   nan   nan   nan   nan 0.767   nan   nan   nan\n",
      "  0.748   nan]\n",
      " [  nan   nan 0.433 0.262 0.083   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.326   nan]\n",
      " [  nan   nan 0.733 0.214 0.05    nan   nan   nan   nan   nan   nan 0.25\n",
      "    nan   nan]\n",
      " [0.571   nan   nan   nan   nan   nan   nan   nan   nan 0.378   nan   nan\n",
      "  0.394   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.      nan]\n",
      " [  nan   nan   nan 0.357 0.1     nan   nan   nan   nan 0.679   nan   nan\n",
      "    nan   nan]\n",
      " [0.357   nan 0.4     nan   nan   nan   nan   nan   nan 0.536 0.8     nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467 0.286 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan 0.    0.    0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.071\n",
      "  0.424   nan]\n",
      " [  nan 0.65  0.933   nan   nan   nan   nan   nan   nan   nan   nan 0.064\n",
      "    nan   nan]\n",
      " [0.357 0.2   0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.036\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.      nan 0.286   nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan   nan 0.286 0.15    nan   nan   nan   nan   nan   nan 0.143\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.071   nan 0.053   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.2  ]\n",
      " [  nan   nan   nan 0.6   0.36    nan   nan   nan   nan   nan   nan 0.478\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.333]\n",
      " [0.643 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.339   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424 0.667]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan 0.214\n",
      "  0.      nan]\n",
      " [  nan   nan 1.      nan   nan 1.    0.29    nan   nan   nan   nan   nan\n",
      "  0.727   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan 0.25\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.571 0.3     nan   nan   nan   nan 0.722   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4   0.286 0.2     nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.    0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [0.871 0.57  0.734   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.467   nan]\n",
      " [  nan   nan 0.8     nan   nan   nan   nan   nan 0.8     nan   nan   nan\n",
      "  0.545   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan 0.083   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.694 0.157 0.025   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.667   nan]]\n",
      "current score:  [[  nan   nan   nan   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.429   nan   nan   nan   nan   nan 0.607   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.4   0.28    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [0.743   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.824   nan]\n",
      " [  nan   nan   nan   nan   nan 0.516 0.36    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.75    nan 0.5     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.58    nan   nan   nan   nan   nan   nan   nan 0.579   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.827   nan   nan   nan   nan   nan   nan   nan   nan 0.235\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.19    nan   nan 0.142   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.293 0.4     nan\n",
      "    nan   nan]\n",
      " [0.571   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.582   nan]\n",
      " [0.343 0.43    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.2     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.091   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.767   nan   nan   nan\n",
      "  0.748   nan]\n",
      " [  nan   nan 0.433   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.326   nan]\n",
      " [  nan   nan   nan 0.214 0.05    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [1.      nan   nan   nan   nan   nan   nan   nan   nan 0.378   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan   nan 0.357 0.1     nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.933   nan   nan   nan   nan   nan   nan   nan   nan 0.064\n",
      "    nan   nan]\n",
      " [0.357 0.2     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.286   nan   nan\n",
      "    nan 0.067]\n",
      " [  nan   nan   nan   nan 0.15    nan   nan   nan   nan   nan   nan 0.143\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.071   nan 0.053   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.6   0.36    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.143 0.      nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.643   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.339   nan]\n",
      " [  nan   nan 0.467   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [  nan   nan   nan   nan   nan 1.    0.29    nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.571 0.3     nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.      nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.      nan]\n",
      " [0.871 0.57    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.8     nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.545   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan 0.083   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.694   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.667   nan]]\n",
      "encoding:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Number of predicted domains: 77\n",
      "Average improvement: 0.38074025974025977\n",
      "Standard deviation: 0.2735834522252956\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 6.4008814e-01  3.1758025e-03 -6.1376188e-03 ...  7.1763769e-03\n",
      "  -1.1990786e-02 -2.1629207e-02]\n",
      " [ 4.7515333e-04 -5.8335066e-03 -2.6475936e-03 ...  1.2393765e-02\n",
      "   1.0293820e-03  5.9053051e-01]\n",
      " [ 1.7535239e-03  3.8653046e-01  7.9965834e-03 ...  2.3487806e-03\n",
      "   4.0795747e-03  4.3530166e-03]\n",
      " ...\n",
      " [ 8.3365142e-03 -9.3086138e-03  8.6310897e-03 ...  5.9695393e-03\n",
      "   1.6210950e-03  4.9911952e-03]\n",
      " [-2.8696358e-03  5.8167237e-01 -3.9427541e-03 ... -4.7596842e-03\n",
      "  -3.6306723e-03 -4.1607060e-03]\n",
      " [ 5.0364956e-03  1.2344591e-02  9.9987620e-03 ...  7.6170713e-03\n",
      "   1.4413878e-02 -1.5163356e-03]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.333]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.694 ...   nan 0.667   nan]]\n",
      "encoding:  [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 88\n",
      "Average improvement: 0.45475789498199115\n",
      "Standard deviation: 0.1237784759120623\n",
      "prediction score:  [[ 6.4008814e-01  3.1758025e-03 -6.1376188e-03 ...  7.1763769e-03\n",
      "  -1.1990786e-02 -2.1629207e-02]\n",
      " [ 4.7515333e-04 -5.8335066e-03 -2.6475936e-03 ...  1.2393765e-02\n",
      "   1.0293820e-03  5.9053051e-01]\n",
      " [ 1.7535239e-03  3.8653046e-01  7.9965834e-03 ...  2.3487806e-03\n",
      "   4.0795747e-03  4.3530166e-03]\n",
      " ...\n",
      " [ 8.3365142e-03 -9.3086138e-03  8.6310897e-03 ...  5.9695393e-03\n",
      "   1.6210950e-03  4.9911952e-03]\n",
      " [-2.8696358e-03  5.8167237e-01 -3.9427541e-03 ... -4.7596842e-03\n",
      "  -3.6306723e-03 -4.1607060e-03]\n",
      " [ 5.0364956e-03  1.2344591e-02  9.9987620e-03 ...  7.6170713e-03\n",
      "   1.4413878e-02 -1.5163356e-03]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.333]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.694 ...   nan 0.667   nan]]\n",
      "encoding:  [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Number of predicted domains: 88\n",
      "Average improvement: 0.45475789498199115\n",
      "Standard deviation: 0.1237784759120623\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.70637298 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.50626141 0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.333]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.694 ...   nan 0.667   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "Number of predicted domains: 88\n",
      "Average improvement: 0.6533646573397246\n",
      "Standard deviation: 0.1296502215006876\n",
      "prediction score:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.70637298 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.50626141 0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan ...   nan   nan 0.333]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.4   ...   nan 0.424   nan]\n",
      " ...\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan   nan ...   nan   nan   nan]\n",
      " [  nan   nan 0.694 ...   nan 0.667   nan]]\n",
      "encoding:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "Number of predicted domains: 88\n",
      "Average improvement: 0.6533646573397246\n",
      "Standard deviation: 0.1296502215006876\n",
      "========= 13 missing\n",
      "----ground truth----\n",
      "prediction score:  [[  nan   nan   nan 0.071   nan   nan   nan   nan   nan 0.036   nan 0.357\n",
      "    nan   nan]\n",
      " [0.429 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [0.643   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "  0.752   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan 0.15    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143 0.16    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.6     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "  0.697   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan 0.1\n",
      "  0.212   nan]\n",
      " [  nan 0.35    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan 0.667   nan   nan   nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.431   nan]\n",
      " [0.429   nan   nan   nan   nan   nan   nan   nan   nan 0.571 1.    0.821\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.737   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314 0.77    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.083   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.167   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.25    nan   nan   nan   nan   nan 0.077   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan 0.      nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.086\n",
      "  0.4     nan]\n",
      " [  nan   nan 0.467   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan 0.      nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan 0.25    nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan 0.728 0.56    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.506 0.5     nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.15    nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]]\n",
      "current score:  [[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.321\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.188   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.4     nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]]\n",
      "encoding:  [[0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Number of predicted domains: 62\n",
      "Average improvement: 0.35780645161290314\n",
      "Standard deviation: 0.22772249712182427\n",
      "prediction score:  [[  nan   nan   nan 0.071   nan   nan   nan   nan   nan 0.036   nan 0.357\n",
      "    nan   nan]\n",
      " [0.429 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [0.643   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "  0.752   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan 0.15    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357 0.25    nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143 0.16    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.6     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "  0.697   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan 0.1\n",
      "  0.212   nan]\n",
      " [  nan 0.35    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan 0.667   nan   nan   nan   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.431   nan]\n",
      " [0.429   nan   nan   nan   nan   nan   nan   nan   nan 0.571 1.    0.821\n",
      "    nan   nan]\n",
      " [  nan   nan 0.667   nan   nan 0.737   nan   nan   nan   nan   nan 0.214\n",
      "    nan   nan]\n",
      " [  nan   nan 0.733   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314 0.77    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.083   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.467   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.167   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.25    nan   nan   nan   nan   nan 0.077   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan 0.167   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan 0.      nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan 0.      nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.086\n",
      "  0.4     nan]\n",
      " [  nan   nan 0.467   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.455   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan 0.      nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan 0.25    nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan 0.728 0.56    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.506 0.5     nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]\n",
      " [  nan 0.15    nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.214 0.05  0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan 0.4     nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "  0.424   nan]]\n",
      "current score:  [[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.321\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.188   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.4     nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]]\n",
      "encoding:  [[0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Number of predicted domains: 62\n",
      "Average improvement: 0.35780645161290314\n",
      "Standard deviation: 0.22772249712182427\n",
      "----random----\n",
      "***nonrepeat***\n",
      "prediction score:  [[ 5.44200093e-03 -2.98844278e-03 -4.97572310e-03 -1.23346820e-02\n",
      "  -6.96929544e-03 -3.03588598e-03 -3.60432267e-03  5.23550436e-04\n",
      "   6.64802641e-03  4.44633693e-01 -2.14519165e-03  5.40561229e-03\n",
      "  -1.32957101e-03 -5.89047046e-03]\n",
      " [ 4.02133584e-01  8.48206133e-03  1.50974542e-02 -4.77135181e-05\n",
      "  -4.60401177e-04  1.16156098e-02  1.13743171e-02  2.66171992e-03\n",
      "   1.57706439e-04 -1.05922669e-03  6.65910076e-03  1.02416500e-02\n",
      "   1.65443122e-02  9.36279446e-03]\n",
      " [ 1.06269345e-02  1.76286399e-02  1.64444372e-02 -1.07925832e-02\n",
      "  -1.24335885e-02  1.23073114e-02  4.61120218e-01  1.20473616e-02\n",
      "   1.93970054e-02 -1.34138167e-02  1.92175657e-02  5.44349849e-03\n",
      "   1.19431894e-02  2.92192120e-03]\n",
      " [-1.15774572e-03  4.76889551e-01  4.38089017e-03 -2.45081633e-03\n",
      "   7.45763630e-03 -7.29870237e-03 -4.22447920e-03  5.15350699e-03\n",
      "  -4.25702333e-03  1.08867884e-02 -6.30251039e-03 -7.63627142e-03\n",
      "  -1.11811478e-02 -8.03709310e-03]\n",
      " [ 6.50361180e-04 -2.89749354e-03 -6.00577518e-03 -1.60149410e-02\n",
      "   1.29148364e-04 -3.07025225e-03 -8.96956772e-03 -6.08300604e-03\n",
      "   7.09327310e-03  4.59001631e-01 -2.23680828e-02  1.70774758e-04\n",
      "  -6.08527195e-03 -5.83428238e-03]\n",
      " [ 1.25087202e-02  1.53849348e-02  9.66304727e-03  1.71469525e-02\n",
      "   1.07367858e-02  4.22674837e-03  5.86658716e-05  1.09342448e-02\n",
      "   1.12541988e-02  4.18477684e-01  1.01601286e-02  1.31621808e-02\n",
      "   1.76454429e-02 -2.67269090e-04]\n",
      " [-1.14238486e-02 -7.27575272e-03 -5.86133450e-03 -7.19728321e-03\n",
      "  -1.24525279e-03 -6.21152110e-03  5.49612284e-01  1.51770189e-04\n",
      "   1.93797797e-03 -1.72962099e-02 -7.81377219e-03  2.24203691e-02\n",
      "   6.87488727e-03  6.59457408e-03]\n",
      " [-2.08168179e-02 -1.69779882e-02 -5.10979071e-03 -2.08018422e-02\n",
      "  -1.28786713e-02 -1.40963858e-02  2.36765221e-02  1.83183365e-02\n",
      "  -1.16527826e-03 -4.25899029e-03  1.15796728e-02  4.49726731e-03\n",
      "  -3.67745236e-02  6.14168346e-01]\n",
      " [ 4.10453081e-01 -2.21102685e-03  9.58921760e-03 -3.39022279e-03\n",
      "   4.99460846e-03  3.83988954e-04  2.03160197e-03  3.58257443e-03\n",
      "   2.42547691e-03  9.91480798e-03  2.52130348e-03  4.60587442e-04\n",
      "   1.67092541e-03  9.00269486e-04]\n",
      " [ 8.99761170e-03 -1.24774873e-04 -2.31393985e-03 -3.44800949e-03\n",
      "   5.44451177e-04  7.51578948e-04 -1.17436200e-02 -3.70893627e-04\n",
      "   1.01406872e-03 -3.39481980e-03  3.57003696e-03  5.49221516e-01\n",
      "   5.96735720e-03  1.01636536e-03]\n",
      " [-6.33016229e-04 -2.17031687e-03 -7.80377723e-03 -4.47301567e-03\n",
      "   7.26684928e-03  4.67071414e-01 -2.14762241e-03 -3.53058800e-03\n",
      "  -1.31227821e-03 -1.70198530e-02 -6.46776333e-03 -2.46210396e-03\n",
      "  -9.82384942e-03  3.73276044e-03]\n",
      " [ 5.25318384e-01  1.68715417e-03 -6.39595091e-04 -1.67041048e-02\n",
      "   3.27665359e-03 -2.87061501e-02  1.65409446e-02 -7.90040009e-03\n",
      "  -3.95338982e-03 -8.66330415e-03 -1.00171240e-02  5.19242138e-03\n",
      "  -7.01833190e-03 -3.36130941e-03]\n",
      " [ 2.64007598e-03 -4.65116650e-03  4.25618701e-03 -9.57101583e-04\n",
      "   9.25146043e-03  4.09932494e-01 -3.30209732e-03 -1.54659292e-02\n",
      "   5.40101528e-03 -5.80400974e-03  5.71062509e-03  1.52575225e-03\n",
      "  -5.20777609e-03 -2.44968617e-03]\n",
      " [ 8.18401575e-04 -1.07276216e-02  4.59445640e-04 -1.20110810e-03\n",
      "   2.49269605e-03  7.96257704e-03  2.99168378e-03 -3.39538231e-03\n",
      "   4.78343040e-01  1.01003721e-02 -9.76593047e-03  1.33065134e-03\n",
      "   6.80697709e-03  4.62229736e-03]\n",
      " [-6.38693571e-04 -2.45334953e-03  2.35182606e-03 -1.06914788e-02\n",
      "  -3.01540643e-03 -8.81273113e-03 -3.13252211e-03  4.88056779e-01\n",
      "  -3.80751491e-03  4.19427454e-03  1.35007566e-02  1.82358548e-02\n",
      "   9.09283292e-04  1.25187300e-02]\n",
      " [ 6.33580983e-03  2.59427726e-03  3.39302234e-03 -3.35165113e-03\n",
      "  -2.79568136e-03  2.44295783e-03 -5.97311556e-03 -3.60928476e-04\n",
      "   3.85773182e-03  4.22977656e-03 -3.39090684e-03  2.54467130e-03\n",
      "   3.07574481e-01 -7.51323998e-04]\n",
      " [ 3.75878066e-03 -8.10752809e-03  2.86437571e-04 -4.58927080e-02\n",
      "   5.20983100e-01 -1.84745039e-03 -2.46246159e-03 -9.96888988e-03\n",
      "   6.30468130e-03  3.87537479e-03 -1.27655026e-02  2.18529254e-02\n",
      "  -4.40979842e-03 -1.08665805e-02]\n",
      " [ 7.55944848e-03 -4.96774912e-03 -1.56898387e-02 -2.05126926e-02\n",
      "   1.08023584e-02  5.23298979e-03  2.98858434e-03 -5.07526845e-03\n",
      "   2.30632722e-04  3.31930757e-01  2.80228943e-01  2.03200206e-02\n",
      "   5.95570914e-03 -4.63907979e-03]\n",
      " [ 2.09041685e-03 -3.67227942e-03  3.79627012e-03 -4.51580435e-03\n",
      "   4.50931489e-04 -6.40028156e-03  5.25236249e-01 -3.92282382e-03\n",
      "   6.72381371e-03 -8.94669443e-03  3.74787953e-03  1.48844197e-02\n",
      "   2.05576792e-03  6.36321492e-03]\n",
      " [-1.73740685e-02 -1.05911493e-02 -5.19681722e-04 -6.65599853e-03\n",
      "   4.67624515e-03 -2.82690246e-02  5.25917858e-03  5.65682650e-01\n",
      "   4.61022109e-02 -2.92062052e-02  9.70687997e-03 -3.64266336e-04\n",
      "  -2.30049845e-02  2.18604561e-02]\n",
      " [ 4.44220006e-03  3.97897512e-03  4.19898704e-03 -4.22353297e-03\n",
      "  -3.66616249e-03 -3.87391984e-03  3.27212363e-03  4.11092862e-03\n",
      "   6.65950775e-03  3.51517648e-03  1.86443888e-03 -1.92523003e-03\n",
      "   6.73227198e-03  4.24423248e-01]\n",
      " [ 1.30903721e-02  3.21006030e-03  7.03178905e-03  5.97619265e-03\n",
      "   3.20622325e-03  2.14869110e-03 -8.53557885e-03  6.59139827e-03\n",
      "   3.18473577e-03  4.41188663e-01  1.25181461e-02  2.53797323e-03\n",
      "   9.62048769e-03 -2.32865429e-03]\n",
      " [ 1.10925511e-02 -3.91565263e-03  4.43236623e-03 -1.67950764e-02\n",
      "  -9.11918283e-03 -2.70986487e-03 -4.31942940e-03  3.04700881e-01\n",
      "   8.69377702e-03  4.20331955e-03  7.74988998e-03  1.42125115e-02\n",
      "  -2.53951619e-03  1.33386031e-02]\n",
      " [ 5.93997538e-03 -1.41662583e-02 -9.72846150e-03 -1.32038668e-02\n",
      "   1.59508362e-02  8.58215382e-04  4.46472317e-03  7.39995390e-04\n",
      "   9.98537987e-03  3.04471105e-01  6.50783062e-01  2.95232981e-03\n",
      "  -8.99855280e-04  1.87713951e-02]\n",
      " [-1.32019073e-03 -2.17592120e-02 -1.20115578e-02 -4.63021547e-03\n",
      "   2.27693468e-03  5.43454243e-03 -1.18222088e-03 -7.27580115e-03\n",
      "   4.80845839e-01  1.58720836e-02 -6.80029998e-03  6.16285205e-03\n",
      "  -6.89871982e-03  5.43038175e-03]\n",
      " [ 1.79604664e-02  9.79091227e-03 -9.63466242e-04  3.74695659e-03\n",
      "   6.12169504e-04  6.07674103e-03 -6.10886514e-03  3.72003764e-04\n",
      "   4.26887542e-01  2.89919227e-03  7.82238320e-04  1.43836662e-02\n",
      "   2.07782015e-02 -1.14000663e-02]\n",
      " [-1.68852508e-04  1.32020637e-02  8.11367761e-03 -6.95465505e-03\n",
      "  -1.19443163e-02  4.81953425e-03  4.52970535e-01  5.43835387e-03\n",
      "   5.41955233e-05 -1.58957690e-02  3.16326972e-03 -4.38079238e-03\n",
      "   1.44378264e-02 -6.50351960e-03]\n",
      " [-6.17843866e-03  7.13100076e-01  3.43830790e-03 -3.86695266e-02\n",
      "  -1.97033994e-02 -9.88441287e-04 -1.01264492e-02 -2.26236917e-02\n",
      "   3.31667811e-03 -2.52309479e-02 -3.85422483e-02 -6.16014004e-03\n",
      "   1.02376984e-02 -4.92593460e-03]\n",
      " [ 4.29017842e-03 -1.62233561e-02 -6.08715601e-03 -1.71346888e-02\n",
      "  -8.72382522e-03 -4.34282934e-04 -2.92308629e-04 -4.99907695e-03\n",
      "  -2.89545953e-03  4.01698053e-03 -1.77518856e-02  9.63671505e-03\n",
      "   6.87014520e-01 -1.02884257e-02]\n",
      " [ 1.04672015e-02  1.33422166e-02  1.47974472e-02  6.85657561e-03\n",
      "   6.65453821e-03 -1.40791968e-03  8.61306489e-03  5.96746802e-03\n",
      "   1.74332410e-03 -1.33187473e-02  8.06347467e-04  1.07105821e-02\n",
      "   1.99633408e-02  4.83099997e-01]\n",
      " [ 1.11157522e-02  2.26985663e-03  6.13667846e-01  8.18611681e-03\n",
      "   6.05462492e-03  4.24992712e-03  2.06237286e-03  7.65210390e-03\n",
      "   3.30484658e-03 -2.53123045e-03 -2.27803513e-02 -1.08271390e-02\n",
      "   4.60803788e-03  5.11418097e-04]\n",
      " [ 5.89698553e-04  1.89928710e-03 -8.39576684e-03 -1.67384744e-03\n",
      "  -3.06118280e-03  7.34605826e-04  4.22931284e-01 -5.63857704e-03\n",
      "   1.01289824e-02  1.20123327e-02 -9.96261649e-03  1.58203170e-02\n",
      "  -5.55866398e-04 -3.46096791e-02]\n",
      " [ 7.99872726e-03  3.83748114e-03  5.05653024e-03 -1.36009529e-02\n",
      "   5.24879992e-03  1.12960106e-02 -3.53671610e-04 -1.34652667e-03\n",
      "   7.54781812e-03  3.40783089e-01  4.99679059e-01 -5.82479686e-03\n",
      "   1.31312404e-02 -2.55666673e-05]\n",
      " [ 3.14117372e-01  9.27899778e-03  1.56563409e-02  6.10113144e-04\n",
      "  -6.06358051e-04 -5.41146100e-03  4.18817252e-03  7.85763189e-03\n",
      "   1.13318115e-02  3.61640751e-03  2.37946846e-02 -1.98867172e-03\n",
      "   6.86595403e-03  9.66940075e-03]\n",
      " [ 6.49521500e-03 -1.87829882e-03  5.29566966e-03  4.39788282e-01\n",
      "   1.82549357e-02 -1.81883504e-03  3.99023294e-03 -1.01700611e-03\n",
      "   5.45795262e-03  1.38865784e-02 -2.58292677e-03  2.42339075e-03\n",
      "   5.53438719e-03  5.14188036e-03]\n",
      " [ 5.58274239e-03  7.88040459e-03  6.53133914e-03  6.41245395e-03\n",
      "   1.08718127e-03  6.07410213e-03 -1.71996653e-03  1.02149099e-02\n",
      "  -1.36380643e-03  4.00029629e-01  1.52081018e-02  1.50504783e-02\n",
      "   2.55182721e-02 -1.88078731e-04]\n",
      " [ 4.47014332e-01  6.00314140e-03  4.99551371e-03 -1.98668987e-03\n",
      "   8.89955461e-03 -1.65260714e-02  9.54828411e-03 -7.65149854e-03\n",
      "   2.72668153e-03  4.63870168e-03  3.87394801e-04 -1.77361071e-04\n",
      "   1.17018772e-03  5.77886589e-04]\n",
      " [-1.09365284e-02 -1.33253634e-03  7.02322602e-01 -1.59343481e-02\n",
      "   1.15982890e-02  5.27664414e-03 -1.35872513e-03  2.46296935e-02\n",
      "   6.83007389e-03 -2.97694653e-03 -3.61651089e-03 -4.87497449e-03\n",
      "  -1.34811373e-02 -6.67420216e-04]\n",
      " [-3.29675600e-02  1.65776908e-03  8.16537678e-01 -4.16539237e-02\n",
      "   2.72077471e-02  9.12735984e-03 -1.04362592e-02 -2.78394669e-03\n",
      "   2.06000656e-02 -4.77480181e-02 -1.20288320e-02  2.68830061e-02\n",
      "  -1.47814574e-02  4.65978496e-03]\n",
      " [ 1.22507662e-03 -4.56621498e-03  3.65417451e-03 -2.40189582e-03\n",
      "   2.84919143e-03  8.27675499e-03  3.08690965e-03 -8.54084454e-03\n",
      "   4.89659399e-01  2.98090279e-03  5.74321020e-03  6.03742898e-03\n",
      "   4.43035457e-03  8.03762488e-03]\n",
      " [-8.87412578e-03 -9.58624482e-03 -1.25475265e-02 -1.40328780e-02\n",
      "  -3.49275768e-03 -8.02659243e-03 -5.31078130e-03  7.40969181e-03\n",
      "   3.98855656e-03 -1.26696452e-02  9.01647564e-03  1.97865069e-03\n",
      "  -2.47751828e-03  5.95702827e-01]\n",
      " [-7.05443323e-04 -5.60420007e-03 -1.11638550e-02 -6.87749684e-03\n",
      "  -3.11271101e-03 -5.92090841e-03  2.92459875e-03  2.08698586e-03\n",
      "  -1.31305307e-03 -3.44084203e-03  7.75435846e-03  7.94034451e-03\n",
      "  -8.36551189e-05  5.98079741e-01]\n",
      " [ 1.00423619e-02  1.13416314e-02  8.16885382e-03  2.11846083e-03\n",
      "   2.90127099e-03  4.25878819e-03  7.46766478e-03  9.54809040e-03\n",
      "  -1.15442276e-03  6.91175461e-03  1.97365601e-03 -8.28985870e-03\n",
      "  -9.08443937e-04  4.27530795e-01]\n",
      " [ 6.59070164e-03  8.61521065e-03  8.57389625e-03  4.24680859e-03\n",
      "  -1.37446821e-03  1.16017042e-03  1.15361065e-03  6.37827069e-03\n",
      "   4.34698164e-03  4.11125183e-01  1.54234162e-02  5.69503009e-03\n",
      "   1.47581175e-02 -1.34183001e-03]\n",
      " [ 2.61808932e-03 -4.81481105e-03 -2.55964138e-03 -6.78719580e-03\n",
      "   4.97704744e-03 -8.80642096e-04  2.41197646e-03 -9.01431777e-03\n",
      "   1.26848370e-03  6.35667145e-03 -4.19454975e-03  7.39444047e-03\n",
      "   2.88104638e-04  5.46338618e-01]\n",
      " [-6.13251328e-03 -1.66461840e-02 -6.14734739e-03 -1.02566853e-02\n",
      "   4.22515720e-03 -3.06169526e-03 -9.50141996e-03 -1.51641127e-02\n",
      "   4.64111418e-01  1.78872794e-03  2.74533406e-04  8.27095658e-03\n",
      "  -1.01103969e-02  4.04995400e-03]\n",
      " [ 4.40296829e-01  4.17089462e-03  9.38495900e-03  4.33549285e-04\n",
      "   1.62752718e-03  1.13333147e-02  7.05972314e-04  1.66367181e-03\n",
      "   1.87092274e-03  6.27524406e-03 -4.50023450e-04  3.60301137e-03\n",
      "   1.64431892e-03  8.88089649e-04]\n",
      " [-8.87386501e-04  3.36853534e-01 -4.10488062e-03  4.90143895e-03\n",
      "   8.99601728e-03 -1.23676611e-02  3.99366021e-03  1.03505179e-02\n",
      "  -1.58376992e-04 -3.36366892e-03  8.19638465e-03  7.63292611e-03\n",
      "  -1.63584203e-03 -4.11079358e-03]\n",
      " [ 1.41240954e-02  8.77954811e-03  1.22062918e-02 -4.35554236e-03\n",
      "  -1.02039874e-02 -6.54579420e-03  4.34451312e-01  7.19095021e-03\n",
      "   8.84516537e-03 -2.40572803e-02  5.66279236e-03 -2.91898102e-03\n",
      "   1.28315073e-02  8.14481452e-03]]\n",
      "current score:  [[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.321\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.2     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.188   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.05    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.857\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.4     nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.536\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.66 ]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]]\n",
      "encoding:  [[0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "Number of predicted domains: 49\n",
      "Average improvement: 0.4861100249144496\n",
      "Standard deviation: 0.10994596920996011\n",
      "prediction score:  [[ 5.44200093e-03 -2.98844278e-03 -4.97572310e-03 -1.23346820e-02\n",
      "  -6.96929544e-03 -3.03588598e-03 -3.60432267e-03  5.23550436e-04\n",
      "   6.64802641e-03  4.44633693e-01 -2.14519165e-03  5.40561229e-03\n",
      "  -1.32957101e-03 -5.89047046e-03]\n",
      " [ 4.02133584e-01  8.48206133e-03  1.50974542e-02 -4.77135181e-05\n",
      "  -4.60401177e-04  1.16156098e-02  1.13743171e-02  2.66171992e-03\n",
      "   1.57706439e-04 -1.05922669e-03  6.65910076e-03  1.02416500e-02\n",
      "   1.65443122e-02  9.36279446e-03]\n",
      " [ 1.06269345e-02  1.76286399e-02  1.64444372e-02 -1.07925832e-02\n",
      "  -1.24335885e-02  1.23073114e-02  4.61120218e-01  1.20473616e-02\n",
      "   1.93970054e-02 -1.34138167e-02  1.92175657e-02  5.44349849e-03\n",
      "   1.19431894e-02  2.92192120e-03]\n",
      " [-1.15774572e-03  4.76889551e-01  4.38089017e-03 -2.45081633e-03\n",
      "   7.45763630e-03 -7.29870237e-03 -4.22447920e-03  5.15350699e-03\n",
      "  -4.25702333e-03  1.08867884e-02 -6.30251039e-03 -7.63627142e-03\n",
      "  -1.11811478e-02 -8.03709310e-03]\n",
      " [ 6.50361180e-04 -2.89749354e-03 -6.00577518e-03 -1.60149410e-02\n",
      "   1.29148364e-04 -3.07025225e-03 -8.96956772e-03 -6.08300604e-03\n",
      "   7.09327310e-03  4.59001631e-01 -2.23680828e-02  1.70774758e-04\n",
      "  -6.08527195e-03 -5.83428238e-03]\n",
      " [ 1.25087202e-02  1.53849348e-02  9.66304727e-03  1.71469525e-02\n",
      "   1.07367858e-02  4.22674837e-03  5.86658716e-05  1.09342448e-02\n",
      "   1.12541988e-02  4.18477684e-01  1.01601286e-02  1.31621808e-02\n",
      "   1.76454429e-02 -2.67269090e-04]\n",
      " [-1.14238486e-02 -7.27575272e-03 -5.86133450e-03 -7.19728321e-03\n",
      "  -1.24525279e-03 -6.21152110e-03  5.49612284e-01  1.51770189e-04\n",
      "   1.93797797e-03 -1.72962099e-02 -7.81377219e-03  2.24203691e-02\n",
      "   6.87488727e-03  6.59457408e-03]\n",
      " [-2.08168179e-02 -1.69779882e-02 -5.10979071e-03 -2.08018422e-02\n",
      "  -1.28786713e-02 -1.40963858e-02  2.36765221e-02  1.83183365e-02\n",
      "  -1.16527826e-03 -4.25899029e-03  1.15796728e-02  4.49726731e-03\n",
      "  -3.67745236e-02  6.14168346e-01]\n",
      " [ 4.10453081e-01 -2.21102685e-03  9.58921760e-03 -3.39022279e-03\n",
      "   4.99460846e-03  3.83988954e-04  2.03160197e-03  3.58257443e-03\n",
      "   2.42547691e-03  9.91480798e-03  2.52130348e-03  4.60587442e-04\n",
      "   1.67092541e-03  9.00269486e-04]\n",
      " [ 8.99761170e-03 -1.24774873e-04 -2.31393985e-03 -3.44800949e-03\n",
      "   5.44451177e-04  7.51578948e-04 -1.17436200e-02 -3.70893627e-04\n",
      "   1.01406872e-03 -3.39481980e-03  3.57003696e-03  5.49221516e-01\n",
      "   5.96735720e-03  1.01636536e-03]\n",
      " [-6.33016229e-04 -2.17031687e-03 -7.80377723e-03 -4.47301567e-03\n",
      "   7.26684928e-03  4.67071414e-01 -2.14762241e-03 -3.53058800e-03\n",
      "  -1.31227821e-03 -1.70198530e-02 -6.46776333e-03 -2.46210396e-03\n",
      "  -9.82384942e-03  3.73276044e-03]\n",
      " [ 5.25318384e-01  1.68715417e-03 -6.39595091e-04 -1.67041048e-02\n",
      "   3.27665359e-03 -2.87061501e-02  1.65409446e-02 -7.90040009e-03\n",
      "  -3.95338982e-03 -8.66330415e-03 -1.00171240e-02  5.19242138e-03\n",
      "  -7.01833190e-03 -3.36130941e-03]\n",
      " [ 2.64007598e-03 -4.65116650e-03  4.25618701e-03 -9.57101583e-04\n",
      "   9.25146043e-03  4.09932494e-01 -3.30209732e-03 -1.54659292e-02\n",
      "   5.40101528e-03 -5.80400974e-03  5.71062509e-03  1.52575225e-03\n",
      "  -5.20777609e-03 -2.44968617e-03]\n",
      " [ 8.18401575e-04 -1.07276216e-02  4.59445640e-04 -1.20110810e-03\n",
      "   2.49269605e-03  7.96257704e-03  2.99168378e-03 -3.39538231e-03\n",
      "   4.78343040e-01  1.01003721e-02 -9.76593047e-03  1.33065134e-03\n",
      "   6.80697709e-03  4.62229736e-03]\n",
      " [-6.38693571e-04 -2.45334953e-03  2.35182606e-03 -1.06914788e-02\n",
      "  -3.01540643e-03 -8.81273113e-03 -3.13252211e-03  4.88056779e-01\n",
      "  -3.80751491e-03  4.19427454e-03  1.35007566e-02  1.82358548e-02\n",
      "   9.09283292e-04  1.25187300e-02]\n",
      " [ 6.33580983e-03  2.59427726e-03  3.39302234e-03 -3.35165113e-03\n",
      "  -2.79568136e-03  2.44295783e-03 -5.97311556e-03 -3.60928476e-04\n",
      "   3.85773182e-03  4.22977656e-03 -3.39090684e-03  2.54467130e-03\n",
      "   3.07574481e-01 -7.51323998e-04]\n",
      " [ 3.75878066e-03 -8.10752809e-03  2.86437571e-04 -4.58927080e-02\n",
      "   5.20983100e-01 -1.84745039e-03 -2.46246159e-03 -9.96888988e-03\n",
      "   6.30468130e-03  3.87537479e-03 -1.27655026e-02  2.18529254e-02\n",
      "  -4.40979842e-03 -1.08665805e-02]\n",
      " [ 7.55944848e-03 -4.96774912e-03 -1.56898387e-02 -2.05126926e-02\n",
      "   1.08023584e-02  5.23298979e-03  2.98858434e-03 -5.07526845e-03\n",
      "   2.30632722e-04  3.31930757e-01  2.80228943e-01  2.03200206e-02\n",
      "   5.95570914e-03 -4.63907979e-03]\n",
      " [ 2.09041685e-03 -3.67227942e-03  3.79627012e-03 -4.51580435e-03\n",
      "   4.50931489e-04 -6.40028156e-03  5.25236249e-01 -3.92282382e-03\n",
      "   6.72381371e-03 -8.94669443e-03  3.74787953e-03  1.48844197e-02\n",
      "   2.05576792e-03  6.36321492e-03]\n",
      " [-1.73740685e-02 -1.05911493e-02 -5.19681722e-04 -6.65599853e-03\n",
      "   4.67624515e-03 -2.82690246e-02  5.25917858e-03  5.65682650e-01\n",
      "   4.61022109e-02 -2.92062052e-02  9.70687997e-03 -3.64266336e-04\n",
      "  -2.30049845e-02  2.18604561e-02]\n",
      " [ 4.44220006e-03  3.97897512e-03  4.19898704e-03 -4.22353297e-03\n",
      "  -3.66616249e-03 -3.87391984e-03  3.27212363e-03  4.11092862e-03\n",
      "   6.65950775e-03  3.51517648e-03  1.86443888e-03 -1.92523003e-03\n",
      "   6.73227198e-03  4.24423248e-01]\n",
      " [ 1.30903721e-02  3.21006030e-03  7.03178905e-03  5.97619265e-03\n",
      "   3.20622325e-03  2.14869110e-03 -8.53557885e-03  6.59139827e-03\n",
      "   3.18473577e-03  4.41188663e-01  1.25181461e-02  2.53797323e-03\n",
      "   9.62048769e-03 -2.32865429e-03]\n",
      " [ 1.10925511e-02 -3.91565263e-03  4.43236623e-03 -1.67950764e-02\n",
      "  -9.11918283e-03 -2.70986487e-03 -4.31942940e-03  3.04700881e-01\n",
      "   8.69377702e-03  4.20331955e-03  7.74988998e-03  1.42125115e-02\n",
      "  -2.53951619e-03  1.33386031e-02]\n",
      " [ 5.93997538e-03 -1.41662583e-02 -9.72846150e-03 -1.32038668e-02\n",
      "   1.59508362e-02  8.58215382e-04  4.46472317e-03  7.39995390e-04\n",
      "   9.98537987e-03  3.04471105e-01  6.50783062e-01  2.95232981e-03\n",
      "  -8.99855280e-04  1.87713951e-02]\n",
      " [-1.32019073e-03 -2.17592120e-02 -1.20115578e-02 -4.63021547e-03\n",
      "   2.27693468e-03  5.43454243e-03 -1.18222088e-03 -7.27580115e-03\n",
      "   4.80845839e-01  1.58720836e-02 -6.80029998e-03  6.16285205e-03\n",
      "  -6.89871982e-03  5.43038175e-03]\n",
      " [ 1.79604664e-02  9.79091227e-03 -9.63466242e-04  3.74695659e-03\n",
      "   6.12169504e-04  6.07674103e-03 -6.10886514e-03  3.72003764e-04\n",
      "   4.26887542e-01  2.89919227e-03  7.82238320e-04  1.43836662e-02\n",
      "   2.07782015e-02 -1.14000663e-02]\n",
      " [-1.68852508e-04  1.32020637e-02  8.11367761e-03 -6.95465505e-03\n",
      "  -1.19443163e-02  4.81953425e-03  4.52970535e-01  5.43835387e-03\n",
      "   5.41955233e-05 -1.58957690e-02  3.16326972e-03 -4.38079238e-03\n",
      "   1.44378264e-02 -6.50351960e-03]\n",
      " [-6.17843866e-03  7.13100076e-01  3.43830790e-03 -3.86695266e-02\n",
      "  -1.97033994e-02 -9.88441287e-04 -1.01264492e-02 -2.26236917e-02\n",
      "   3.31667811e-03 -2.52309479e-02 -3.85422483e-02 -6.16014004e-03\n",
      "   1.02376984e-02 -4.92593460e-03]\n",
      " [ 4.29017842e-03 -1.62233561e-02 -6.08715601e-03 -1.71346888e-02\n",
      "  -8.72382522e-03 -4.34282934e-04 -2.92308629e-04 -4.99907695e-03\n",
      "  -2.89545953e-03  4.01698053e-03 -1.77518856e-02  9.63671505e-03\n",
      "   6.87014520e-01 -1.02884257e-02]\n",
      " [ 1.04672015e-02  1.33422166e-02  1.47974472e-02  6.85657561e-03\n",
      "   6.65453821e-03 -1.40791968e-03  8.61306489e-03  5.96746802e-03\n",
      "   1.74332410e-03 -1.33187473e-02  8.06347467e-04  1.07105821e-02\n",
      "   1.99633408e-02  4.83099997e-01]\n",
      " [ 1.11157522e-02  2.26985663e-03  6.13667846e-01  8.18611681e-03\n",
      "   6.05462492e-03  4.24992712e-03  2.06237286e-03  7.65210390e-03\n",
      "   3.30484658e-03 -2.53123045e-03 -2.27803513e-02 -1.08271390e-02\n",
      "   4.60803788e-03  5.11418097e-04]\n",
      " [ 5.89698553e-04  1.89928710e-03 -8.39576684e-03 -1.67384744e-03\n",
      "  -3.06118280e-03  7.34605826e-04  4.22931284e-01 -5.63857704e-03\n",
      "   1.01289824e-02  1.20123327e-02 -9.96261649e-03  1.58203170e-02\n",
      "  -5.55866398e-04 -3.46096791e-02]\n",
      " [ 7.99872726e-03  3.83748114e-03  5.05653024e-03 -1.36009529e-02\n",
      "   5.24879992e-03  1.12960106e-02 -3.53671610e-04 -1.34652667e-03\n",
      "   7.54781812e-03  3.40783089e-01  4.99679059e-01 -5.82479686e-03\n",
      "   1.31312404e-02 -2.55666673e-05]\n",
      " [ 3.14117372e-01  9.27899778e-03  1.56563409e-02  6.10113144e-04\n",
      "  -6.06358051e-04 -5.41146100e-03  4.18817252e-03  7.85763189e-03\n",
      "   1.13318115e-02  3.61640751e-03  2.37946846e-02 -1.98867172e-03\n",
      "   6.86595403e-03  9.66940075e-03]\n",
      " [ 6.49521500e-03 -1.87829882e-03  5.29566966e-03  4.39788282e-01\n",
      "   1.82549357e-02 -1.81883504e-03  3.99023294e-03 -1.01700611e-03\n",
      "   5.45795262e-03  1.38865784e-02 -2.58292677e-03  2.42339075e-03\n",
      "   5.53438719e-03  5.14188036e-03]\n",
      " [ 5.58274239e-03  7.88040459e-03  6.53133914e-03  6.41245395e-03\n",
      "   1.08718127e-03  6.07410213e-03 -1.71996653e-03  1.02149099e-02\n",
      "  -1.36380643e-03  4.00029629e-01  1.52081018e-02  1.50504783e-02\n",
      "   2.55182721e-02 -1.88078731e-04]\n",
      " [ 4.47014332e-01  6.00314140e-03  4.99551371e-03 -1.98668987e-03\n",
      "   8.89955461e-03 -1.65260714e-02  9.54828411e-03 -7.65149854e-03\n",
      "   2.72668153e-03  4.63870168e-03  3.87394801e-04 -1.77361071e-04\n",
      "   1.17018772e-03  5.77886589e-04]\n",
      " [-1.09365284e-02 -1.33253634e-03  7.02322602e-01 -1.59343481e-02\n",
      "   1.15982890e-02  5.27664414e-03 -1.35872513e-03  2.46296935e-02\n",
      "   6.83007389e-03 -2.97694653e-03 -3.61651089e-03 -4.87497449e-03\n",
      "  -1.34811373e-02 -6.67420216e-04]\n",
      " [-3.29675600e-02  1.65776908e-03  8.16537678e-01 -4.16539237e-02\n",
      "   2.72077471e-02  9.12735984e-03 -1.04362592e-02 -2.78394669e-03\n",
      "   2.06000656e-02 -4.77480181e-02 -1.20288320e-02  2.68830061e-02\n",
      "  -1.47814574e-02  4.65978496e-03]\n",
      " [ 1.22507662e-03 -4.56621498e-03  3.65417451e-03 -2.40189582e-03\n",
      "   2.84919143e-03  8.27675499e-03  3.08690965e-03 -8.54084454e-03\n",
      "   4.89659399e-01  2.98090279e-03  5.74321020e-03  6.03742898e-03\n",
      "   4.43035457e-03  8.03762488e-03]\n",
      " [-8.87412578e-03 -9.58624482e-03 -1.25475265e-02 -1.40328780e-02\n",
      "  -3.49275768e-03 -8.02659243e-03 -5.31078130e-03  7.40969181e-03\n",
      "   3.98855656e-03 -1.26696452e-02  9.01647564e-03  1.97865069e-03\n",
      "  -2.47751828e-03  5.95702827e-01]\n",
      " [-7.05443323e-04 -5.60420007e-03 -1.11638550e-02 -6.87749684e-03\n",
      "  -3.11271101e-03 -5.92090841e-03  2.92459875e-03  2.08698586e-03\n",
      "  -1.31305307e-03 -3.44084203e-03  7.75435846e-03  7.94034451e-03\n",
      "  -8.36551189e-05  5.98079741e-01]\n",
      " [ 1.00423619e-02  1.13416314e-02  8.16885382e-03  2.11846083e-03\n",
      "   2.90127099e-03  4.25878819e-03  7.46766478e-03  9.54809040e-03\n",
      "  -1.15442276e-03  6.91175461e-03  1.97365601e-03 -8.28985870e-03\n",
      "  -9.08443937e-04  4.27530795e-01]\n",
      " [ 6.59070164e-03  8.61521065e-03  8.57389625e-03  4.24680859e-03\n",
      "  -1.37446821e-03  1.16017042e-03  1.15361065e-03  6.37827069e-03\n",
      "   4.34698164e-03  4.11125183e-01  1.54234162e-02  5.69503009e-03\n",
      "   1.47581175e-02 -1.34183001e-03]\n",
      " [ 2.61808932e-03 -4.81481105e-03 -2.55964138e-03 -6.78719580e-03\n",
      "   4.97704744e-03 -8.80642096e-04  2.41197646e-03 -9.01431777e-03\n",
      "   1.26848370e-03  6.35667145e-03 -4.19454975e-03  7.39444047e-03\n",
      "   2.88104638e-04  5.46338618e-01]\n",
      " [-6.13251328e-03 -1.66461840e-02 -6.14734739e-03 -1.02566853e-02\n",
      "   4.22515720e-03 -3.06169526e-03 -9.50141996e-03 -1.51641127e-02\n",
      "   4.64111418e-01  1.78872794e-03  2.74533406e-04  8.27095658e-03\n",
      "  -1.01103969e-02  4.04995400e-03]\n",
      " [ 4.40296829e-01  4.17089462e-03  9.38495900e-03  4.33549285e-04\n",
      "   1.62752718e-03  1.13333147e-02  7.05972314e-04  1.66367181e-03\n",
      "   1.87092274e-03  6.27524406e-03 -4.50023450e-04  3.60301137e-03\n",
      "   1.64431892e-03  8.88089649e-04]\n",
      " [-8.87386501e-04  3.36853534e-01 -4.10488062e-03  4.90143895e-03\n",
      "   8.99601728e-03 -1.23676611e-02  3.99366021e-03  1.03505179e-02\n",
      "  -1.58376992e-04 -3.36366892e-03  8.19638465e-03  7.63292611e-03\n",
      "  -1.63584203e-03 -4.11079358e-03]\n",
      " [ 1.41240954e-02  8.77954811e-03  1.22062918e-02 -4.35554236e-03\n",
      "  -1.02039874e-02 -6.54579420e-03  4.34451312e-01  7.19095021e-03\n",
      "   8.84516537e-03 -2.40572803e-02  5.66279236e-03 -2.91898102e-03\n",
      "   1.28315073e-02  8.14481452e-03]]\n",
      "current score:  [[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.321\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.2     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.188   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.05    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.857\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.4     nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.536\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.66 ]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]]\n",
      "encoding:  [[0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "Number of predicted domains: 49\n",
      "Average improvement: 0.4861100249144496\n",
      "Standard deviation: 0.10994596920996011\n",
      "----best----\n",
      "***nonrepeat***\n",
      "prediction score:  [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.68318987 0.        ]\n",
      " [0.         0.         0.5732168  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.46112022 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.66241068 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.6882295  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.50533223]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.88600022 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.94616562 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.69633085 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.68575913 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.73555064 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.77678889 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.6410445  0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.6735602  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.77488589 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.59849972 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.78392476 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.53146106]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.74817377 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.92869318 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.49543566\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.63143355 0.        ]\n",
      " [0.         0.5442     0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.65078306 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.64443982 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.50055283 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.50502402]\n",
      " [0.         0.         0.80401713 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.68701452 0.        ]\n",
      " [0.         0.         0.55044216 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.61366785 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.69331229 0.        ]\n",
      " [0.         0.         0.68237096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.48921743 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.60218638 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.56459469 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.71861702 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.85590643 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.92455524 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.70924133 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.89958054 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.87434536 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.67211246 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.50187343]\n",
      " [0.         0.         0.65843308 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.81999016 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.67325974 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.47356731\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.43445131 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.321\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.2     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.188   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.05    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.857\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.4     nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.536\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.66 ]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]]\n",
      "encoding:  [[0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "Number of predicted domains: 49\n",
      "Average improvement: 0.6705094581964065\n",
      "Standard deviation: 0.13498856346456112\n",
      "prediction score:  [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.68318987 0.        ]\n",
      " [0.         0.         0.5732168  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.46112022 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.66241068 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.6882295  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.50533223]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.88600022 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.94616562 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.69633085 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.68575913 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.73555064 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.77678889 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.6410445  0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.6735602  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.77488589 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.59849972 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.78392476 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.53146106]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.74817377 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.92869318 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.49543566\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.63143355 0.        ]\n",
      " [0.         0.5442     0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.65078306 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.64443982 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.50055283 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.50502402]\n",
      " [0.         0.         0.80401713 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.68701452 0.        ]\n",
      " [0.         0.         0.55044216 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.61366785 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.69331229 0.        ]\n",
      " [0.         0.         0.68237096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.48921743 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.60218638 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.56459469 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.71861702 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.85590643 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.92455524 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.70924133 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.89958054 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.87434536 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.67211246 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.50187343]\n",
      " [0.         0.         0.65843308 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.81999016 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.67325974 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.47356731\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.43445131 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "current score:  [[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan 0.21    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.4     nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan 0.35    nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.28    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan 0.35    nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.061   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.143   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.507\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan 0.75    nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.503   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.321\n",
      "    nan   nan]\n",
      " [  nan 0.38    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.821\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.357\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.2     nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [0.314   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.767]\n",
      " [  nan   nan   nan 0.188   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.05    nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.857\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.133]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan 0.357   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.4     nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 0.5     nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.536\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.684   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan 1.      nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "  0.273   nan]\n",
      " [  nan   nan   nan   nan   nan 0.737   nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
      "    nan 0.66 ]\n",
      " [  nan   nan   nan   nan   nan   nan   nan 0.317   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]\n",
      " [  nan   nan   nan   nan   nan 0.      nan   nan   nan   nan   nan   nan\n",
      "    nan   nan]]\n",
      "encoding:  [[0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "Number of predicted domains: 49\n",
      "Average improvement: 0.6705094581964065\n",
      "Standard deviation: 0.13498856346456112\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 14):\n",
    "    print(\"========= %d missing\" % n)\n",
    "    print(\"----ground truth----\")\n",
    "    # ground truth\n",
    "    temp_nonrepeat = ground_truth_test_data_n[n][ground_truth_test_data_n[n].repeat == False]\n",
    "    if len(temp_nonrepeat) != 0:\n",
    "        nonrepeat_ground_truth_avg.append(overall_avg_improvement_with_std(temp_nonrepeat)[0])\n",
    "        nonrepeat_ground_truth_std.append(overall_avg_improvement_with_std(temp_nonrepeat)[1])\n",
    "    else:\n",
    "        nonrepeat_ground_truth_avg.append(0)\n",
    "        nonrepeat_ground_truth_std.append(0)\n",
    "\n",
    "    print(\"----random----\")\n",
    "    # random\n",
    "    temp_nonrepeat = random_test_data_n[n][random_test_data_n[n].repeat == False]\n",
    "    print(\"***nonrepeat***\")\n",
    "    if len(temp_nonrepeat) != 0:\n",
    "        nonrepeat_random_avg.append(overall_avg_improvement_with_std(temp_nonrepeat)[0])\n",
    "        nonrepeat_random_std.append(overall_avg_improvement_with_std(temp_nonrepeat)[1])\n",
    "    else:\n",
    "        nonrepeat_random_avg.append(0)\n",
    "        nonrepeat_random_std.appen(0)\n",
    "    \n",
    "    print(\"----best----\")\n",
    "    # best\n",
    "    temp_nonrepeat = best_test_data_n[n][best_test_data_n[n].repeat == False]\n",
    "    print(\"***nonrepeat***\")\n",
    "    if len(temp_nonrepeat) != 0:\n",
    "        nonrepeat_best_avg.append(overall_avg_improvement_with_std(temp_nonrepeat)[0])\n",
    "        nonrepeat_best_std.append(overall_avg_improvement_with_std(temp_nonrepeat)[0])\n",
    "    else:\n",
    "        nonrepeat_best_avg.append(0)\n",
    "        nonrepeat_best_std.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_by_nan_count_nonzero_only(prediction_matrix, ground_truth_df, metric=\"mae\"):\n",
    "    \"\"\"\n",
    "    Plots error per number of NaNs in score columns with error bars, considering only nonzero values.\n",
    "\n",
    "    Parameters:\n",
    "    prediction_matrix (np.ndarray): 2D NumPy array of predicted values.\n",
    "    ground_truth_df (pd.DataFrame): DataFrame containing ground truth and score columns.\n",
    "    metric (str): \"mae\" for Mean Absolute Error, \"mse\" for Mean Squared Error.\n",
    "    \"\"\"\n",
    "    global score_columns  # List of score column names\n",
    "    global target_columns  # List of target columns\n",
    "    global encoding_columns  # List of encoding columns\n",
    "\n",
    "    mean_errors_list = []\n",
    "    error_std_list = []\n",
    "    nan_counts = list(range(1, 14))  # Checking sessions with 1 to 13 NaNs\n",
    "\n",
    "    for n in nan_counts:\n",
    "        filtered_df = filter_n_missing(ground_truth_df, n)  # Filter by NaN count\n",
    "        \n",
    "        if filtered_df.empty:  # Skip if no data\n",
    "            mean_errors_list.append(np.nan)\n",
    "            error_std_list.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Correctly map DataFrame indices to NumPy indices\n",
    "        valid_indices = ground_truth_df.index.get_indexer(filtered_df.index)\n",
    "        valid_indices = valid_indices[valid_indices >= 0]  # Ensure only valid indices are used\n",
    "\n",
    "        # Extract matrices\n",
    "        ground_truth_matrix = np.nan_to_num(filtered_df[target_columns].to_numpy() * filtered_df[encoding_columns].to_numpy())\n",
    "        filtered_prediction_matrix = prediction_matrix[valid_indices] * filtered_df[encoding_columns].to_numpy()\n",
    "\n",
    "        # Ensure matrices have the same shape\n",
    "        assert filtered_prediction_matrix.shape == ground_truth_matrix.shape, \"Mismatch in matrix shapes\"\n",
    "\n",
    "        # Compute improvement (errors)\n",
    "        errors = np.abs(filtered_prediction_matrix - ground_truth_matrix) if metric == \"mae\" else (filtered_prediction_matrix - ground_truth_matrix) ** 2\n",
    "\n",
    "        # Extract only nonzero errors\n",
    "        nonzero_errors = errors[errors != 0]\n",
    "\n",
    "        if len(nonzero_errors) == 0:\n",
    "            mean_errors_list.append(np.nan)\n",
    "            error_std_list.append(np.nan)\n",
    "        else:\n",
    "            mean_errors_list.append(np.mean(nonzero_errors))\n",
    "            error_std_list.append(np.std(nonzero_errors, ddof=1))  # Sample standard deviation\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    mean_errors = np.array(mean_errors_list)\n",
    "    error_std = np.array(error_std_list)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(nan_counts, mean_errors, yerr=error_std, fmt='-o', capsize=5, color='b', alpha=0.7)\n",
    "    plt.xlabel(\"Number of NaNs in Score Columns\")\n",
    "    plt.ylabel(\"Error (Nonzero Only)\")\n",
    "    plt.title(f\"{metric.upper()} by Missing Domains (Nonzero Only)\")\n",
    "    plt.xticks(nan_counts)\n",
    "    plt.ylim(-np.nanmax(error_std) * 1.1, np.nanmax(mean_errors + error_std) * 1.1 if not np.isnan(np.nanmax(mean_errors)) else 1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== from create_model_data ======\n",
      "data_scores:  [[0.526 0.474 0.02  ... 0.919 1.    0.   ]\n",
      " [0.526 0.474 0.11  ... 0.356 0.2   0.8  ]\n",
      " [1.    0.    1.    ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.214 0.786 0.    ... 0.    0.533 0.467]\n",
      " [0.779 0.221 0.91  ... 0.135 0.    0.   ]\n",
      " [1.    0.    1.    ... 0.454 1.    0.   ]]\n",
      "target:  [[0.    0.    0.    ... 0.    0.081 0.   ]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.    0.      nan]\n",
      " ...\n",
      " [0.      nan   nan ...   nan   nan 0.522]\n",
      " [0.    0.9   0.    ... 0.    0.      nan]\n",
      " [0.989 0.    0.    ... 0.    0.546 0.   ]]\n",
      "encoding:  [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]]\n",
      "data put in model tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9190, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3560, 0.2000, 0.8000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5330, 0.4670],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.1350, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000,  ..., 0.4540, 1.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x_tmp, y_tmp = create_model_data(ground_truth_test_data_final) # create scores with missing indicators and target\n",
    "rows, cols = y_tmp.shape\n",
    "encoding = ground_truth_test_data_final[encoding_columns].to_numpy()\n",
    "print(\"encoding: \", encoding)\n",
    "x_train_tmp = add_encoding(x_tmp, encoding)\n",
    "print(\"data put in model\", x_train_tmp)\n",
    "ground_truth_prediction = predict(model, x_train_tmp, torch.from_numpy(y_tmp).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error_by_nan_count_nonzero_only(ground_truth_prediction, ground_truth_test_data_final, metric=\"mae\")  # Use \"mse\" for Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\x15\\x88\\xbe\\xdfe_M\\xb4L\\x81.o\\x89\\xa9\\xf6\\xcf{\\xa3\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00\\xa1\\x00\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd\\x00\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2\\x00\\xc3\\x00\\xc4\\x00\\xc5\\x13\\x01\\x13\\x02\\x13\\x03\\x13\\x04\\x13\\x05\\xc0\\x01\\xc0\\x02\\xc0\\x03\\xc0\\x04\\xc0\\x05', b\"\\xc0\\x07\\xc0\\x08\\xc0\\t\\xc0\\n\\xc0\\x0b\\xc0\\x0c\\xc0\\r\\xc0\\x0e\\xc0\\x0f\\xc0\\x10\\xc0\\x11\\xc0\\x12\\xc0\\x13\\xc0\\x14\\xc0\\x15\\xc0\\x16\\xc0\\x17\\xc0\\x18\\xc0\\x19\\xc0#\\xc0$\\xc0%\\xc0&\\xc0'\\xc0(\\xc0)\\xc0*\\xc0+\\xc0,\\xc0-\\xc0.\\xc0/\\xc00\\xc01\\xc02\\xc0r\\xc0s\\xc0t\\xc0u\\xc0v\\xc0w\\xc0x\\xc0y\\xc0z\\xc0{\\xc0|\\xc0}\\xc0~\\xc0\\x7f\\xc0\\x80\\xc0\\x81\\xc0\\x82\\xc0\\x83\\xc0\\x84\\xc0\\x85\\xc0\\x86\\xc0\\x87\\xc0\\x88\\xc0\\x89\\xc0\\x8a\\xc0\\x8b\\xc0\\x8c\\xc0\\x8d\\xc0\\x8e\\xc0\\x8f\\xc0\\x90\\xc0\\x91\\xc0\\x92\\xc0\\x93\\xc0\\x94\\xc0\\x95\\xc0\\x96\\xc0\\x97\\xc0\\x98\\xc0\\x99\\xc0\\x9a\\xc0\\x9b\\xcc\\xa8\\xcc\\xa9\\xcc\\xaa\\xcc\\xab\\xcc\\xac\\xcc\\xad\\xcc\\xae\\x02\\x00\\x01\\x00J\\x00\\n\\x00\\n\\x00\\x08\\x00\\x17\\x00\\x19\\x00\\x18\\x00\\x16\\x00\\x0b\\x00\\x04\"]\n",
      "Bad pipe message: %s [b'\\x01\\x02']\n",
      "Bad pipe message: %s [b'\\x8e\\x96;}\\xfd\\xe2\\xac\\xffz\\xaf\\xce\\xcam-\\xad\\x94\\xe1\\xaf\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B']\n",
      "Bad pipe message: %s [b'\\xff`r\\xf7-\\x17\\x19g\\xc3[\\xdbr\\xa2<vRGb\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00\\x0e\\x00\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15\\x00\\x16\\x00\\x17\\x00\\x18\\x00\\x19\\x00\\x1a\\x00\\x1b\\x00/\\x000\\x001\\x002\\x003\\x004\\x005\\x006\\x007\\x008\\x009\\x00:\\x00;\\x00<\\x00=\\x00>\\x00?\\x00@\\x00A\\x00B\\x00C\\x00D\\x00E\\x00F\\x00g\\x00h\\x00i\\x00j\\x00k\\x00l\\x00m\\x00\\x84\\x00\\x85\\x00\\x86\\x00\\x87\\x00\\x88\\x00\\x89\\x00\\x96\\x00\\x97\\x00\\x98\\x00\\x99\\x00\\x9a\\x00\\x9b\\x00\\x9c\\x00\\x9d\\x00\\x9e\\x00\\x9f\\x00\\xa0\\x00']\n",
      "Bad pipe message: %s [b\"\\xa2\\x00\\xa3\\x00\\xa4\\x00\\xa5\\x00\\xa6\\x00\\xa7\\x00\\xba\\x00\\xbb\\x00\\xbc\\x00\\xbd\\x00\\xbe\\x00\\xbf\\x00\\xc0\\x00\\xc1\\x00\\xc2\\x00\\xc3\\x00\\xc4\\x00\\xc5\\x13\\x01\\x13\\x02\\x13\\x03\\x13\\x04\\x13\\x05\\xc0\\x01\\xc0\\x02\\xc0\\x03\\xc0\\x04\\xc0\\x05\\xc0\\x06\\xc0\\x07\\xc0\\x08\\xc0\\t\\xc0\\n\\xc0\\x0b\\xc0\\x0c\\xc0\\r\\xc0\\x0e\\xc0\\x0f\\xc0\\x10\\xc0\\x11\\xc0\\x12\\xc0\\x13\\xc0\\x14\\xc0\\x15\\xc0\\x16\\xc0\\x17\\xc0\\x18\\xc0\\x19\\xc0#\\xc0$\\xc0%\\xc0&\\xc0'\\xc0(\\xc0)\\xc0*\\xc0+\\xc0,\\xc0-\\xc0.\\xc0/\\xc00\\xc01\\xc02\\xc0r\\xc0s\\xc0t\\xc0u\\xc0v\\xc0w\\xc0x\\xc0y\\xc0z\\xc0{\\xc0|\\xc0}\\xc0~\\xc0\\x7f\\xc0\\x80\\xc0\\x81\\xc0\"]\n",
      "Bad pipe message: %s [b'\\xe4\\xf1\\xc4\\xe53l#\\x17\\xa2\\xd4\\x8dEz\\xc2\\xd7Bmh\\x00\\x01|\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00\\x04\\x00\\x05\\x00\\x06\\x00\\x07\\x00\\x08\\x00', b'\\n\\x00\\x0b\\x00\\x0c\\x00\\r\\x00']\n",
      "Bad pipe message: %s [b'\\x0f\\x00\\x10\\x00\\x11\\x00\\x12\\x00\\x13\\x00\\x14\\x00\\x15']\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, 14), nonrepeat_best_avg, label=\"nonrepeat best\")\n",
    "plt.plot(range(1, 14), nonrepeat_random_avg, label=\"nonrepeat random\")\n",
    "plt.plot(range(1, 14), nonrepeat_ground_truth_avg, label=\"nonrepeat ground truth\")\n",
    "plt.xlabel(\"number of unknown domains\")\n",
    "plt.ylabel(\"average improvement in score\")\n",
    "plt.title(\"nonrepeats\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define x-axis values (number of unknown domains)\n",
    "x_values = range(1, 14)\n",
    "\n",
    "# Plot with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.errorbar(x_values, nonrepeat_best_avg, yerr=nonrepeat_best_std, label=\"Nonrepeat Best\", fmt='-o', capsize=5)\n",
    "plt.errorbar(x_values, nonrepeat_random_avg, yerr=nonrepeat_random_std, label=\"Nonrepeat Random\", fmt='-o', capsize=5)\n",
    "plt.errorbar(x_values, nonrepeat_ground_truth_avg, yerr=nonrepeat_ground_truth_std, label=\"Nonrepeat Ground Truth\", fmt='-o', capsize=5)\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Number of Unknown Domains\")\n",
    "plt.ylabel(\"Average Improvement in Score\")\n",
    "plt.title(\"Nonrepeats with Error Bars\")\n",
    "\n",
    "# Legend and Grid\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>domain 1 encoding</th>\n",
       "      <th>domain 2 encoding</th>\n",
       "      <th>domain 3 encoding</th>\n",
       "      <th>domain 4 encoding</th>\n",
       "      <th>domain 5 encoding</th>\n",
       "      <th>domain 6 encoding</th>\n",
       "      <th>domain 7 encoding</th>\n",
       "      <th>domain 8 encoding</th>\n",
       "      <th>domain 9 encoding</th>\n",
       "      <th>...</th>\n",
       "      <th>domain 7 target</th>\n",
       "      <th>domain 8 target</th>\n",
       "      <th>domain 9 target</th>\n",
       "      <th>domain 10 target</th>\n",
       "      <th>domain 11 target</th>\n",
       "      <th>domain 12 target</th>\n",
       "      <th>domain 13 target</th>\n",
       "      <th>domain 14 target</th>\n",
       "      <th>repeat</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4134494</th>\n",
       "      <td>240716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483269</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>-0.005556</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>-0.002984</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>-0.006323</td>\n",
       "      <td>False</td>\n",
       "      <td>1.573090e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647759</th>\n",
       "      <td>167488.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468794</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.012663</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>-0.008881</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>False</td>\n",
       "      <td>1.556046e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835628</th>\n",
       "      <td>136434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620679</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>-0.015128</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>False</td>\n",
       "      <td>1.670880e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577152</th>\n",
       "      <td>125246.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>-0.012851</td>\n",
       "      <td>-0.002015</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>0.551326</td>\n",
       "      <td>False</td>\n",
       "      <td>1.534870e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412577</th>\n",
       "      <td>43440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>0.421774</td>\n",
       "      <td>False</td>\n",
       "      <td>1.641832e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101413</th>\n",
       "      <td>235924.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006762</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>-0.004509</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>-0.008405</td>\n",
       "      <td>0.578331</td>\n",
       "      <td>False</td>\n",
       "      <td>1.558703e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253013</th>\n",
       "      <td>27901.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002801</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>-0.004931</td>\n",
       "      <td>-0.002695</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.539889</td>\n",
       "      <td>False</td>\n",
       "      <td>1.611782e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756847</th>\n",
       "      <td>220057.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450820</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>-0.007214</td>\n",
       "      <td>-0.009580</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>-0.007242</td>\n",
       "      <td>False</td>\n",
       "      <td>1.592850e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593647</th>\n",
       "      <td>274123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.579057</td>\n",
       "      <td>-0.004920</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.001716</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>-0.004762</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>False</td>\n",
       "      <td>1.580932e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357949</th>\n",
       "      <td>330496.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.570018</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>-0.010571</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>False</td>\n",
       "      <td>1.684770e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14721 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         patient_id  domain 1 encoding  domain 2 encoding  domain 3 encoding  \\\n",
       "4134494    240716.0                  0                  0                  0   \n",
       "2647759    167488.0                  0                  0                  0   \n",
       "1835628    136434.0                  0                  0                  0   \n",
       "1577152    125246.0                  0                  0                  0   \n",
       "412577      43440.0                  0                  0                  0   \n",
       "...             ...                ...                ...                ...   \n",
       "4101413    235924.0                  0                  0                  0   \n",
       "253013      27901.0                  0                  0                  0   \n",
       "3756847    220057.0                  0                  0                  0   \n",
       "4593647    274123.0                  0                  0                  0   \n",
       "5357949    330496.0                  0                  0                  0   \n",
       "\n",
       "         domain 4 encoding  domain 5 encoding  domain 6 encoding  \\\n",
       "4134494                  0                  0                  0   \n",
       "2647759                  0                  0                  0   \n",
       "1835628                  0                  0                  0   \n",
       "1577152                  0                  0                  0   \n",
       "412577                   0                  0                  0   \n",
       "...                    ...                ...                ...   \n",
       "4101413                  0                  0                  0   \n",
       "253013                   0                  0                  0   \n",
       "3756847                  0                  0                  0   \n",
       "4593647                  0                  0                  0   \n",
       "5357949                  0                  0                  0   \n",
       "\n",
       "         domain 7 encoding  domain 8 encoding  domain 9 encoding  ...  \\\n",
       "4134494                  1                  0                  0  ...   \n",
       "2647759                  1                  0                  0  ...   \n",
       "1835628                  1                  0                  0  ...   \n",
       "1577152                  0                  0                  0  ...   \n",
       "412577                   0                  0                  0  ...   \n",
       "...                    ...                ...                ...  ...   \n",
       "4101413                  0                  0                  0  ...   \n",
       "253013                   0                  0                  0  ...   \n",
       "3756847                  1                  0                  0  ...   \n",
       "4593647                  0                  1                  0  ...   \n",
       "5357949                  0                  1                  0  ...   \n",
       "\n",
       "         domain 7 target  domain 8 target  domain 9 target  domain 10 target  \\\n",
       "4134494         0.483269         0.002313        -0.005556          0.010413   \n",
       "2647759         0.468794         0.003601         0.009121          0.012663   \n",
       "1835628         0.620679         0.009639         0.008209          0.004231   \n",
       "1577152         0.003574        -0.004446         0.006550         -0.012851   \n",
       "412577          0.000558         0.004790         0.000841          0.007093   \n",
       "...                  ...              ...              ...               ...   \n",
       "4101413         0.006762        -0.001832         0.002907          0.015948   \n",
       "253013         -0.002801        -0.003289         0.008562          0.001872   \n",
       "3756847         0.450820         0.004205        -0.007214         -0.009580   \n",
       "4593647         0.004977         0.579057        -0.004920         -0.000470   \n",
       "5357949         0.004004         0.570018        -0.003148          0.000369   \n",
       "\n",
       "         domain 11 target  domain 12 target  domain 13 target  \\\n",
       "4134494         -0.002984          0.008233          0.002245   \n",
       "2647759          0.004357         -0.008881          0.001076   \n",
       "1835628          0.007506         -0.015128          0.001937   \n",
       "1577152         -0.002015          0.009141         -0.004564   \n",
       "412577           0.003841          0.001799         -0.003482   \n",
       "...                   ...               ...               ...   \n",
       "4101413         -0.004509          0.003326         -0.008405   \n",
       "253013          -0.004931         -0.002695          0.005506   \n",
       "3756847          0.001148          0.002242          0.010741   \n",
       "4593647         -0.001716          0.001357         -0.004762   \n",
       "5357949          0.006165          0.016993         -0.010571   \n",
       "\n",
       "         domain 14 target  repeat    start_time  \n",
       "4134494         -0.006323   False  1.573090e+09  \n",
       "2647759          0.001043   False  1.556046e+09  \n",
       "1835628          0.004721   False  1.670880e+09  \n",
       "1577152          0.551326   False  1.534870e+09  \n",
       "412577           0.421774   False  1.641832e+09  \n",
       "...                   ...     ...           ...  \n",
       "4101413          0.578331   False  1.558703e+09  \n",
       "253013           0.539889   False  1.611782e+09  \n",
       "3756847         -0.007242   False  1.592850e+09  \n",
       "4593647          0.001628   False  1.580932e+09  \n",
       "5357949         -0.005344   False  1.684770e+09  \n",
       "\n",
       "[14721 rows x 45 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_data_n[2][random_test_data_n[2].repeat == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>domain 1 encoding</th>\n",
       "      <th>domain 2 encoding</th>\n",
       "      <th>domain 3 encoding</th>\n",
       "      <th>domain 4 encoding</th>\n",
       "      <th>domain 5 encoding</th>\n",
       "      <th>domain 6 encoding</th>\n",
       "      <th>domain 7 encoding</th>\n",
       "      <th>domain 8 encoding</th>\n",
       "      <th>domain 9 encoding</th>\n",
       "      <th>...</th>\n",
       "      <th>domain 7 target</th>\n",
       "      <th>domain 8 target</th>\n",
       "      <th>domain 9 target</th>\n",
       "      <th>domain 10 target</th>\n",
       "      <th>domain 11 target</th>\n",
       "      <th>domain 12 target</th>\n",
       "      <th>domain 13 target</th>\n",
       "      <th>domain 14 target</th>\n",
       "      <th>repeat</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4134494</th>\n",
       "      <td>240716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.573090e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647759</th>\n",
       "      <td>167488.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.556046e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835628</th>\n",
       "      <td>136434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.670880e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577152</th>\n",
       "      <td>125246.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551326</td>\n",
       "      <td>False</td>\n",
       "      <td>1.534870e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412577</th>\n",
       "      <td>43440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421774</td>\n",
       "      <td>False</td>\n",
       "      <td>1.641832e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101413</th>\n",
       "      <td>235924.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578331</td>\n",
       "      <td>False</td>\n",
       "      <td>1.558703e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253013</th>\n",
       "      <td>27901.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539889</td>\n",
       "      <td>False</td>\n",
       "      <td>1.611782e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756847</th>\n",
       "      <td>220057.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.592850e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593647</th>\n",
       "      <td>274123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.580932e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357949</th>\n",
       "      <td>330496.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.684770e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14721 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         patient_id  domain 1 encoding  domain 2 encoding  domain 3 encoding  \\\n",
       "4134494    240716.0                  0                  0                  0   \n",
       "2647759    167488.0                  0                  0                  0   \n",
       "1835628    136434.0                  0                  0                  0   \n",
       "1577152    125246.0                  0                  0                  0   \n",
       "412577      43440.0                  0                  0                  0   \n",
       "...             ...                ...                ...                ...   \n",
       "4101413    235924.0                  0                  0                  0   \n",
       "253013      27901.0                  0                  0                  0   \n",
       "3756847    220057.0                  0                  0                  0   \n",
       "4593647    274123.0                  0                  0                  0   \n",
       "5357949    330496.0                  0                  0                  0   \n",
       "\n",
       "         domain 4 encoding  domain 5 encoding  domain 6 encoding  \\\n",
       "4134494                  0                  0                  0   \n",
       "2647759                  0                  0                  0   \n",
       "1835628                  0                  0                  0   \n",
       "1577152                  0                  0                  0   \n",
       "412577                   0                  0                  0   \n",
       "...                    ...                ...                ...   \n",
       "4101413                  0                  0                  0   \n",
       "253013                   0                  0                  0   \n",
       "3756847                  0                  0                  0   \n",
       "4593647                  0                  0                  0   \n",
       "5357949                  0                  0                  0   \n",
       "\n",
       "         domain 7 encoding  domain 8 encoding  domain 9 encoding  ...  \\\n",
       "4134494                  1                  0                  0  ...   \n",
       "2647759                  1                  0                  0  ...   \n",
       "1835628                  1                  0                  0  ...   \n",
       "1577152                  0                  0                  0  ...   \n",
       "412577                   0                  0                  0  ...   \n",
       "...                    ...                ...                ...  ...   \n",
       "4101413                  0                  0                  0  ...   \n",
       "253013                   0                  0                  0  ...   \n",
       "3756847                  0                  1                  0  ...   \n",
       "4593647                  0                  1                  0  ...   \n",
       "5357949                  0                  1                  0  ...   \n",
       "\n",
       "         domain 7 target  domain 8 target  domain 9 target  domain 10 target  \\\n",
       "4134494         0.483269         0.000000              0.0               0.0   \n",
       "2647759         0.468794         0.000000              0.0               0.0   \n",
       "1835628         0.620679         0.000000              0.0               0.0   \n",
       "1577152         0.000000         0.000000              0.0               0.0   \n",
       "412577          0.000000         0.000000              0.0               0.0   \n",
       "...                  ...              ...              ...               ...   \n",
       "4101413         0.000000         0.000000              0.0               0.0   \n",
       "253013          0.000000         0.000000              0.0               0.0   \n",
       "3756847         0.000000         0.529294              0.0               0.0   \n",
       "4593647         0.000000         0.579057              0.0               0.0   \n",
       "5357949         0.000000         0.570018              0.0               0.0   \n",
       "\n",
       "         domain 11 target  domain 12 target  domain 13 target  \\\n",
       "4134494               0.0               0.0               0.0   \n",
       "2647759               0.0               0.0               0.0   \n",
       "1835628               0.0               0.0               0.0   \n",
       "1577152               0.0               0.0               0.0   \n",
       "412577                0.0               0.0               0.0   \n",
       "...                   ...               ...               ...   \n",
       "4101413               0.0               0.0               0.0   \n",
       "253013                0.0               0.0               0.0   \n",
       "3756847               0.0               0.0               0.0   \n",
       "4593647               0.0               0.0               0.0   \n",
       "5357949               0.0               0.0               0.0   \n",
       "\n",
       "         domain 14 target  repeat    start_time  \n",
       "4134494          0.000000   False  1.573090e+09  \n",
       "2647759          0.000000   False  1.556046e+09  \n",
       "1835628          0.000000   False  1.670880e+09  \n",
       "1577152          0.551326   False  1.534870e+09  \n",
       "412577           0.421774   False  1.641832e+09  \n",
       "...                   ...     ...           ...  \n",
       "4101413          0.578331   False  1.558703e+09  \n",
       "253013           0.539889   False  1.611782e+09  \n",
       "3756847          0.000000   False  1.592850e+09  \n",
       "4593647          0.000000   False  1.580932e+09  \n",
       "5357949          0.000000   False  1.684770e+09  \n",
       "\n",
       "[14721 rows x 45 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test_data_n[2][best_test_data_n[2].repeat == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain 1 encoding</th>\n",
       "      <th>domain 2 encoding</th>\n",
       "      <th>domain 3 encoding</th>\n",
       "      <th>domain 4 encoding</th>\n",
       "      <th>domain 5 encoding</th>\n",
       "      <th>domain 6 encoding</th>\n",
       "      <th>domain 7 encoding</th>\n",
       "      <th>domain 8 encoding</th>\n",
       "      <th>domain 9 encoding</th>\n",
       "      <th>domain 10 encoding</th>\n",
       "      <th>domain 11 encoding</th>\n",
       "      <th>domain 12 encoding</th>\n",
       "      <th>domain 13 encoding</th>\n",
       "      <th>domain 14 encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5198989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain 1 encoding  domain 2 encoding  domain 3 encoding  \\\n",
       "5198989                0.0                0.0                0.0   \n",
       "\n",
       "         domain 4 encoding  domain 5 encoding  domain 6 encoding  \\\n",
       "5198989                0.0                0.0                0.0   \n",
       "\n",
       "         domain 7 encoding  domain 8 encoding  domain 9 encoding  \\\n",
       "5198989                0.0                0.0                0.0   \n",
       "\n",
       "         domain 10 encoding  domain 11 encoding  domain 12 encoding  \\\n",
       "5198989                 0.0                 0.0                 0.0   \n",
       "\n",
       "         domain 13 encoding  domain 14 encoding  \n",
       "5198989                 1.0                 0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[encoding_columns].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 14):\n",
    "    temp_repeat = ground_truth_test_data_n[n][ground_truth_test_data_n[n].repeat == True]\n",
    "    temp_nonrepeat = ground_truth_test_data_n[n][ground_truth_test_data_n[n].repeat == False]\n",
    "    if len(temp_repeat) != 0:\n",
    "        ids.append(temp_repeat.index[0])\n",
    "    if len(temp_nonrepeat) != 0:\n",
    "        ids.append(temp_nonrepeat.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5198989,\n",
       " 3511929,\n",
       " 4134494,\n",
       " 217809,\n",
       " 108777,\n",
       " 4313511,\n",
       " 4184746,\n",
       " 3694380,\n",
       " 2051828,\n",
       " 5151980,\n",
       " 5447081,\n",
       " 3640067,\n",
       " 4856734,\n",
       " 5313162,\n",
       " 4203617,\n",
       " 1813788,\n",
       " 3485634,\n",
       " 4876271,\n",
       " 2213497,\n",
       " 5025916,\n",
       " 274747,\n",
       " 4621927,\n",
       " 3888559,\n",
       " 2592816,\n",
       " 4325322,\n",
       " 3673390]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
