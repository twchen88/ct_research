{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages and helper functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from helper import *\n",
    "from connection import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"data/test_dataset.csv\")\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.897966, 0.102034, 0.057928, 0.942072],\n",
       "       [0.423429, 0.576571, 0.753434, 0.246566],\n",
       "       [0.652121, 0.347879, 0.851987, 0.148013],\n",
       "       ...,\n",
       "       [0.833881, 0.166119, 0.354543, 0.645457],\n",
       "       [0.269787, 0.730213, 0.219943, 0.780057],\n",
       "       [0.501157, 0.498843, 0.775908, 0.224092]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l, w) = data.shape\n",
    "x_train = np.zeros((l, w*2))\n",
    "for i in range(l):\n",
    "    for d in range(w):\n",
    "        p = data[i, d]\n",
    "        # update output array\n",
    "        if p == 0: \n",
    "            x_train[i, d*2] = p # 0 score\n",
    "            x_train[i, d*2+1] = p # missing indicator\n",
    "        else:\n",
    "            x_train[i, d*2] = p # score\n",
    "            x_train[i, d*2+1] = 1-p # 1-score\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mse(y_true, y_pred):\n",
    "    ground = []\n",
    "    n_domain = 2\n",
    "    for row in range(len(y_true)):\n",
    "        new_row = []\n",
    "        for i in range(n_domain):\n",
    "            # if missing, then modify target\n",
    "            if y_true[row, i*2] == 0 and y_true[row, i*2+1] == 0:\n",
    "                new_row.append(y_pred[row, i*2])\n",
    "                new_row.append(y_pred[row, i*2+1])\n",
    "            else:\n",
    "                new_row.append(y_true[row, i*2])\n",
    "                new_row.append(y_true[row, i*2+1])\n",
    "        ground.append(new_row)\n",
    "\n",
    "    ground = tf.convert_to_tensor(ground)\n",
    "\n",
    "    return tf.reduce_mean(tf.math.squared_difference(y_pred, ground)) # check how the gradient works in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build autoencoder\n",
    "from keras import layers\n",
    "\n",
    "n_domain = w # number of domains\n",
    "\n",
    "encoding_dim = 1\n",
    "## input n_domain * 2 to represent missing values\n",
    "input_layer = keras.Input(shape=(n_domain * 2,))\n",
    "encode_layer = layers.Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "decode_layer = layers.Dense(n_domain * 2, activation=\"sigmoid\")(encode_layer)\n",
    "\n",
    "autoencoder = keras.Model(input_layer, decode_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build encoder and decoder model\n",
    "encoder = keras.Model(input_layer, encode_layer)\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decode_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decode_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile with optimizer and loss function\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test = train_test_split(x_train, test_size=0.20, random_state=42)\n",
    "x_train, x_val = train_test_split(x_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = np.array([[0, 0, 1, 0]])\n",
    "test_case.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test_encoded = encoder.predict(test_case, batch_size=256)\n",
    "x_decoded = decoder.predict(x_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_mse(test_case, x_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1018 - val_loss: 0.0939\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.0932\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1004 - val_loss: 0.0927\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0997 - val_loss: 0.0922\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0991 - val_loss: 0.0918\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0986 - val_loss: 0.0913\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.0909\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0977 - val_loss: 0.0906\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0973 - val_loss: 0.0902\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0969 - val_loss: 0.0899\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0966 - val_loss: 0.0896\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0962 - val_loss: 0.0894\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0959 - val_loss: 0.0891\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0889\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0954 - val_loss: 0.0887\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0952 - val_loss: 0.0885\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0950 - val_loss: 0.0883\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.0881\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0946 - val_loss: 0.0879\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0877\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.0876\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.0874\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.0872\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0936 - val_loss: 0.0870\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.0869\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0867\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.0865\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0862\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.0860\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.0858\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.0855\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0917 - val_loss: 0.0853\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0850\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0847\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0909 - val_loss: 0.0844\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.0841\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0838\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.0835\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0832\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0828\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0888 - val_loss: 0.0825\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.0821\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.0817\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0814\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0810\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0806\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0802\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.0799\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0795\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0854 - val_loss: 0.0791\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0787\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0783\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.0779\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0775\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0834 - val_loss: 0.0771\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0767\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0763\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0759\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0755\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0751\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0747\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0807 - val_loss: 0.0743\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.0739\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0736\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0732\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0728\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0724\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0720\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0717\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.0713\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.0709\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.0705\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0702\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0698\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0694\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0691\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0752 - val_loss: 0.0687\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0683\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0680\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0742 - val_loss: 0.0676\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0673\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0670\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0666\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0663\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0660\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0657\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0719 - val_loss: 0.0653\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0716 - val_loss: 0.0650\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0647\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0644\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0641\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0637\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.0634\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0698 - val_loss: 0.0631\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0628\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0625\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0622\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0620\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0617\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0614\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0611\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0609\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0606\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.0604\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.0601\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0598\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0664 - val_loss: 0.0596\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0594\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.0591\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.0588\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0586\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0584\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0581\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0647 - val_loss: 0.0579\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0577\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0574\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0572\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0639 - val_loss: 0.0570\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0568\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0566\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.0564\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0562\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0560\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0558\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.0556\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0624 - val_loss: 0.0555\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0553\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0620 - val_loss: 0.0551\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0549\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0548\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0546\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0545\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0543\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.0542\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0540\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0539\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0537\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0536\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0534\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0533\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0531\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0530\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0528\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0527\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0526\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0525\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0524\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0523\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0522\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0520\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0519\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0518\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0517\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0516\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0515\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0514\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0513\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0512\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0511\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0510\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0509\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0508\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0508\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0507\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0506\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0505\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0504\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0503\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.0503\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0570 - val_loss: 0.0502\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0501\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0501\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0500\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0499\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0499\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0498\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0498\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0497\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0497\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.0496\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0495\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0494\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0494\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0493\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.0492\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0491\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0491\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0490\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0490\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0489\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.0488\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0488\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0487\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0487\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0486\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0486\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0485\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0485\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0484\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0484\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0484\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0483\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0483\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0482\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0482\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0482\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0482\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0481\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0481\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0480\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0480\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0479\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0479\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0479\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0478\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0478\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0478\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0477\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0477\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0477\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0476\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0476\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0475\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0475\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0475\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0475\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0475\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0475\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0474\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0474\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0474\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.0474\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0473\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0473\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0473\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0473\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0473\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0472\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0473\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.0473\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0472\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0472\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0471\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.0471\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0471\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0471\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0471\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0471\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0471\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0470\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0470\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0470\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0469\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0469\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0469\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0469\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0469\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0469\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0469\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0469\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0469\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0469\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0468\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0468\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.0468\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0468\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0468\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0467\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0467\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0467\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0466\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0466\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0467\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0466\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0466\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0465\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0465\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0465\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0465\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0465\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0465\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0465\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0465\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0465\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0465\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0464\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0464\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0464\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0464\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0464\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0464\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0464\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0464\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0464\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0464\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0464\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0464\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0464\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0464\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0464\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.0463\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0463\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0463\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0462\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0462\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0462\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0462\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0463\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0463\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0463\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0463\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0463\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0462\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0462\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0462\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0462\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0461\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0461\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0461\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0461\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0461\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0461\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0460\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0460\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0460\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0460\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0459\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0459\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0459\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.0460\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0459\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0459\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0459\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0459\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0460\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0459\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0459\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0459\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0459\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0458\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0458\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0458\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0459\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0458\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0459\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0458\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0458\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0458\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0457\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0458\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0458\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0457\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0457\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0457\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0457\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0457\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0457\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0456\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0456\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0457\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0456\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0457\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0457\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0456\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.0456\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0456\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0456\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0456\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0456\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0455\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0456\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0455\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0455\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0454\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0454\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0455\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0455\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0455\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0455\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0455\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0455\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0455\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0453\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0453\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0453\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0453\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0453\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0453\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0452\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0452\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0452\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0452\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0453\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0452\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0451\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0451\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0451\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0451\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0451\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0452\n"
     ]
    }
   ],
   "source": [
    "output = autoencoder.fit(x_train, x_train,\n",
    "                epochs=500,\n",
    "                validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 636us/step\n"
     ]
    }
   ],
   "source": [
    "x_decoded = decoder.predict(x_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.209749, 0.208109, 0.113383, 0.103197])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(x_test, x_decoded, multioutput=\"raw_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15860926322166863"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(x_test, x_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfHklEQVR4nO3deXxU1f3/8dedmcxM9hASEpaw7wJBAdm0WI0GN8TaipTWvf60WrVU+xVbFfXbYqu4W7Fat29rpdKKC0pFEETFhU1l3/dsQJLJOpOZub8/7mQgECCQZbK8n4/HfcydO2fufO6VwrvnnHuvYZqmiYiIiEgbYot0ASIiIiJNTQFIRERE2hwFIBEREWlzFIBERESkzVEAEhERkTZHAUhERETaHAUgERERaXMUgERERKTNUQASERGRNkcBSERavB07dmAYBq+++upJf3fx4sUYhsHixYuP2+7VV1/FMAx27NhxSjWKSPOiACQiIiJtjgKQiIiItDkKQCIiItLmKACJSL1Nnz4dwzDYtGkTP/vZz0hMTCQ1NZX77rsP0zTZvXs3l112GQkJCaSnpzNz5syj9pGfn88NN9xAWloabrebzMxMXnvttaPaFRUVce2115KYmEhSUhLXXHMNRUVFtda1YcMGfvzjH5OcnIzb7Wb48OG8++67DXrsf/nLXzjttNNwuVx06tSJW2+99ah6Nm/ezBVXXEF6ejput5suXbpw1VVXUVxcHG6zYMECzjrrLJKSkoiLi6Nfv37ce++9DVqriBziiHQBItJ6TJo0iQEDBvDII48wb948/vd//5fk5GReeOEFzj33XP70pz/xj3/8g7vuuosRI0bwgx/8AICKigrOOecctmzZwm233UaPHj146623uPbaaykqKuKOO+4AwDRNLrvsMj777DNuvvlmBgwYwNtvv80111xzVC1r165l7NixdO7cmXvuuYfY2Fj+9a9/MXHiRP79739z+eWX1/t4p0+fzoMPPkhWVha33HILGzdu5Pnnn+ebb77h888/JyoqCp/PR3Z2Nl6vl1/96lekp6ezd+9e3n//fYqKikhMTGTt2rVccsklDBkyhIceegiXy8WWLVv4/PPP612jiByDKSJSTw888IAJmDfddFN4m9/vN7t06WIahmE+8sgj4e2FhYVmdHS0ec0114S3PfnkkyZg/v3vfw9v8/l85ujRo824uDjT4/GYpmmac+fONQHzz3/+c43fOfvss03AfOWVV8LbzzvvPHPw4MFmZWVleFswGDTHjBlj9unTJ7ztk08+MQHzk08+Oe4xvvLKKyZgbt++3TRN08zPzzedTqd5wQUXmIFAINzu2WefNQHz5ZdfNk3TNFetWmUC5ltvvXXMfT/xxBMmYBYUFBy3BhFpOBoCE5EGc+ONN4bX7XY7w4cPxzRNbrjhhvD2pKQk+vXrx7Zt28LbPvjgA9LT05k8eXJ4W1RUFLfffjulpaUsWbIk3M7hcHDLLbfU+J1f/epXNeo4ePAgixYt4sorr6SkpIT9+/ezf/9+Dhw4QHZ2Nps3b2bv3r31OtaPP/4Yn8/HnXfeic126K/SX/ziFyQkJDBv3jwAEhMTAfjvf/9LeXl5rftKSkoC4J133iEYDNarLhGpGwUgEWkwXbt2rfE+MTERt9tNSkrKUdsLCwvD73fu3EmfPn1qBAmAAQMGhD+vfu3YsSNxcXE12vXr16/G+y1btmCaJvfddx+pqak1lgceeACw5hzVR3VNR/620+mkZ8+e4c979OjB1KlTeemll0hJSSE7O5vnnnuuxvyfSZMmMXbsWG688UbS0tK46qqr+Ne//qUwJNKINAdIRBqM3W6v0zaw5vM0lurgcNddd5GdnV1rm969ezfa7x9p5syZXHvttbzzzjt89NFH3H777cyYMYMvv/ySLl26EB0dzaeffsonn3zCvHnzmD9/PrNnz+bcc8/lo48+OuY5FJFTpx4gEYm4bt26sXnz5qN6PDZs2BD+vPo1JyeH0tLSGu02btxY433Pnj0BaxgtKyur1iU+Pr7eNdf22z6fj+3bt4c/rzZ48GB+//vf8+mnn7J06VL27t3LrFmzwp/bbDbOO+88Hn/8cdatW8cf/vAHFi1axCeffFKvOkWkdgpAIhJxF110Ebm5ucyePTu8ze/388wzzxAXF8e4cePC7fx+P88//3y4XSAQ4Jlnnqmxvw4dOnDOOefwwgsvkJOTc9TvFRQU1LvmrKwsnE4nTz/9dI3erL/97W8UFxdz8cUXA+DxePD7/TW+O3jwYGw2G16vF7DmLB1p6NChAOE2ItKwNAQmIhF300038cILL3DttdeyYsUKunfvzpw5c/j888958sknw701l156KWPHjuWee+5hx44dDBw4kP/85z815tNUe+655zjrrLMYPHgwv/jFL+jZsyd5eXksW7aMPXv28O2339ar5tTUVKZNm8aDDz7I+PHjmTBhAhs3buQvf/kLI0aM4Gc/+xkAixYt4rbbbuMnP/kJffv2xe/383//93/Y7XauuOIKAB566CE+/fRTLr74Yrp160Z+fj5/+ctf6NKlC2eddVa96hSR2ikAiUjERUdHs3jxYu655x5ee+01PB4P/fr145VXXuHaa68Nt7PZbLz77rvceeed/P3vf8cwDCZMmMDMmTM5/fTTa+xz4MCBLF++nAcffJBXX32VAwcO0KFDB04//XTuv//+Bql7+vTppKam8uyzz/LrX/+a5ORkbrrpJv74xz8SFRUFQGZmJtnZ2bz33nvs3buXmJgYMjMz+fDDDxk1ahQAEyZMYMeOHbz88svs37+flJQUxo0bx4MPPhi+ikxEGpZhNuZMRBEREZFmSHOAREREpM1RABIREZE2RwFIRERE2hwFIBEREWlzFIBERESkzVEAEhERkTZH9wGqRTAYZN++fcTHx2MYRqTLERERkTowTZOSkhI6dep01MOVj6QAVIt9+/aRkZER6TJERETkFOzevZsuXboct40CUC2qb7u/e/duEhISIlyNiIiI1IXH4yEjI6NODztWAKpF9bBXQkKCApCIiEgLU5fpK5oELSIiIm2OApCIiIi0OQpAIiIi0uZoDlA9BAIBqqqqIl1Gi+R0Ok94iaKIiEhjUQA6BaZpkpubS1FRUaRLabFsNhs9evTA6XRGuhQREWmDFIBOQXX46dChAzExMbpZ4kmqvtFkTk4OXbt21fkTEZEmpwB0kgKBQDj8tG/fPtLltFipqans27cPv99PVFRUpMsREZE2RpMwTlL1nJ+YmJgIV9KyVQ99BQKBCFciIiJtkQLQKdKwTf3o/ImISCQpAImIiEibowAkp6R79+48+eSTkS5DRETklGgSdBtyzjnnMHTo0AYJLt988w2xsbH1L0pERCQCFICakD8YxOcPEh1lb5ZzYEzTJBAI4HCc+I9FampqE1QkIiLSODQE1oQ8FVVsyS9lY14Jew6Wc7DMS2VVANM0G/23r732WpYsWcJTTz2FYRgYhsGrr76KYRh8+OGHDBs2DJfLxWeffcbWrVu57LLLSEtLIy4ujhEjRvDxxx/X2N+RQ2CGYfDSSy9x+eWXExMTQ58+fXj33Xcb/bhEREROhXqAGoBpmlRUnfhy7pJKPz5/kMqqAJ6KQ4/QsBsGbqcdt8OOK8qGy2EtDvvx8+nJ9CQ99dRTbNq0iUGDBvHQQw8BsHbtWgDuueceHnvsMXr27Em7du3YvXs3F110EX/4wx9wuVy8/vrrXHrppWzcuJGuXbse8zcefPBB/vznP/Poo4/yzDPPMGXKFHbu3ElycnKdahQREWkqCkANoKIqwMD7/9vkv7vuoWxinHX7T5iYmIjT6SQmJob09HQANmzYAMBDDz3E+eefH26bnJxMZmZm+P3DDz/M22+/zbvvvsttt912zN+49tprmTx5MgB//OMfefrpp/n6668ZP378SR+biIhIY1IAasHW53iId0XhsBtE2W047AYOW/Wrgb16MazXYxk+fHiN96WlpUyfPp158+aRk5OD3++noqKCXbt2HbeeIUOGhNdjY2NJSEggPz+/fgcpIiLSCBSAGkB0lJ11D2WfuGHxPigvOGyDAa5EcCeAOx5sh/5zBIMmXn8An9/EF7AmT/sCQaoCQaoCJqZp4rAZVPoD4D/xTxtAuc9PYZmPLfml2G0G+Z5KAMoCdvaXesOh6de/nsqiRQt59M+P0qdPb2JiYvjxj3+Mz+c77m8c+UgLwzAIBoMnLk5ERKSJRXwS9HPPPUf37t1xu92MHDmSr7/++rjt33rrLfr374/b7Wbw4MF88MEHNT4vLS3ltttuo0uXLkRHRzNw4EBmzZrVmIeAYRjEOB0nXlK7EtN5EDHtuxATHUtMlEFM0ENM+R5iDm4gxrODGN8BYsxK4pw22se56ZgUTbf2sfRJi+e0TokMzWjH8G7tOKNrO/qlJ9AjJZaMdjGkJ7pJiXORFB1FnMtBdJQdp92GLTRHyATsDic+v59yn5+SyipKvFZyyi/xsq+ogl0Hy9m+v4wlSz/jwsuvos/IczHad6OQGLZt30FxRRU79pex62A5gaCJp6KKPE8l+0u8AJR5/ZRW+qnw+fH5rTlRTTHBW0RE5GRFtAdo9uzZTJ06lVmzZjFy5EiefPJJsrOz2bhxIx06dDiq/RdffMHkyZOZMWMGl1xyCW+88QYTJ05k5cqVDBo0CICpU6eyaNEi/v73v9O9e3c++ugjfvnLX9KpUycmTJjQ1Id4NIcL4tKsxVcOlYVQWQx+L/hKrKWa3QWuOHDFgzPO6iEKXcHlsBs47OCOsp/wJ4OmSSBoMrBvL779dhWUFhAdHUu7aOs/f7vYKOKiowgETfxBk+49e7Fo/nuMO388hgHPPfpHgkGr98lTWRXeZ6nXT16oFwmgoMTLtv2lNX53T2EFa/cVYzcMbIcNxwX9PorKfby0dBv2KBfxbgfxbgcJ7ijiQutxLgfxrihiXfYTTggXERE5GRENQI8//ji/+MUvuO666wCYNWsW8+bN4+WXX+aee+45qv1TTz3F+PHjufvuuwFrcu6CBQt49tlnw708X3zxBddccw3nnHMOADfddBMvvPACX3/9dfMIQIdzxlhLQmeoqgRvMfjKrCXoh4AXyr1QfsBqb9jA7rQWhwscbmuxOcBmtxbj6KBgMwxsdoP/+e3dXHPNNYw6I5OKigpeeeUVADonxZCUdOimhi/+5Rmuv/56rr08m5SUFH79m7sIeMuJdzno0i6aQBBsNoM4l4PkWCfVo1zW1Wt2AkGTwGE9P4GgSQATDrtQzvRXUeoN8M+vc9hbcuIr6KKj7FYwcjlqBKRYp4NYl4MYlz28Huu0E+NyEOeyE+OsbmO32jmtdrbjzIkSEZHWL2IByOfzsWLFCqZNmxbeZrPZyMrKYtmyZbV+Z9myZUydOrXGtuzsbObOnRt+P2bMGN59912uv/56OnXqxOLFi9m0aRNPPPHEMWvxer14vd7we4/Hc4pHVQ9RbmupFqiCqnLwlliLvxLMoPXqrwTvMfZji7ICks1mrTtc1mJ30bdnd5Z9/pkVkkJDY9dee+1Ru+jevTuLFi2qse3Xd9xe4/3unTtrvD9yqMs0TYoKiwiEep+CoVAUCJoETZPKShuVbgeXn96ZnNKgNSRX6afUay3V771+K11VVAWoqApQUHKsAz850VH2w0KRFZoSoqO4cFA6Px7WpVneqFJERBpOxALQ/v37CQQCpKWl1dielpYWvjz7SLm5ubW2z83NDb9/5plnuOmmm+jSpQsOhwObzcaLL77ID37wg2PWMmPGDB588MF6HE0jsEeBPRHcidZ7MwgBH/h9Vs+Q3wf+CmvoLBgAM9SLEqyyluMyDusxqu49OqwXyRZl/X71pGybIzz8BkY4PIWZQagOQKFwZd1sEWwY1DZKV2k3KY6O4rZze+B2u49uEOLzB625RV4/nsoqSg8LSZ5KP+VeP2W+AGVea25TmddaL/P5KfcFKPX6KfcGKPP5KfP6CYbKrA5U+0trTuxetCGfqoDJT0ce+35HIiLS8rW6q8CeeeYZvvzyS9599126devGp59+yq233kqnTp3Iysqq9TvTpk2r0bPk8XjIyMhoqpLrxrAdGvKqjWmGhs18Vu+RGbBe/V6rxyjgs4ISprUE/dZyzK6k4xZzKAxhWgHo8DrtLitAYVo/Z9hq9DoB4PNbQ3sfzoLK/FCdXqsmM2gtwSqc3hKcDjftnHEQFW3tI7w/W6gWm9W+otA67qSukJYW7vnC4QKbA7OymEBpAcHS/QQrS0M9UkGMymKq7NF8VDmQ6ft/yJJN+QpAIiKtXMQCUEpKCna7nby8vBrb8/LywjfqO1J6evpx21dUVHDvvffy9ttvc/HFFwPWvWlWr17NY489dswA5HK5cLlc9T2kyDKMUK9R1LHbmKGwUt1jFPRb60F/6H1oPVB1KESBtc7hQ1zmoR6fo34jGOqZqjh+vX7Tmuu0dSGU7j6ZIz2xvStq3Wxw/D/wV7EcZ9Q2nsy5q2HrERGRZidiAcjpdDJs2DAWLlzIxIkTAQgGgyxcuPCYdxsePXo0Cxcu5M477wxvW7BgAaNHjwagqqqKqqoqbLaaE4HtdrvuRwOh3pPQMNfJMKsDT/Cw9dCrgTWMZtisbYEqa4guUHWol6i6R+fwEOWtgmg//OC3YA+GempCE7zDPTx26wo4f4UVlqoqDoW46p6n6veGAe4k67VwB5QfDA0ZVlo9S4EqiE6CmPYQkwzO+EO9Us44KFgPH0/nMtvnPFF4BaXes4lztboOUhERCYno3/BTp07lmmuuYfjw4Zx55pk8+eSTlJWVha8Ku/rqq+ncuTMzZswA4I477mDcuHHMnDmTiy++mDfffJPly5fz17/+FYCEhATGjRvH3XffTXR0NN26dWPJkiW8/vrrPP744xE7zhbPqB7yqsOl6DZ7zcncx+KoBFcJ9L8SjjMHqMn0Gw/bl2LfupAf25eyMXciw7rpGWYiIq1VRAPQpEmTKCgo4P777yc3N5ehQ4cyf/788ETnXbt21ejNGTNmDG+88Qa///3vuffee+nTpw9z584N3wMI4M0332TatGlMmTKFgwcP0q1bN/7whz9w8803N/nxSQvT42zYupAuRj4bcksUgEREWjHD1K16j+LxeEhMTKS4uJiEhIQan1VWVrJ9+3Z69Dj+1UtyfM3yPH47G96+iS8CA1lxzuv86rw+ka5IREROwvH+/T6Sbq8rUi2hEwBpRmH4MSEiItI6KQCJVAsFoI7GQTzlx3/wq4iItGwKQFJn3bt358knn4x0GY0nFIBiDC/+8uIIFyMiIo1JAUikWlQ0vijrzttRZfsiXIyIiDQmBSCRw3hjrJtquipyT9BSRERaMgWgNuKvf/0rnTp1OuqGkJdddhnXX389W7du5bLLLiMtLY24uDhGjBjBxx9/HKFqIycQ1xGAOG9+hCsREZHGpADUEMzQYx2aejmJOxj85Cc/4cCBA3zyySfhbQcPHmT+/PlMmTKF0tJSLrroIhYuXMiqVasYP348l156Kbt27WqMM9ZsGbEpALiqiiJbiIiINCrd678hVJXDHzs1/e/euw+csXVq2q5dOy688ELeeOMNzjvvPADmzJlDSkoKP/zhD7HZbGRmZobbP/zww7z99tu8++67x3w0SWtkj7buG2H3l0e4EhERaUzqAWpDpkyZwr///W+8XusJ8P/4xz+46qqrsNlslJaWctdddzFgwACSkpKIi4tj/fr1ba4HKCrGmgQdHSynsioQ4WpERKSxqAeoIUTFWL0xkfjdk3DppZdimibz5s1jxIgRLF26lCeeeAKAu+66iwULFvDYY4/Ru3dvoqOj+fGPf4zP17buhxMV6gGKowJPZRXuqJN8cKyIiLQICkANwTDqPBQVSW63mx/96Ef84x//YMuWLfTr148zzjgDgM8//5xrr72Wyy+/HIDS0lJ27NgRwWojw+aOByDWqKSk0k+H+AgXJCIijUIBqI2ZMmUKl1xyCWvXruVnP/tZeHufPn34z3/+w6WXXophGNx3331HXTHWJrisxBNHBZ6KqggXIyIijUVzgNqYc889l+TkZDZu3MhPf/rT8PbHH3+cdu3aMWbMGC699FKys7PDvUNtijMOgDijAk+lngcmItJaqQeojbHZbOzbd/R8pe7du7No0aIa22699dYa79vEkFioByiWSvZVqgdIRKS1Ug+QyOFch3qAyn26CkxEpLVSABI5nPPQHKAKBSARkVZLAUjkcIdNgi73ag6QiEhrpQAkcrjQEJjdMPFVlkW4GBERaSwKQKfIPInncMnRmu35i4rFxAAgUOmJcDEiItJYFIBOUlRUFADl5XpWVH1U32Habm9md1q22fDZrTtsBytLIlyMiIg0Fl0Gf5LsdjtJSUnk5+cDEBMTg2EYEa6qZQkGgxQUFBATE4PD0fz+CFY5YnEFysCrACQi0lo1v399WoD09HSAcAiSk2ez2ejatWuzDI8BRyx4UQASEWnFFIBOgWEYdOzYkQ4dOlBVpZvlnQqn04nN1jxHYANR1nPdbFWlEa5EREQaiwJQPdjt9uY3h0XqzYyyrgQzfLoKTESktWqe/xdcJJKc1iRom18T3UVEWisFIJEjOa0hMLsCkIhIq6UAJHIEWygA2fyVEa5EREQaiwKQyBFsLmsIzBGoiHAlIiLSWBSARI7gcFk9QFHBiuZ7x2oREakXBSCRI9jd1lVgbtOLLxCMcDUiItIYFIBEjhAVCkAxhpdybyDC1YiISGNQABI5gj00BygaL+VVCkAiIq2RApDIkUJ3go7GS4XPH+FiRESkMSgAiRwpdCPEGMNLuU89QCIirZECkMiRokIBCAUgEZHWSgFI5EihGyG68VKhACQi0iopAIkcKSoa0BCYiEhrpgAkcqTDJkGXaxK0iEirpAAkciTnoTlAugpMRKR1UgASOVJoErTDCFLp1QNRRURaIwUgkSOFAhBAVWVZBAsREZHGogAkciSHk4BhByBQWRrhYkREpDEoAInUwm+zrgQLqAdIRKRVUgASqYXfbgWgoFcBSESkNVIAEqlFwGHNAwr4FIBERFojBSCRWgQdbmvFVx7ZQkREpFEoAInUwgxdCWZUKQCJiLRGCkAitVAAEhFp3RSARGoTehyGLaAAJCLSGikAidTC5goFIH9FhCsREZHGoAAkUgtb6HlgjoACkIhIa6QAJFKL6h6gqICeBSYi0hopAInUwuGOA8BlVuLzByNcjYiINDQFIJFaONxWD1AMXip8gQhXIyIiDU0BSKQWjtAQWLThpbzKH+FqRESkoSkAidQmdB+gaLyUedUDJCLS2igAidTGeWgIrMyrHiARkdZGAUikNqEeoBhDAUhEpDVSABKpTeg+QG58lCoAiYi0OgpAIrWp7gGikjKfApCISGujACRSm+pJ0IaXUk2CFhFpdRSARGrjrO4B0hwgEZHWSAFIpDahp8FH46OssirCxYiISENTABKpTagHyGaYVFaWR7gYERFpaApAIrUJzQECqKooiWAhIiLSGJpFAHruuefo3r07brebkSNH8vXXXx+3/VtvvUX//v1xu90MHjyYDz74oMbnhmHUujz66KONeRjSmtjsBGxOAALesggXIyIiDS3iAWj27NlMnTqVBx54gJUrV5KZmUl2djb5+fm1tv/iiy+YPHkyN9xwA6tWrWLixIlMnDiRNWvWhNvk5OTUWF5++WUMw+CKK65oqsOSVsBvt3qBgpXqARIRaW0M0zTNSBYwcuRIRowYwbPPPgtAMBgkIyODX/3qV9xzzz1HtZ80aRJlZWW8//774W2jRo1i6NChzJo1q9bfmDhxIiUlJSxcuLBONXk8HhITEykuLiYhIeEUjkpag/I/n0ZM+R5+l/w4f7j9hkiXIyIiJ3Ay/35HtAfI5/OxYsUKsrKywttsNhtZWVksW7as1u8sW7asRnuA7OzsY7bPy8tj3rx53HCD/gGTkxN0xlsrPvUAiYi0No5I/vj+/fsJBAKkpaXV2J6WlsaGDRtq/U5ubm6t7XNzc2tt/9prrxEfH8+PfvSjY9bh9Xrxer3h9x6Pp66HIK2Y6bICkN1XGuFKRESkoUV8DlBje/nll5kyZQput/uYbWbMmEFiYmJ4ycjIaMIKpbky3Fb3qaNKAUhEpLWJaABKSUnBbreTl5dXY3teXh7p6em1fic9Pb3O7ZcuXcrGjRu58cYbj1vHtGnTKC4uDi+7d+8+ySOR1sjmtnqAHH4FIBGR1iaiAcjpdDJs2LAak5ODwSALFy5k9OjRtX5n9OjRR01mXrBgQa3t//a3vzFs2DAyMzOPW4fL5SIhIaHGImKPTgQgOliOPxCMcDUiItKQIj4ENnXqVF588UVee+011q9fzy233EJZWRnXXXcdAFdffTXTpk0Lt7/jjjuYP38+M2fOZMOGDUyfPp3ly5dz22231divx+PhrbfeOmHvj8ixOKKtIBxnVFBSqeeBiYi0JhGdBA3WZe0FBQXcf//95ObmMnToUObPnx+e6Lxr1y5stkM5bcyYMbzxxhv8/ve/595776VPnz7MnTuXQYMG1djvm2++iWmaTJ48uUmPR1oPe3UAooLiiiraxTojXJGIiDSUiN8HqDnSfYAEgK9egA9/y/uBUXS5aTZDM5IiXZGIiBxHi7kPkEizFroMvroHSEREWg8FIJFjqQ5ARgVF5b4IFyMiIg1JAUjkWA7rAfKoB0hEpFVRABI5lho9QApAIiKtiQKQyLG4rAl08ZRrDpCISCujACRyLIcNgWkOkIhI66IAJHIs1Q9DNUwqy/VEeBGR1kQBSORYomII2KybHwbLDkS4GBERaUgKQCLHYhj4XcnWasXBCBcjIiINSQFI5DiCMe0BiKpUD5CISGuiACRyHEYoADm8heipMSIirYcCkMhxOOJTAEgIeij16onwIiKthQKQyHE44qwA1M4oYX+pLoUXEWktFIBEjifGCkDt8bC/1BvhYkREpKEoAIkcT4x1FVg7o4T9JQpAIiKthQKQyPGEJkEnGyXqARIRaUUUgESOJ9YaAkumhALNARIRaTUUgESOJ9wDpDlAIiKtiQKQyPHEpgLQjlIOesojXIyIiDQUBSCR44lJIWjYsRkmVZ68SFcjIiINRAFI5HhsNvzR1jwgozQ3wsWIiEhDUQASOZG4dADs5fl6HIaISCuhACRyAo7EjgAkBw9SWF4V4WpERKQhKACJnIAtweoB6kAROcUVEa5GREQaggKQyImEhsDSjELyPJURLkZERBqCApDIicRbASjVKCK3WPcCEhFpDRSARE4kFIA6GEXkaghMRKRVUAASOZFQAOpoHCRXQ2AiIq2CApDIiSRmAFYPUEGRJ8LFiIhIQ1AAEjmRmPYE7C4AfIV7I1yMiIg0BAUgkRMxDILxna314r0Eg7oZoohIS6cAJFIH9nahYbBgAfkluhJMRKSlUwASqQNbaB5QJ+MAuwv1VHgRkZZOAUikLhK7ANDZ2M/ugwpAIiItnQKQSF2EAlBH4wC7D+peQCIiLZ0CkEhdJFqToDsZB9ilHiARkRZPAUikLkJzgKwhsLIIFyMiIvWlACRSFwlWD1CcUUnRwf0RLkZEROpLAUikLpwxBKPbA2Av3YvPH4xwQSIiUh8KQCJ1ZITmAaVzgL1FmggtItKSKQCJ1JFRYx6QJkKLiLRkCkAidRW6FF43QxQRafkUgETq6rCbIepSeBGRlk0BSKSu2nUDoKuRz479uhReRKQlUwASqavkngB0NfLYVqAAJCLSkikAidRVu+4AtDdKOHiggEDQjGw9IiJyyhSAROrKFY8Z2wGAjsEc9mgitIhIi6UAJHISjOQeAHQz8tmmeUAiIi2WApDIyQjNA+pm5GoekIhIC6YAJHIyQgGou5HHtoLSCBcjIiKnSgFI5GS0Cw2B2XQlmIhIS6YAJHIywkNgeWzXHCARkRZLAUjkZIQmQacbhRR5iinz+iNckIiInAoFIJGTEd0O3ImAdUdo9QKJiLRMCkAiJ8MwDpsInctWTYQWEWmRFIBETlb1RGgjj425JREuRkREToUCkMjJat8bgJ5GDhsUgEREWiQFIJGTldIXgJ62HDbkeCJcjIiInAoFIJGTlVLdA7SPfcWVFJdXRbggERE5WQpAIicrNASWanhIoJQNueoFEhFpaRSARE6WKx7iOwHQy8hhvYbBRERaHAUgkVMRGgbrZdunidAiIi2QApDIqaieCG3ksF4BSESkxVEAEjkV7fsAVgDalFtCIGhGuCARETkZCkAipyLFCkC9bfuoqAqw62B5hAsSEZGToQAkcipCAaibkYedgO4HJCLSwkQ8AD333HN0794dt9vNyJEj+frrr4/b/q233qJ///643W4GDx7MBx98cFSb9evXM2HCBBITE4mNjWXEiBHs2rWrsQ5B2qKELuCIJgo/GUa+rgQTEWlhTikAvfbaa8ybNy/8/re//S1JSUmMGTOGnTt31nk/s2fPZurUqTzwwAOsXLmSzMxMsrOzyc/Pr7X9F198weTJk7nhhhtYtWoVEydOZOLEiaxZsybcZuvWrZx11ln079+fxYsX891333HffffhdrtP5VBFamezha8E623s00RoEZEWxjBN86Rnb/br14/nn3+ec889l2XLlpGVlcUTTzzB+++/j8Ph4D//+U+d9jNy5EhGjBjBs88+C0AwGCQjI4Nf/epX3HPPPUe1nzRpEmVlZbz//vvhbaNGjWLo0KHMmjULgKuuuoqoqCj+7//+72QPK8zj8ZCYmEhxcTEJCQmnvB9p5f5zE3w3m0erruTdxMks/e25ka5IRKRNO5l/v0+pB2j37t307m39v9+5c+dyxRVXcNNNNzFjxgyWLl1ap334fD5WrFhBVlbWoWJsNrKysli2bFmt36kOW4fLzs4Otw8Gg8ybN4++ffuSnZ1Nhw4dGDlyJHPnzj2FoxQ5gbTTABhg28XugxWUVOqRGCIiLcUpBaC4uDgOHDgAwEcffcT5558PgNvtpqKiok772L9/P4FAgLS0tBrb09LSyM3NrfU7ubm5x22fn59PaWkpjzzyCOPHj+ejjz7i8ssv50c/+hFLliw5Zi1erxePx1NjETmhUAAa5NgNwNp9+nMjItJSOE7lS+effz433ngjp59+Ops2beKiiy4CYO3atXTv3r0h6zspwWAQgMsuu4xf//rXAAwdOpQvvviCWbNmMW7cuFq/N2PGDB588MEmq1NaibRBAHQ1c3Dh4/s9xYzq2T7CRYmISF2cUg/Qc889x+jRoykoKODf//437dtbf+mvWLGCyZMn12kfKSkp2O128vLyamzPy8sjPT291u+kp6cft31KSgoOh4OBAwfWaDNgwIDjXgU2bdo0iouLw8vu3bvrdAzSxsWlQUx7bATpY+zhu73Fka5IRETq6JR6gJKSksITlw93Mr0oTqeTYcOGsXDhQiZOnAhYPTgLFy7ktttuq/U7o0ePZuHChdx5553hbQsWLGD06NHhfY4YMYKNGzfW+N6mTZvo1q3bMWtxuVy4XK461y4CgGFAh4GwYyn9bbtZoQAkItJinFIP0Pz58/nss8/C75977jmGDh3KT3/6UwoLC+u8n6lTp/Liiy/y2muvsX79em655RbKysq47rrrALj66quZNm1auP0dd9zB/PnzmTlzJhs2bGD69OksX768RmC6++67mT17Ni+++CJbtmzh2Wef5b333uOXv/zlqRyqyPGFhsH6G7vYvr+M4gpNhBYRaQlOKQDdfffd4YnC33//Pb/5zW+46KKL2L59O1OnTq3zfiZNmsRjjz3G/fffz9ChQ1m9ejXz588PT3TetWsXOTk54fZjxozhjTfe4K9//SuZmZnMmTOHuXPnMmjQoHCbyy+/nFmzZvHnP/+ZwYMH89JLL/Hvf/+bs84661QOVeT4QhOhhzr3ArBWvUAiIi3CKd0HKC4ujjVr1tC9e3emT5/OmjVrmDNnDitXruSiiy465lVcLYXuAyR1tnclvPhDSmyJDC7/C9MuHMD/G9cr0lWJiLRJjX4fIKfTSXm59fDHjz/+mAsuuACA5ORkXUIubUtqfzBsxAeLSaVYE6FFRFqIU5oEfdZZZzF16lTGjh3L119/zezZswFrsnGXLl0atECRZs0ZA8m94MBm+tt28d2ejpGuSERE6uCUeoCeffZZHA4Hc+bM4fnnn6dz584AfPjhh4wfP75BCxRp9kLzgPrbdrP7YAUFJd4IFyQiIidySj1AXbt2rfE8rmpPPPFEvQsSaXHSToN1czkzOocXS2DFzkLGD6r9XlYiItI8nFIAAggEAsydO5f169cDcNpppzFhwgTsdnuDFSfSIoR6gE6zWzfQXLlLAUhEpLk7pQC0ZcsWLrroIvbu3Uu/fv0A63ESGRkZzJs3j169dBWMtCGhAJTm20EUfpbvOBjhgkRE5EROaQ7Q7bffTq9evdi9ezcrV65k5cqV7Nq1ix49enD77bc3dI0izVtSN3AnYg9W0dfYw5q9HiqrApGuSkREjuOUAtCSJUv485//THJycnhb+/bteeSRR4771HWRVskwoGMmAKOid+ELBFmjy+FFRJq1UwpALpeLkpKSo7aXlpbidDrrXZRIi9NxKABnx1p3hF6xs+6PhBERkaZ3SgHokksu4aabbuKrr77CNE1M0+TLL7/k5ptvZsKECQ1do0jz12koAAPZBigAiYg0d6cUgJ5++ml69erF6NGjcbvduN1uxowZQ+/evXnyyScbuESRFiDUA5RSvhkHflbsLOQUnjIjIiJN5JSuAktKSuKdd95hy5Yt4cvgBwwYQO/evRu0OJEWI7knuBKxeYs5zb6Pb8u6svNAOd1TYiNdmYiI1KLOAehET3n/5JNPwuuPP/74qVck0hIZBnTKhO2fkt0+l2/zu7JiZ6ECkIhIM1XnALRq1ao6tTMM45SLEWnROg6F7Z8y0r0LOJNvdhzkimF6Np6ISHNU5wB0eA+PiNQiNBG6t38LAF9sPRDBYkRE5HhOaRK0iNQiNBE6oXgjbluAXQfL2X2wPLI1iYhIrRSARBpKaCK0EfBycboHgM+37I9wUSIiUhsFIJGGYhjQcQgAFyTnAvCZApCISLOkACTSkELzgIbatwOwbOsBgkHdD0hEpLlRABJpSJ3OACDVs4boKDsHynxsyD36sTEiIhJZCkAiDSljJAC23O/5QfdoAL7YqmEwEZHmRgFIpCEldobEDDADTGi/D9BEaBGR5kgBSKShhXqBRtg3AfDV9oP4/MFIViQiIkdQABJpaF1HAZBauJrkWCflvgCrdxdFtiYREalBAUikoYUCkLHnG87u1Q6ARRvyI1mRiIgcQQFIpKF1GAiuBPCVMLFTEQCLNuRFtiYREalBAUikodns0GU4AKMcW7DbDDblleqxGCIizYgCkEhj6DoagOjcrxnezRoG+3i9eoFERJoLBSCRxhC6EoxdX5E1IA2Ahes1D0hEpLlQABJpDF2Gg2EHzx4u6FIFwFfbD1BSWRXhwkREBBSARBqHMxbSBwPQrex7eqTEUhUwWbpZN0UUEWkOFIBEGku3sdbrjqWc178DoHlAIiLNhQKQSGPp8QPrdfunnBeaB7R4YwEBPR1eRCTiFIBEGku3MdY8oIPbGN6ujAS3g4NlPlbvLox0ZSIibZ4CkEhjcSdAp9MBiNr1OeP6VQ+D6WowEZFIUwASaUw9zrZet39K1oBQAFqneUAiIpGmACTSmA6bB3ROn1Si7Aab80vZkl8S2bpERNo4BSCRxpQxCmxR4NlDYuVuzu6TCsB73+ZEuDARkbZNAUikMTljIONMa337p1wypCMA7323D9PU1WAiIpGiACTS2KqHwXYs5fyBaTgdNrYVlLE+R8NgIiKRogAk0tgOmwcU73JwTt/QMNh3+yJYlIhI26YAJNLYOg8DRzSUFUDBBi7N7ATAe9/uI6ibIoqIRIQCkEhjc7ig6yhrffunZA1II87lYE9hBct36qaIIiKRoAAk0hQOGwaLdtoZPygdgLdX7YlgUSIibZcCkEhT6DHOet2xFIIBfnR6ZwDe/y6HyqpABAsTEWmbFIBEmkLHTHAnQWUx7FnOqJ7t6ZjopqTSzycb9GgMEZGmpgAk0hTsDuh9nrW+aT42m8HEUC/QWys0DCYi0tQUgESaSp9s63XzRwD8ZFgXABZvzCenuCJSVYmItEkKQCJNpXcWGDbIWwNFu+mZGseZPZIJmjBnuXqBRESakgKQSFOJbQ9dRljroV6gq0ZkADB7+W7dE0hEpAkpAIk0pT4XWK+hAHThoI7Eu617An22ZX8ECxMRaVsUgESaUt/x1uu2JVBVQbTTHr4k/h9f7YxgYSIibYsCkEhTSjsNEjqDvwK2LwVgyqhuACxYl6fJ0CIiTUQBSKQpGcahYbBN8wHomxbPyNBk6H9+tSuCxYmItB0KQCJNrd+F1uvGDyAYBODno61eoH9+sxufPxipykRE2gwFIJGm1vMccMZDSQ7s+QaACwamkxrvoqDEy4drciJbn4hIG6AAJNLUHK5DvUDr3gHA6bDx89BcoL99th3T1CXxIiKNSQFIJBIGXma9rnsHQmFnysiuOB02vttTzPKdhREsTkSk9VMAEomE3ueBMw48e2DvSgDax7m44gzrkviXlm6LZHUiIq2eApBIJERFQ9/Qs8HWzQ1vvn5sDwA+WpfHtoLSCBQmItI2KACJREotw2B90uLJGtAB04RZS7ZGsDgRkdZNAUgkUnqfD1ExULQTcr4Nb/7lD3sD8J+Ve9lbpBsjiog0BgUgkUhxxkCf8631NXPCm8/o2o7RPdvjD5q8+KnmAomINAYFIJFIGvwT6/X7ORAMhDffdq7VC/TmN7vYX+qNRGUiIq2aApBIJPW5ANxJ1k0Rty8Jbx7Tqz2ZGUlUVgX522fbI1efiEgrpQAkEkkOFwz6kbX+7ezwZsMwuC00F+jVz3eQX1IZiepERFqtZhGAnnvuObp3747b7WbkyJF8/fXXx23/1ltv0b9/f9xuN4MHD+aDDz6o8fm1116LYRg1lvHjxzfmIYicuiFXWa/r3wPvoUvfswZ0YGhGEhVVAZ5btCVCxYmItE4RD0CzZ89m6tSpPPDAA6xcuZLMzEyys7PJz8+vtf0XX3zB5MmTueGGG1i1ahUTJ05k4sSJrFmzpka78ePHk5OTE17++c9/NsXhiJy8jDOhXQ+oKoO1b4c3G4bBb8f3A+CNr3ex+2B5pCoUEWl1Ih6AHn/8cX7xi19w3XXXMXDgQGbNmkVMTAwvv/xyre2feuopxo8fz913382AAQN4+OGHOeOMM3j22WdrtHO5XKSnp4eXdu3aNcXhiJw8w4Azfm6tr3ytxkdjeqVwdp8UqgImTyzYFIHiRERap4gGIJ/Px4oVK8jKygpvs9lsZGVlsWzZslq/s2zZshrtAbKzs49qv3jxYjp06EC/fv245ZZbOHDgQMMfgEhDGfozsDmsp8Pn1uzN/G12fwDeXr2XDbmeSFQnItLqRDQA7d+/n0AgQFpaWo3taWlp5Obm1vqd3NzcE7YfP348r7/+OgsXLuRPf/oTS5Ys4cILLyQQCBy5OwC8Xi8ej6fGItKk4tOg30XW+opXa3w0uEsiFw/uiGnCY/9VL5CISEOI+BBYY7jqqquYMGECgwcPZuLEibz//vt88803LF68uNb2M2bMIDExMbxkZGQ0bcEiAMOvs16/mw2+mvN9pl7QF7vN4OP1eXyz42AEihMRaV0iGoBSUlKw2+3k5eXV2J6Xl0d6enqt30lPTz+p9gA9e/YkJSWFLVtqv5Jm2rRpFBcXh5fdu3ef5JGINIAe50BSN/B6akyGBuiVGseVw61g/uB7awkEzaavT0SkFYloAHI6nQwbNoyFCxeGtwWDQRYuXMjo0aNr/c7o0aNrtAdYsGDBMdsD7NmzhwMHDtCxY8daP3e5XCQkJNRYRJqczQbDrrHWV7xy1Md3XdCXeLeDNXs9/Gu5QrqISH1EfAhs6tSpvPjii7z22musX7+eW265hbKyMq67zhoOuPrqq5k2bVq4/R133MH8+fOZOXMmGzZsYPr06SxfvpzbbrsNgNLSUu6++26+/PJLduzYwcKFC7nsssvo3bs32dnZETlGkTo7zmTo9nEu7szqC8Cj/91IUbkvEhWKiLQKEQ9AkyZN4rHHHuP+++9n6NChrF69mvnz54cnOu/atYucnJxw+zFjxvDGG2/w17/+lczMTObMmcPcuXMZNGgQAHa7ne+++44JEybQt29fbrjhBoYNG8bSpUtxuVwROUaROjt8MvQRl8QDXD26G306xHGwzMcf5q1v4uJERFoPwzRNTSY4gsfjITExkeLiYg2HSdPbugj+73JwJcJvNlhPjT/Mip2F/HjWF5gm/P2GkZzVJyVChYqINC8n8+93xHuAROQIPc4JTYYuPmoyNMCwbu24elQ3AO59+3sqfLXf3kFERI5NAUikuTl8MvQ3L0ItnbR3j+9Px0Q3uw6W8+THujeQiMjJUgASaY7OuAYcbti3CnZ8dtTHcS4H/zvRmvf24tJtrNlb3NQVioi0aApAIs1RbAoMnWKtf/5UrU3OG5DGpZmdCJrw2znfURUINmGBIiItmwKQSHM1+lYwbLBlwVGXxFd74NKBJMVEsS7Hw18/3dbEBYqItFwKQCLNVfteMGCCtf7FM7U2SYlzcf8lAwF4fMEmVuwsbKrqRERaNAUgkeZs7B3W65o5UFT73Z8vP70zEzI7EQia3P7PVRRXVDVhgSIiLZMCkEhz1vkM6PEDCPrhy+drbWIYBn+4fBBdk2PYW1TBPf/+Dt3eS0Tk+BSARJq76l6gFa9CRe1DXPHuKJ796elE2Q0+XJPLG1/varr6RERaIAUgkeau13mQNgiqyuCbl47ZbEiXJH6b3R+Ah95bx/d7dGm8iMixKACJNHeGcagX6KsXoKrimE1vOKsH5/bvgNcf5MbXvyG3uLKJihQRaVkUgERagtMuh8QMKCuA5S8fs5nNZvDkVUPpmxZHnsfLDa99Q5nX34SFioi0DApAIi2BPQrG/dZa//RRqDz28FaCO4q/XTOC9rFO1u7zcOfs1QSDmhQtInI4BSCRliLzp5DSz5oI/dmTx22akRzDX68ehtNhY8G6PGZ8uL5pahQRaSEUgERaCrsDsqZb618+D559x20+rFsyj/54CAAvLt3OC0u2NnKBIiIthwKQSEvS70LIGAX+Clg844TNLxvamWkXWleGzfhwA2/q8ngREUABSKRlMQw4/yFrfdXfIX/DCb/y/8b14v+N6wnAtLe/Z86KPY1ZoYhIi6AAJNLSdB0J/S8BMwgfP1Cnr9wzvj9Xj+6GacLdc77lndV7G7lIEZHmTQFIpCU67wGwOWDTfFj37gmbG4bB9EtPY/KZXTFN+PXs1bz/3fHnEImItGYKQCItUWrfQzdH/OAuqCg64VdsNoM/TBzElcO7EDThjjdXM39NTuPWKSLSTCkAibRUP/gttO8DpXmw4L46fcVmM5jxoyH86PTOBIImt72xirmrNBwmIm2PApBISxXlhglPW+srX4ftn9bpa3abwaM/yeTy0zvjD5rcOXs1Ly3d1oiFiog0PwpAIi1ZtzEw/Hpr/d3bj/ucsMPZbQYzf5LJ9WN7APC/89Yz48P1mKbuGC0ibYMCkEhLlzUd4jtB4fY63Ruoms1mcN8lA/if8dZ9gl5Yso2753yHPxBspEJFRJoPBSCRls6dCBfPtNa/eBb2rarzVw3D4JZzevHnHw/BbjOYs2IP1736DUXlvkYqVkSkeVAAEmkN+l9kPTHeDMDcX4Lfe1Jfv3J4Bi/8bBjRUXaWbt7PhGc/Z0Oup5GKFRGJPAUgkdbioscgJgXy18GSP53017MGpvGfX44hIzmaXQfL+dFfvuCD73WZvIi0TgpAIq1FbApc8oS1/tkTsPOLk97FgI4JvHvrWYzt3Z5yX4Bf/mMl099di9cfaOBiRUQiSwFIpDUZOAGGXGU9JuOt66A0/6R30S7WyWvXnclNP7CeH/bqFzu4/Lkv2FpQ2tDViohEjAKQSGtz8UxI7Q+luTDnegj4T3oXDruNey8awMvXDic51sm6HA+XPvMZ//pmty6VF5FWQQFIpLVxxcGVr0NULOxYCp/84ZR3dW7/ND6842zG9LKGxH777++48bXl5HsqG7BgEZGmpwAk0hql9oPLnrHWP3scNs4/5V2lJbj5vxtGcs+F/XHabSzckM8FT37Ku9/uU2+QiLRYCkAirdWgK+DM/2etv30TFO445V3ZbQY3j+vFe786i9M6JVBUXsXt/1zFbW+sUm+QiLRICkAirdkF/wtdRkBlMbw5Bbwl9dpdv/R45t46ljuz+uCwGcz7PocfPraYWUu26koxEWlRFIBEWjOHE37yKsR2gLw1pzwp+nBRdht3ZvVl7q1jycxIoswX4JEPN5D9xKcsXJ+nYTERaREUgERau8QuMPlNcLhh80fw0e8aZLeDOify9i1jeOwnmaTGu9hxoJwbXlvONa98w5Z8XTIvIs2bApBIW9BlGFz+grX+1Sz45m8NslubzeDHw7rwyV3ncPO4XjjtNj7dVMD4Jz9l+rtr2V96co/kEBFpKoap/uqjeDweEhMTKS4uJiEhIdLliDScpTNh4UNgi4LrPoCMMxt09zv2l/G/89bx8XrrBoyxTjs3nt2TG8/uQbw7qkF/S0TkSCfz77cCUC0UgKTVMk146xpY9w7Ed4QbP7aGyBrY51v286f5G/huTzEA7WKiuH5sD64e3Z3EGAUhEWkcCkD1pAAkrZq3BF46HwrWQ/vecN2HENehwX/GNE0+XJPLY//dyLb9ZYDVI/TTkV254ayepCe6G/w3RaRtUwCqJwUgafWKdsMrF0LxbkgbBNe8BzHJjfJT/kCQed/n8PzirWzItS7Dj7Ib/Oj0Ltw0rie9UuMa5XdFpO1RAKonBSBpEw5stUJQaR50HgZXvwOu+Eb7OdM0WbypgOcXb+Xr7QcBMAzIHpjOLef0IjMjqdF+W0TaBgWgelIAkjYjbx28ejFUHISMkdbl8o3UE3S4FTsLmbVkKwvW5YW3jenVnpvH9eLsPikYhtHoNYhI66MAVE8KQNKm7FsFr10G3mJrTtCUOZDco0l+enNeCbOWbOOd1XvxB62/inqmxPLTkV35ybAMTZgWkZOiAFRPCkDS5uSvh3/8xJoTFJMCP/2Xde+gJrK3qIKXlm7jreV7KPVad6p2OWxcmtmJn43qRmaXRPUKicgJKQDVkwKQtEkluVYIyv0OHNHw479B/4ubtIRSr593Vu/l71/uYn2OJ7x9UOcEpozsxiVDOup+QiJyTApA9aQAJG2WtxTeuha2LAAMuPDPMPKmJi/DNE1W7iriH1/u5P3vc/D5g4DVK3T+wDQmZHZiXL9UXA57k9cmIs2XAlA9KQBJmxbww7ypsPI16/3o2+D8h8EWmSfnHCzzMWfFbt78ZjfbCsrC2+PdDrJPS+eSIR0Z2zuFKLue7CPS1ikA1ZMCkLR5pgmfPW49NgNg4GXWs8SioiNYksl3e4p599t9zPsuh1xPZfizdjFRXDi4I5cO6cSZPZKx2zRfSKQtUgCqJwUgkZDv3oK5t0CwCjoPh5+8AkldI10VwaDJ8p2FvPftPj74PocDZb7wZ6nxLi4e3JFLMztxRtckTZ4WaUMUgOpJAUjkMNuXwuwpUFkM7kS47C8w4JJIVxXmDwRZtu0A7327j/lrcvFU+sOfdU6K5pLMjlw8uCODOiViU8+QSKumAFRPCkAiRzi4Hf59I+xdbr0/ayqc+3uwNa9JyD5/kKWbC3jv230sWJdHmS8Q/iwtwcV5A9LIGtCBMb1ScEc1r9pFpP4UgOpJAUikFoEqWPAAfPmc9b7rGLj8eWjXPaJlHUuFL8AnG/N5/7t9LN5YQPlhYSg6ys7Y3ilkDejAuf070CFBD2YVaQ0UgOpJAUjkOL6fA+/dAb5ScMZB9h/hjKutB3s1U5VVAb7cdoCP1+excH0+OcWVNT4f3DmRH/RNYVzfDpzeNUlXlIm0UApA9aQAJHICB7fD3F/Cri+s932yYcLTEJ8e2brqwDRN1uV4WLQ+n4835PPt7qIan8c47Qzr1o6RPZIZ1bM9mRkKRCIthQJQPSkAidRBMADLnoNFD0PAB9Ht4KLHYNAVzbo36Ej5JZUs3bSfJZsK+GzLfg4edkUZQJzLwaieyYztncLY3in0To3TZGqRZkoBqJ4UgEROQt46ePv/WY/QAMgYBdl/gC7DI1vXKQgGTTbll/DVtoN8tf0AX247eFQgSoyO4oyuSQzvnszwbu3IzEjShGqRZkIBqJ4UgEROkt8Hnz1hLf4Ka9uQSXDeA5DYObK11UMwaA2XLd28n8+2FLBiZyGVVcEabaLsBqd1SmR4t3YM796OYd2SSY13RahikbZNAaieFIBETpFnHyx8GL59w3ofFQNj74QxvwJnTERLawhVgSDr9nlYvrOQFTsPsnxHIfkl3qPadWsfw/BuyaFA1E7DZiJNRAGonhSAROpp70qYPw12f2m9T+gC5z/Y4uYHnYhpmuwprOCbHQetULSjkE35JRz5t2qC28EZ3doxrKsViDIzkoh1OSJTtEgrpgBUTwpAIg3ANGHtf6x7BxXvtrZ1GQFZ06H7WREtrTEVV1SxcpcVhlbsLGT17iIqqgI12thtBgM6xjM0I4khXZIY0iWR3qlxOHS1mUi9KADVkwKQSAOqqoBlz8LSJ6Aq9DT33llwwR+gQ//I1tYEqgJBNuSUWENmOwtZubOQfUfchwjAHWXjtE6JDM1I4oyu7Ti9axKdkiL38FmRlkgBqJ4UgEQaQUkuLPkzrHwNgn4w7DDiBhj3PxCbEunqmtS+ogpW7Czk+73FfLeniDV7PZR6/Ue1S09wM6RLIgM6JjCwUwIDOybQpV20HvAqcgwKQPWkACTSiA5shY/ug43zrPcON2ReBaNuhdS+ka0tQoJBk+0Hyvh2dxGrdhWxanch63NKCASP/uu5fayToRlJnNY5kYEdEzitk0KRSDUFoHpSABJpAtsWw8cPwr6Vh7b1HQ+jb4XuZ7eqydKnotzn5/s9xazZ52F9jod1+zxszi+hKnD0X9nxbgcDD+slGtgpgT4d4nE6NKdI2hYFoHpSABJpIqYJu5bBF8/Cxg+A0F9HHQbCgAkw+CeQ0juiJTYnlVUB1uV4+HZ3Eev2eViX42FTXu2hKMpu0KdDfI1QNKBjAonRURGoXKRptLgA9Nxzz/Hoo4+Sm5tLZmYmzzzzDGeeeeYx27/11lvcd9997Nixgz59+vCnP/2Jiy66qNa2N998My+88AJPPPEEd955Z53qUQASiYD9W+DLv8DqNw7dTBEDTrscfnA3pA2MaHnNlc8fZGtBKWv3eUKhqJh1+zx4Ko+eUwTQpV00/dPj6ZMWT9+0OHqmxJGW4CY90d3ElYs0vJP59zviN6KYPXs2U6dOZdasWYwcOZInn3yS7OxsNm7cSIcOHY5q/8UXXzB58mRmzJjBJZdcwhtvvMHEiRNZuXIlgwYNqtH27bff5ssvv6RTp05NdTgicqpSesMlj8O5v4dN82HNf2DLAutS+rX/gW5jYeBEGDoZXPGRrrbZcDpsDOho9e4wzNpmmiZ7iypYt89jBaPQENreogr2FFrLx+vza+ynZ0osvTvE0TM1jl6psfRMjaN3hzj1GEmrFfEeoJEjRzJixAieffZZAILBIBkZGfzqV7/innvuOar9pEmTKCsr4/333w9vGzVqFEOHDmXWrFnhbXv37mXkyJH897//5eKLL+bOO+9UD5BIS5P7PXz6KKx759C26HZw+s9g2HXQvlfkamuBisurwsNmm/JK2JxXyq6D5RSUemudcA3WlWh90+Pp2yGOvmnx9EmzQpKCkTRHLaYHyOfzsWLFCqZNmxbeZrPZyMrKYtmyZbV+Z9myZUydOrXGtuzsbObOnRt+HwwG+fnPf87dd9/Naaed1ii1i0gTSB8MV74ORbth/buw/GU4sAW+eMZaep0LZ1wNfS4AZ2ykq232EmOiGN2rPaN7ta+xvbDMx3d7i9lWUMq2gjK27S9la34ZuZ7K8PLppoIa30mJc9EzNZZeoR6jXqlx9EyNpUu7GOx67Ie0ABENQPv37ycQCJCWllZje1paGhs2bKj1O7m5ubW2z83NDb//05/+hMPh4Pbbb69THV6vF6/30PN8PB5PXQ9BRJpCUoZ1ddjIm2HzR/DN32DLx7B1kbU4oqHP+XDaROiTDa64SFfcorSLdTKubyrj+qbW2O6prGJzXgmb8krZmGv1Gm0tKCXP42V/qbV8vf1gje84HTa6t4+hT4d4+qbF0y89nt4d4uiaHKOr0qRZifgcoIa2YsUKnnrqKVauXFnn+2LMmDGDBx98sJErE5F6s9mh34XWUrgDVrxmzQ8q3GH1EK1/17qvUK/zoNcPoec50L53m7+k/lQluKMY1i2ZYd2Sa2wvqaxi+/4ytoZ6jLaGe47K8PmDbMorZVNeKfO+zwl/x2ZAl3Yx9EiJPWrplBStXiNpchENQCkpKdjtdvLy8mpsz8vLIz09vdbvpKenH7f90qVLyc/Pp2vXruHPA4EAv/nNb3jyySfZsWPHUfucNm1ajWE1j8dDRkbGqR6WiDSFdt0h6wE4737I+daaJ7RuLhzcZt1ksfpGi8k9rfsLdRsLnYdBQsdIVt0qxLujQs8wS6qxPRA02VdUwZaCUrbklbIht4SNeR62F5RR5guw62A5uw6Ws+SI4TSnw0a3ZCsc9QwNpVUPrSXFOJvwyKQtaRaToM8880yeeeYZwJq/07VrV2677bZjToIuLy/nvffeC28bM2YMQ4YMYdasWRw4cICcnJwa38nOzubnP/851113Hf369TthTZoELdJCmSbkrYGN82H7Etj9FQR8NdukDrDmDvU6F7qNAWdMZGptQ0zTpKDEy7b9ZezYX8b2/VZv0fb9Zew6UI4vEDzmd10OG2kJbgZ3TqRTkptOSdF0TY6hW/tYMpKjcTnsTXgk0ty1mEnQAFOnTuWaa65h+PDhnHnmmTz55JOUlZVx3XXXAXD11VfTuXNnZsyYAcAdd9zBuHHjmDlzJhdffDFvvvkmy5cv569//SsA7du3p337mhP8oqKiSE9Pr1P4EZEWzDCsidPpg2Hc3eAtse44vWm+1UuUuwYK1lvLl8+B3WWFoN7nWcNmHQZouKwRGIZBhwQ3HRLcjOpZ8+/n6l6jbfvL2F5Qyrb9ZeFhtZziSrz+YLjn6Oj9WlepdUy0glH39rF0TY6hU1I0ndtF0zHRjTtKAUlqF/EANGnSJAoKCrj//vvJzc1l6NChzJ8/PzzRedeuXdhshybOjRkzhjfeeIPf//733HvvvfTp04e5c+cedQ8gERFc8TDgUmsBKD9oBaJtn8CWReDZY61v+wT4PUQnQ8dMyDgTuo6CLmdqQnUjs9sMMpJjyEiOOWoSdpnXz8EyH1tCc4xyiirYW1TBzgNWICr1+skpriSnuJKVu4pq3X9qvItOSdF0CYWizklWMEpPdJOe4KZ9nEvzj9qoiA+BNUcaAhNpA0wT9m+CLQth60LY8flhd6AOMexWb1LX0VYo6jQU2vVQL1EzYJomB8p87D5YTm5xJXsKK9h+oIw9hRXsLSxnb1EFlVXHHlqr5rAZdIh3WYEo0U1aqEfJeo0mPcFNhwSXepJaiBb3KIzmRgFIpA3yeyFvrfVw1t1fw85lULzr6HbuRKuXqONQ67XT6VYosukS7+bENE0Ky6vYW2j1Gu0tqgitW4Ep11NJQYmXY9z/8SjJsU7rkSEJLtJDwahjopu0UE9SeqKbBLejzlcfS+NQAKonBSARAaB4D+z60npg694VVkA6clI1gCsB0odYPUTVwah9b4WiZs4fCFJQ6rUCUSgU1fbq9Z+4JwkgOsoe7j0K9yjFu6z5T/Eu0hKsz3Q/pMajAFRPCkAiUqtAFeSvh5zVsG+1NbE6bw34K49uG90OOp0BaadZS4cBkNIPovTQ0ZbENE2KyqsO3RW7uLJGYMrzWHOQiiuq6rzPlDgX6Yku0hOiSUtwkRLnIiXOSUqci/bV6/Eu4l3qUTpZCkD1pAAkInUWqIKCjVYYqg5Gud8fPZ8IwLBBci8rDFWHorRB1r2K9A9di1bhC4TD0OGveZ5K8ku85JdUkufx4qtjbxJY90dKiXXSLtZJrMtBYnQUqfEuUuNc1mv1EnqveUoKQPWmACQi9RKogpzvIPc7a9gsfz3kr4WKwtrbuxIhtS+07wMpva2QlNgFEjpDXAfrDtjS4lXPS8opriA3dPVavqeS/WU+DpR62V966LXU6z/p/ce5HCTHOmkXE0W7WCfJMU7rfaz1mhgdRZTdRoLbQZfkGFLjXK1uOE4BqJ4UgESkwZkmlOZB/jorEOWts0JR3joIeI/9PZsD4jtCQidriU6GmGRI6mpNvm7XDeI7gT3idzWRBlRZFQg9b81HYbmPMq+fovIqCkq8FJR6KSixnsVWUOIlv+TkepYO53LYcNpt9EyNJTXeRUJ0FAnuKBKjDy0J0TXfJ8VENdveJgWgelIAEpEmE6iyLsffvwn2b4EDm63HeXj2QUkOmHX4h82wQWIGuBMgNtVaT+pqLdXhKb6j7nrdSpmmSYnXz/4SL4XlVRSW+ThYZgWng2WHFk9lFb6ASWGZj31FFfjreglcLVwOG0kxUSRFO0mMicLAmtuUGBNFdJQ9FKIcJMbUHqYa6w7eLepO0CIibZo96tBE6SMF/FCWD8V7wbPXCkQVhVBWAIU7oXC7daVawAdFO0/8W+5Eq7cooeOh14TOVlCyOax5SIYNnHHW0FtMCjj0LK7mzjAMEtxWz01dBYImpZV+PJVVVFYF2JJfSlFFFcWhxXP4eqW/xvtA0MTrD5Ln8ZLnOU7v5XG4o2zcdHZPpl4QuSc0KACJiDRXdsehoS9G1N4mGLRC0sFt4Cu3htmKdllL8W4rNHn2QVU5VBZbS8H6utfgTrJ6leI6QGyKtR4bWo/rEHofWlzxmszdQththtU7E2OFpj5p8XX6nmmalIaG44orqigqr6Kowmc9hs9TSZk3QHmVH09FzdB0KExVYZpQWRWM+BVuCkAiIi2ZzQbx6dZyLKZpBZ/qMFSSA54cKNlnBSVP9VCbab1WeqxeJjMAlUXWcmDziWuxu6xQFBVj9SjFJFu9Ts4465EizlhwxofWq7fFW2HKFQ92J0QnWZ8pSDVLhmEQ744i3h1Fxil8Pxg0Kan0U1xRRYwrsvOIFIBERFo7w7CCRXSSdel9XQSDVvApK4DSfOu1einNh7L9ofehdV+pNZm7eHf967W7Qr1K7a1huNgUK0hFRVvhKirmsPVoa7E7rcXhsoYV7a7Qe+ehz6o/rx7ukyZnO6LnKZIUgERE5Gg2m9WDE5MMqXWYp+ErPxSQqsqtyd0VheD1gLfUCkjeUvCV1HzvLbGG7aoqrAAV8Fmvnj3W0iiMI8KS89CrI/pQWIxuZy3u0Lor3rolgWE7bLFbQ5W2KGsftqjQe4f1OaF5VTb7oSv4jgxfwSAEq6zv6u7hTUYBSERE6s8ZA85u1mX59eErs3qUyvdD2YHQa4EVlqrKQ0uF1a6qIrSEAld1eApUWc92C1RZ7/1e4PArnsxQu1ObwFsvht0KQ9UXYJuBmlf6OeOsHi2HOzRkGAsY1jHYo0Kh7fDeLucRPV2uQwHMFmVtd0RbdyB3uK02NkcorDmsOsxAqK3rsH2Gwlywygq3mIdCH0YoxJnWRP2Az2oXqIKg/9Dv2l3Wqy30WzZ76Pht1ntXghU0I0QBSEREmo/qf/TrG6SOVP0PdY2A5DtsCX3uK7OG/ioKoaLosPVCq7fKDIZCQ9AKDsFA6B9/f80QEPQf1i5otfMWW98JBI5dpy/UO9YWjL0Tzn8wYj+vACQiIq2f3RG6WWQE74Xk91k9WtW9P9W3HageNvP7rCFDv9d6lIqvzOr5MoNWD051L5ffdyjM+X2Hhg6r14MBK4BVBz1/BVRVWs+sC4e1UGCr7tUJt60M9eiEvm+PsuZaGbZDYa462MFhQ4jOQz1P4ToPC5nBQCgwVgdHv9XbFEEKQCIiIk3B4Qzd0uA44lKbphZBs61ERESkzVEAEhERkTZHAUhERETaHAUgERERaXMUgERERKTNUQASERGRNkcBSERERNocBSARERFpcxSAREREpM1RABIREZE2RwFIRERE2hwFIBEREWlzFIBERESkzVEAEhERkTbHEekCmiPTNAHweDwRrkRERETqqvrf7ep/x49HAagWJSUlAGRkZES4EhERETlZJSUlJCYmHreNYdYlJrUxwWCQffv2ER8fj2EYDbpvj8dDRkYGu3fvJiEhoUH3LYfoPDcNneemo3PdNHSem0ZjnWfTNCkpKaFTp07YbMef5aMeoFrYbDa6dOnSqL+RkJCg/3E1AZ3npqHz3HR0rpuGznPTaIzzfKKen2qaBC0iIiJtjgKQiIiItDkKQE3M5XLxwAMP4HK5Il1Kq6bz3DR0npuOznXT0HluGs3hPGsStIiIiLQ56gESERGRNkcBSERERNocBSARERFpcxSAREREpM1RAGpCzz33HN27d8ftdjNy5Ei+/vrrSJfUonz66adceumldOrUCcMwmDt3bo3PTdPk/vvvp2PHjkRHR5OVlcXmzZtrtDl48CBTpkwhISGBpKQkbrjhBkpLS5vwKJq/GTNmMGLECOLj4+nQoQMTJ05k48aNNdpUVlZy66230r59e+Li4rjiiivIy8ur0WbXrl1cfPHFxMTE0KFDB+6++278fn9THkqz9/zzzzNkyJDwzeBGjx7Nhx9+GP5c57lxPPLIIxiGwZ133hnepnNdf9OnT8cwjBpL//79w583u3NsSpN48803TafTab788svm2rVrzV/84hdmUlKSmZeXF+nSWowPPvjA/N3vfmf+5z//MQHz7bffrvH5I488YiYmJppz5841v/32W3PChAlmjx49zIqKinCb8ePHm5mZmeaXX35pLl261Ozdu7c5efLkJj6S5i07O9t85ZVXzDVr1pirV682L7roIrNr165maWlpuM3NN99sZmRkmAsXLjSXL19ujho1yhwzZkz4c7/fbw4aNMjMysoyV61aZX7wwQdmSkqKOW3atEgcUrP17rvvmvPmzTM3bdpkbty40bz33nvNqKgoc82aNaZp6jw3hq+//trs3r27OWTIEPOOO+4Ib9e5rr8HHnjAPO2008ycnJzwUlBQEP68uZ1jBaAmcuaZZ5q33npr+H0gEDA7depkzpgxI4JVtVxHBqBgMGimp6ebjz76aHhbUVGR6XK5zH/+85+maZrmunXrTMD85ptvwm0+/PBD0zAMc+/evU1We0uTn59vAuaSJUtM07TOa1RUlPnWW2+F26xfv94EzGXLlpmmaYVVm81m5ubmhts8//zzZkJCgun1epv2AFqYdu3amS+99JLOcyMoKSkx+/TpYy5YsMAcN25cOADpXDeMBx54wMzMzKz1s+Z4jjUE1gR8Ph8rVqwgKysrvM1ms5GVlcWyZcsiWFnrsX37dnJzc2uc48TEREaOHBk+x8uWLSMpKYnhw4eH22RlZWGz2fjqq6+avOaWori4GIDk5GQAVqxYQVVVVY1z3b9/f7p27VrjXA8ePJi0tLRwm+zsbDweD2vXrm3C6luOQCDAm2++SVlZGaNHj9Z5bgS33norF198cY1zCvoz3ZA2b95Mp06d6NmzJ1OmTGHXrl1A8zzHehhqE9i/fz+BQKDGf1SAtLQ0NmzYEKGqWpfc3FyAWs9x9We5ubl06NChxucOh4Pk5ORwG6kpGAxy5513MnbsWAYNGgRY59HpdJKUlFSj7ZHnurb/FtWfySHff/89o0ePprKykri4ON5++20GDhzI6tWrdZ4b0JtvvsnKlSv55ptvjvpMf6YbxsiRI3n11Vfp168fOTk5PPjgg5x99tmsWbOmWZ5jBSAROaZbb72VNWvW8Nlnn0W6lFarX79+rF69muLiYubMmcM111zDkiVLIl1Wq7J7927uuOMOFixYgNvtjnQ5rdaFF14YXh8yZAgjR46kW7du/Otf/yI6OjqCldVOQ2BNICUlBbvdftRs97y8PNLT0yNUVetSfR6Pd47T09PJz8+v8bnf7+fgwYP671CL2267jffff59PPvmELl26hLenp6fj8/koKiqq0f7Ic13bf4vqz+QQp9NJ7969GTZsGDNmzCAzM5OnnnpK57kBrVixgvz8fM444wwcDgcOh4MlS5bw9NNP43A4SEtL07luBElJSfTt25ctW7Y0yz/PCkBNwOl0MmzYMBYuXBjeFgwGWbhwIaNHj45gZa1Hjx49SE9Pr3GOPR4PX331Vfgcjx49mqKiIlasWBFus2jRIoLBICNHjmzympsr0zS57bbbePvtt1m0aBE9evSo8fmwYcOIioqqca43btzIrl27apzr77//vkbgXLBgAQkJCQwcOLBpDqSFCgaDeL1enecGdN555/H999+zevXq8DJ8+HCmTJkSXte5bnilpaVs3bqVjh07Ns8/zw0+rVpq9eabb5oul8t89dVXzXXr1pk33XSTmZSUVGO2uxxfSUmJuWrVKnPVqlUmYD7++OPmqlWrzJ07d5qmaV0Gn5SUZL7zzjvmd999Z1522WW1XgZ/+umnm1999ZX52WefmX369NFl8Ee45ZZbzMTERHPx4sU1LmctLy8Pt7n55pvNrl27mosWLTKXL19ujh492hw9enT48+rLWS+44AJz9erV5vz5883U1FRdMnyEe+65x1yyZIm5fft287vvvjPvuece0zAM86OPPjJNU+e5MR1+FZhp6lw3hN/85jfm4sWLze3bt5uff/65mZWVZaakpJj5+fmmaTa/c6wA1ISeeeYZs2vXrqbT6TTPPPNM88svv4x0SS3KJ598YgJHLddcc41pmtal8Pfdd5+ZlpZmulwu87zzzjM3btxYYx8HDhwwJ0+ebMbFxZkJCQnmddddZ5aUlETgaJqv2s4xYL7yyivhNhUVFeYvf/lLs127dmZMTIx5+eWXmzk5OTX2s2PHDvPCCy80o6OjzZSUFPM3v/mNWVVV1cRH07xdf/31Zrdu3Uyn02mmpqaa5513Xjj8mKbOc2M6MgDpXNffpEmTzI4dO5pOp9Ps3LmzOWnSJHPLli3hz5vbOTZM0zQbvl9JREREpPnSHCARERFpcxSAREREpM1RABIREZE2RwFIRERE2hwFIBEREWlzFIBERESkzVEAEhERkTZHAUhEpA4WL16MYRhHPctIRFomBSARERFpcxSAREREpM1RABKRFiEYDDJjxgx69OhBdHQ0mZmZzJkzBzg0PDVv3jyGDBmC2+1m1KhRrFmzpsY+/v3vf3Paaafhcrno3r07M2fOrPG51+vlf/7nf8jIyMDlctG7d2/+9re/1WizYsUKhg8fTkxMDGPGjGHjxo2Ne+Ai0igUgESkRZgxYwavv/46s2bNYu3atfz617/mZz/7GUuWLAm3ufvuu5k5cybffPMNqampXHrppVRVVQFWcLnyyiu56qqr+P7775k+fTr33Xcfr776avj7V199Nf/85z95+umnWb9+PS+88AJxcXE16vjd737HzJkzWb58OQ6Hg+uvv75Jjl9EGpYehioizZ7X6yU5OZmPP/6Y0aNHh7ffeOONlJeXc9NNN/HDH/6QN998k0mTJgFw8OBBunTpwquvvsqVV17JlClTKCgo4KOPPgp//7e//S3z5s1j7dq1bNq0iX79+rFgwQKysrKOqmHx4sX88Ic/5OOPP+a8884D4IMPPuDiiy+moqICt9vdyGdBRBqSeoBEpNnbsmUL5eXlnH/++cTFxYWX119/na1bt4bbHR6OkpOT6devH+vXrwdg/fr1jB07tsZ+x44dy+bNmwkEAqxevRq73c64ceOOW8uQIUPC6x07dgQgPz+/3scoIk3LEekCREROpLS0FIB58+bRuXPnGp+5XK4aIehURUdH16ldVFRUeN0wDMCanyQiLYt6gESk2Rs4cCAul4tdu3bRu3fvGktGRka43ZdffhleLywsZNOmTQwYMACAAQMG8Pnnn9fY7+eff07fvn2x2+0MHjyYYDBYY06RiLRe6gESkWYvPj6eu+66i1//+tcEg0HOOussiouL+fzzz0lISKBbt24APPTQQ7Rv3560tDR+97vfkZKSwsSJEwH4zW9+w4gRI3j44YeZNGkSy5Yt49lnn+Uvf/kLAN27d+eaa67h+uuv5+mnnyYzM5OdO3eSn5/PlVdeGalDF5FGogAkIi3Cww8/TGpqKjNmzGDbtm0kJSVxxhlncO+994aHoB555BHuuOMONm/ezNChQ3nvvfdwOp0AnHHGGfzrX//i/vvv5+GHH6Zjx4489NBDXHvtteHfeP7557n33nv55S9/yYEDB+jatSv33ntvJA5XRBqZrgITkRav+gqtwsJCkpKSIl2OiLQAmgMkIiIibY4CkIiIiLQ5GgITERGRNkc9QCIiItLmKACJiIhIm6MAJCIiIm2OApCIiIi0OQpAIiIi0uYoAImIiEibowAkIiIibY4CkIiIiLQ5CkAiIiLS5vx/FL8aro3d6qgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output.history['loss'])\n",
    "plt.plot(output.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.422863, 0.519536, 0.513177, 0.397293]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## all zero test case, expecting it to return averages\n",
    "\n",
    "all_zeros = np.zeros((1, 4))\n",
    "all_zeros_encoded = encoder.predict(all_zeros)\n",
    "all_zeros_decoded = decoder.predict(all_zeros_encoded)\n",
    "all_zeros_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.422863, 0.519536, 0.513177, 0.397293]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "all_zeros_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.466631, 0.486703, 0.445332, 0.491335])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
